+++
date = '2025-08-28T14:30:02+08:00'
draft = false
title = 'Binder'
+++

## 同步通信

![](/ethenslab/images/binder-sync.png)

## 异步通信

![](/ethenslab/images/binder-async.png)

## 内存管理

好的。遵照您的要求，以下是对该问题的严肃且精准的完整回答。

### **Binder 驱动的通信内存管理机制**

Binder 驱动的内存管理是一套内核层面的复杂机制，其核心目标是在进程间高效、安全地传输数据，并实现“一次拷贝”原则。

#### **第一部分：Binder 通信内存的总体管理机制**

该机制主要分为三个阶段：虚拟内存区的建立、事务缓冲区的分配与映射、以及事务缓冲区的释放。

**1.1 进程虚拟内存区的建立**

当一个用户进程首次打开 `/dev/binder` 设备并对其执行 `mmap()` 系统调用时，Binder 驱动会执行 `binder_mmap()` 内核函数。此函数的主要工作包括：
* 为该进程在内核中创建一个 `binder_proc` 结构体实例，用于追踪其所有 Binder 相关状态。
* 在该进程的虚拟地址空间中，分配并初始化一块指定大小（由 `BINDER_VM_SIZE` 决定，通常为 1MB）的虚拟内存区域（Virtual Memory Area, VMA）。
* 将这个 VMA 与进程的 `binder_proc` 结构体关联。

此阶段的关键在于，**仅分配了虚拟地址空间，并未分配实际的物理内存**。这块 VMA 的作用是为未来接收 Binder 数据提供一个预先确定的目标地址范围。

**1.2 事务缓冲区的分配与映射**

当一个进程（Client）通过 `ioctl(BINDER_WRITE_READ)` 发起一次事务（Transaction）时：
1.  **分配内核缓冲区**：Binder 驱动的 `binder_thread_write()` 函数会调用 `binder_alloc_buf()`，根据事务数据的大小，从内核的通用物理内存池（如 `vmalloc` 或 slab 分配器）中分配一个 `binder_buffer` 内核对象。
2.  **数据拷贝（一次拷贝）**：驱动调用 `copy_from_user()`，将数据从 Client 进程的用户空间地址，拷贝到上一步分配的内核 `binder_buffer` 中。这是整个跨进程通信中唯一的一次数据内容拷贝。
3.  **地址空间映射**：驱动识别出目标进程（Server）后，并不会再次拷贝数据。它会执行一个核心操作：**修改 Server 进程的内核页表**，将承载着数据的 `binder_buffer` 的物理内存页，直接映射到 Server 进程在 1.1 阶段建立的 VMA 中。
4.  **数据投递**：驱动将映射后的缓冲区在 Server 进程中的虚拟地址，连同事务命令（如 `BR_TRANSACTION` 或 `BR_ONEWAY`），一同投递给 Server 中等待的 Binder 线程。Server 线程可以直接访问该地址，如同访问进程内内存一样。

**1.3 事务缓冲区的释放**

当 Server 进程处理完事务数据后，它会通过 `ioctl` 向驱动发送 `BC_FREE_BUFFER` 命令，并附上需要释放的缓冲区的虚拟地址。
* 驱动接收到命令后，调用 `binder_free_buf()` 函数。
* 该函数首先解除该物理内存在 Server 进程 VMA 中的映射（通过修改页表），然后将 `binder_buffer` 对象及其占用的物理内存归还给内核的通用内存池。

---

#### **第二部分：同步与异步消息的内存划分机制**

Binder 驱动对同步和异步消息的内存管理，遵循“**统一物理来源，独立记账配额**”的核心原则。

**2.1 核心原则阐述**

* **统一物理来源**：无论是同步还是异步事务，其 `binder_buffer` 均从上文所述的**同一个内核通用物理内存池**中分配。物理来源上没有划分。
* **独立记账配额**：驱动对每个 `binder_proc`（即每个使用 Binder 的进程）内部，实施了严格独立的会计和配额制度，以此来区分和限制不同类型事务所能占用的内存资源。

**2.2 异步事务的内存配额机制**

为防止非阻塞的异步调用（`oneway`）耗尽系统资源而形成拒绝服务攻击，Binder 驱动对异步事务强制实施了内存配额限制。

* **配额初始化**：在 `binder_mmap()` 阶段，驱动会为进程的 `binder_proc` 结构体初始化一个 `free_async_space` 成员变量。其初始值被设定为该进程总 Binder 缓冲区大小（`buffer_size`）的**一半**。
* **分配时检查**：当 `binder_alloc_buf()` 为一个带有 `TF_ONE_WAY` 标志的异步事务分配缓冲区时，它会执行以下检查：
    * 若请求的缓冲区大小 `size` **大于** 当前可用的 `free_async_space`，分配将失败，内核返回 `-ENOSPC` 错误，该异步事务被丢弃。
    * 若 `size` **小于等于** `free_async_space`，则分配成功，并从配额中扣除相应大小：`free_async_space -= size`。
* **释放时归还**：当 `binder_free_buf()` 释放一个用于异步事务的缓冲区时，会将该缓冲区的大小加回到配额中：`free_async_space += size`。

**2.3 同步事务的内存使用机制**

* 同步事务所请求的内存**不受 `free_async_space` 配额的限制**。
* 其内存使用主要受限于整个进程的总缓冲区大小（`buffer_size`）。由于同步调用会阻塞客户端线程，天然地形成了反向压力（Back-pressure），使其无法在短时间内无限制地消耗内存，因此不需要类似的显式配额限制。

综上所述，Binder 驱动通过 `mmap` 和页表修改实现了高效的“一次拷贝”内存管理。在此基础上，它并未对物理内存池进行划分，而是通过对每个进程实施一个占其总可用缓冲区一半的**异步内存配额**，来精确地约束和管理同步与异步消息的资源使用，确保系统的稳定性和公平性。