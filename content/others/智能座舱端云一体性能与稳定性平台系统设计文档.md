# 智能座舱端云一体性能与稳定性平台 (Polaris 1.0) 系统设计文档



## 版本信息

| 序号 | 版本 | 修订内容 | 状态 | 修订人 | 日期 |
| --- | --- | --- | --- | --- | --- |
|1|0.1|First draft||操权力|2025/12/9|

## 文档目的

本文档旨在全面定义 智能座舱端云一体性能与稳定性平台 (代号 Polaris 1.0) 的系统架构、功能需求及实施路径。本文档将服务于以下核心场景：

* 管理层决策：清晰阐述项目背景、痛点、ROI（投入产出比）及资源需求，作为立项审批与资源调度的依据。
* 跨部门协同：作为座舱平台部与车云平台部沟通数据协议、接口规范及边界划分的“蓝本”，确保端云技术方案的一致性。
* 工程落地指导：作为项目启动后的核心输入，指导研发团队进行端侧 Agent 开发、埋点设计及测试验收。
  
## 背景与问题定义

### 背景

当前智能座舱的数据建设存在数据维度失衡与底层感知缺失的问题，具体表现在以下三个方面：

* 应用质量量化手段缺失：目前虽已具备应用层的业务埋点能力（如 PV/UV、页面点击流），能支撑产品运营分析；但对于应用技术质量（如 Crash率、ANR率、错误日志）及 核心性能指标（如启动耗时、页面响应延迟）尚缺乏系统性的监控与度量手段，导致软件交付质量缺乏客观数据支撑。

* 平台侧缺乏云端可观测性：作为座舱底座的平台研发部门，目前缺乏专属的云端观测平台。对于线上车辆的系统级健康度（如 SystemServer 重启、关键服务存活、资源水位），研发团队缺乏实时获取线上运行时状态的能力，往往只能在故障发生后进行被动回溯。

* 系统稳定性保障体系亟待构建：随着智能座舱软件规模与复杂度的提升，单纯依赖线下测试已难以覆盖所有边缘场景。为了保障用户体验，亟需构建一套严谨的、标准化的端云一体性能与稳定性监控平台，实现对线上真实运行质量的精准监测与闭环管理。

### 当前痛点

| 痛点 | 描述 | 业务影响 |
| --- | --- | --- |
| **跨端故障排查成本较高** | 当前缺乏跨端（Android-Linux-MCU）的自动化关联数据，面对复杂的跨域交互问题，排查过程往往需要人工拼接多端日志。 | **研发效率受限**：故障定位往往需要多方协同与多次排查，拉长了问题的解决周期。 |
| **性能量化数据覆盖不足** | 现有的性能评估主要依赖线下测试或有限样本，缺乏全量用户场景下的启动速度、流畅度等自动化量化数据。 | **版本评价受限**：难以精确捕捉版本迭代中的细微性能波动，线上实际体验的评估数据不够丰满。 |
| **偶发异常现场回溯困难** | 对于线上偶发的非必现问题，目前主要依赖事后尝试复现，缺乏异常发生瞬间的自动“快照”捕获机制。 | **闭环周期较长**：部分偶发性稳定性问题（如随机黑屏、卡顿）因缺乏现场数据支持，难以快速彻底根除。 |
| **资源效能优化缺乏支撑** | 缺乏进程级的 CPU、内存、IO 历史趋势画像，在进行精细化资源管控时缺乏足够的数据颗粒度。 | **成本优化受限**：硬件资源规划倾向于保守策略以保障稳定性，BOM 成本的进一步精细化挖掘存在困难。 |


## 目标与范围

### 项目目标

本项目旨在基于 “端侧深度探针 + 云端聚合分析 + 全链路追踪” 的技术理念，构建 Polaris 1.0 端云一体化平台，实现以下三个核心目标：

1. 全链路可观测：打破 Android、Linux Host、MCU 的数据孤岛，建立统一的 全局事件标准 (Global Event ID)，将分散在不同系统的故障与状态数据聚合至同一平台，实现跨端调用的追踪，为后续的可视化链路分析奠定数据基础。
   
2. 故障现场自动聚合与关联：突破现有“日志碎片化”及“事后拉取不全”的局限。建立 “事件驱动”的现场快照机制，在异常发生瞬间，自动聚合与该事件强相关的全维度上下文信息（如 Trace、系统 Log、进程状态等）并生成 完整的故障证据包。这不仅实现了 Event 与 Log 的精准索引，更确保了现场信息的完整性，彻底解决因关键日志缺失导致无法定位的难题。
   
3. 数据驱动治理：建立系统级的性能与稳定性基线（Baseline），通过量化数据驱动版本质量验收与硬件资源优化，将质量管理从“定性”转向“定量”。

### 核心 KPI 指标

| 维度 | 指标名称 | 目标值 (示例) | 说明 |
| --- | --- | --- | --- |
| **质量** | **严重故障主动发现率** | **> 90%** | 在用户报修前，通过平台主动捕获并预警系统级崩溃与卡顿。 |
| **效率** | **日志精准命中率** | **100%** | 每一个上报的严重异常事件，都能直接下载到对应的、正确的 Log 文件，无需人工筛选。 |
| **复现** | **致命问题现场捕获率** | **> 80%** | 针对 Crash/Watchdog 等致命问题，确保有对应的 Trace/Log 可供分析。 |
| **成本** | **资源优化场景产出** | **TOP 5/季度** | 每季度识别并输出 5 个高资源消耗（CPU/内存）场景。 |

### 项目范围

#### 范围内

1. **端侧全栈感知体系**：
   * **Android 深度探针**：构建系统级监控服务 `PolarisAgentService`，实现对应用生命周期、核心服务状态、底层资源（LMK/IO/Binder）的**全维度深度监听**。
   * **Linux/MCU 异构覆盖**：建设 Linux Host 侧的**系统健康守护进程**，负责关键服务（Service）存活检测与系统指标采集；适配 MCU 遥测协议，实现异构芯片间的故障透传。
   * **边缘智能处理**：在端侧实现数据的**预处理与清洗**，包含事件聚合、流控防爆、日志现场的智能截取与压缩，减轻车云带宽压力。
   * **标准化基础设施**：建立《全局事件注册表》及自动化工具链，统一多端的数据定义与协议标准。

2. **云端分析能力需求**:
   * **元数据管理能力**：要求云端支持同步《全局事件注册表》，实现对上报事件的自动化解析、分类与标签化管理。
   * **自动化关联引擎**：要求云端具备**“事件-日志”自动匹配能力**，将结构化的 Event 数据与非结构化的 Log 文件（基于索引）在存储层自动关联，形成完整的故障证据包。
   * **趋势与模式识别**：要求云端支持基于时间窗口的聚合计算，能够识别异常爆发（Spike）趋势及性能指标（CPU/内存）的长期演进趋势。

3. **可视化与运营平台**
   * **数字化质量驾驶舱**：建设多维度的质量仪表盘（Dashboard），支持按版本、车型、时间段下钻分析千车故障率、性能基线达标率。
   * **智能排查工作台**：提供“一站式”问题分析界面，支持通过 EventID/TraceID 检索故障，直接浏览关联的日志、堆栈及设备状态，支持远程诊断指令的下发与结果展示。

#### 范围外

1. **可视化的全链路拓扑分析**：1.0 阶段聚焦于跨端链路数据的 标准化采集与逻辑串联，优先夯实数据底座能力；全链路图形化的调用链拓扑展示规划在后续版本迭代中实现。
2. **业务代码修复**：Polaris 平台负责精准“定位”并“指派”问题，**不负责** 具体业务 APP 内部的代码逻辑修复。
3. **交互体验设计**：本项目专注于性能数据的量化，**不包含** HMI 界面（UI/UE）的主观交互设计与优化。

## 业务流程与核心场景

### 角色定义

| 角色 | 职责描述 | 关注点 |
| --- | --- | --- |
| **研发工程师** | 接收告警，分析堆栈与日志，修复 Bug；针对疑难客诉问题，远程下发特定诊断指令 | 故障堆栈的完整性，日志关联的准确性，是否需要补充更多运行时信息。 |
| **质量工程师** | 配置告警阈值，监控线上大盘水位，识别版本质量风险 | 故障率趋势是否劣化，性能指标是否符合预期，流量消耗是否异常。 |
| **产品经理** | 查看应用活跃度与性能体验趋势 | 核心功能的响应速度趋势，用户使用过程中的卡顿频率。 |

### 核心作业流程图

**1. 故障主动发现闭环流程**

> *描述从异常发生到研发接入的处理路径*

* **捕获 (Capture)**: Polaris Agent 监听到异常（如 ANR），记录运行时状态，抓取 Trace/Logcat，并生成唯一 EventID。
* **处理 (Process)**: 端侧进行流量控制检查，通过 `logf` 索引将 Event 与 Log 文件进行逻辑组合。
* **上报 (Report)**: Event 数据实时上报，大文件 Log 在 WiFi/空闲时段异步上传（支持云端按需拉取）。
* **通知 (Notify)**: 云端检测到异常数据超过阈值（例如某版本 Crash 率上升），向 **责任模块负责人** 发送通知。
* **分析 (Analyze)**: 研发工程师查看通知，进入平台查看关联的上下文数据，确认问题根因并修复。

**2. 疑难问题排查流程**

> *描述针对复杂客诉或非必现问题的处理路径*

* **检索**: 研发工程师在平台输入车辆 VIN 码或 EventID 检索相关记录。
* **查看**: 系统展示该事件的发生时间、设备信息、以及**已自动关联**的 Log 文件下载链接。
* **诊断**: 针对区域技术支持无法处理的复杂客诉，若现有日志不足以定位，**研发工程师** 通过控制台下发 `Shell` 诊断指令，端侧执行后回传结果，以获取更深度的运行时信息。

### 典型用户故事

#### 场景一：风险预警

> **背景**: 某车型灰度推送 v1.5 OTA 版本。
> **事件**: 上线 24 小时内，Polaris 平台监测到 `GVM_SYS_STORAGE_LOW`（磁盘空间不足）事件在特定批次车辆上的上报量呈**异常上升趋势**。
> **行动**:
> 1. 平台自动触发 **风险预警**，即时通知研发负责人。
> 2. 研发工程师通过平台获取存储分布数据，精准定位到某应用私有目录占用空间急剧膨胀。
> 3. **分析**: 结合自动关联采样的 Log，确认该应用在特定异常分支下陷入**数据库高频重复写入**死循环。
> **结果**: 研发团队在磁盘被完全耗尽导致系统挂死（System Hang）前，紧急输出修复补丁并推送 OTA，成功拦截了批量重大事故。
> 

#### 场景二：稳定性治理

> **背景**: 某应用发布 v2.0 灰度版本。
> **事件**: 灰度发布期间，平台监测到应用出现**偶发性** `GVM_APP_ANR`（无响应）告警，且线下测试难以复现。
> **行动**:
> 1. 研发工程师点击告警详情，查看聚合后的故障样本。
> 2. 系统已通过 `logf` 字段自动关联了故障时刻的 `traces.txt` 以及系统侧 `perflog` (性能日志)。
> 3. **分析**: 工程师通过 Trace 文件发现应用主线程阻塞在 Binder IPC 调用中；进一步联合分析 `perflog`，定位到是对端 Service 在高并发场景下因锁竞争导致处理耗时过长，拖累了客户端。
> **结果**: 确认根因为**服务端卡顿**。研发工程师针对服务端逻辑进行异步化优化，彻底解决了这一隐蔽的跨进程阻塞问题。
> 

#### 场景三：性能监控

> **背景**: 某版本上线后，产品经理关注核心应用在复杂交互场景下的滑动流畅度。
> **事件**: Polaris 仪表盘显示 `GVM_APP_JANK` (掉帧/卡顿) 指标在特定列表滑动场景下出现劣化趋势。
> **行动**:
> 1. 系统展示了掉帧率与主线程负载的关联曲线。
> 2. **发现**: 在卡顿发生的时间段内，主线程 MessageQueue 待处理消息数量显著激增。
> 3. **分析**: 研发工程师通过分析采集到的 `Looper` 统计数据，发现是一次性加载过多列表项导致并在主线程频繁 Post UI 刷新消息，引发**主线程消息队列积压**，从而阻塞了渲染信号（Vsync）的处理。
> **结果**: 研发工程师引入消息合并与节流机制（Throttling），消除了主线程拥堵，恢复了滑动流畅性。
>

#### 场景四：远程指令下发

> **背景**: 用户反馈方控按键（下一曲）失效，或错误地控制了不显示在屏幕上的后台音乐应用，常规 Logcat 无法体现系统内部的分发逻辑。 
> **行动**: 
> 1. 研发工程师怀疑是 MediaSession 焦点抢占或状态同步异常。
> 2. 工程师通过 Polaris 控制台，向目标车辆下发 dumpsys media_session 指令。
> 3. 分析: 回传的诊断结果显示，Media button session 仍被后台应用 com.reachauto.clouddesk 占用（尽管其状态为 active=false），导致按键事件未正确分发给前台亮屏的 com.tencent.wecarflow。 
> 结果: 确认根因是后台应用未正确释放焦点，研发工程师将 Bug 准确指派给相关应用团队，无需现场抓包。


## 需求拆解

本章节将 Polaris 1.0 平台的核心需求拆解为四大关键能力域。这些能力定义了系统的边界与核心价值，是后续详细功能设计的基础。
本章节采用能力域（Capability Domain）拆解方法，以系统应具备的核心能力为中心，而非具体功能或实现方式。每一能力域仅定义目标、适用范围与责任边界，不涉及接口设计、数据结构或技术选型细节。具体功能点将在后续《功能性需求》中展开，质量与约束要求将在《非功能性需求》中统一定义。


### 稳定性全栈感知能力

**目标**：构建覆盖 Android 应用层、系统框架层以及 Linux Host/MCU 异构计算单元的异常捕获体系，实现全栈、全维度的故障感知与现场数据留存。

| 能力名称 | 能力描述与目标 | 适用范围 | 责任边界 |
| --- | --- | --- | --- |
| **应用层稳定性监控**<br>(App Layer Stability) | **描述**：具备对 Android **应用层 (APK)** 致命异常的实时监测能力。涵盖 Java Crash、App Native Crash (JNI)、ANR 及 App OOM；在异常触发时同步执行现场冻结与堆栈抓取。<br>**目标**：确保应用级崩溃捕获率 > 98%，异常现场数据完整性 100%。 | Android Framework<br>Third-party Apps<br>System Apps (Launcher等) | **负责**：捕获应用堆栈、页面栈及进程状态；<br>**不负责**：分析应用内部具体的业务逻辑错误。 |
| **系统框架稳定性监控**<br>(System Framework Stability) | **描述**：具备对 **Android 核心服务**及**关键守护进程**的存活状态监测能力；识别系统级资源耗尽风险（如 Binder 耗尽、句柄泄漏、LMK）。<br>**目标**：准确识别 SystemServer 死锁 (Watchdog)、核心服务崩溃、系统异常重启及严重资源拥堵事件。 | SystemServer<br>Binder Driver<br>Native Daemons (SurfaceFlinger等) | **负责**：识别导致系统不稳定的服务异常和资源瓶颈；<br>**不负责**：介入 Linux Kernel 内部调度机制的调试。 |
| **异构运行环境监控**<br>(Heterogeneous Env Monitoring) | **描述**：具备对 **Linux Host (PVM)** 及 **MCU** 运行状态的独立监测能力。通过 Native Daemon 标准化采集 Linux 侧服务状态、系统重启事件以及 MCU 侧的心跳与硬件故障码。<br>**目标**：实现对底层虚拟化环境与硬件外设健康状况的统一视图监控。 | Linux Host (PVM)<br>MCU<br>Hypervisor | **负责**：异构数据的标准化接入、协议对齐及状态监测；<br>**不负责**：异构系统内部具体业务逻辑的监控实现。 |


### 性能与资源度量能力

**目标**：建立可量化的性能基线，从“主观体验”转向“客观数据”，实现对计算资源（CPU/Mem/IO）及系统启动效率的精细化审计。

| 能力名称 | 能力描述与目标 | 适用范围 | 责任边界 |
| :--- | :--- | :--- | :--- |
| **交互体验量化**| **描述**：具备对用户核心交互体验的监测能力。重点涵盖**应用启动耗时**、**主线程健康度 (MessageQueue)** 以及**界面流畅度 (FPS/Jank)**。<br>**目标**：量化 App 启动速度，识别主线程阻塞与掉帧现象。 | Top 核心应用<br>Launcher<br>SystemUI | **负责**：采集启动耗时、MessageQueue 调度延迟及绘制帧率；<br>**不负责**：应用页面内部的数据加载逻辑。 |
| **资源水位画像**| **描述**：具备对**进程级**资源消耗（CPU使用率、内存占用、IO吞吐量、句柄数）的周期性采样与 TOP 排行识别能力。<br>**目标**：识别**高资源消耗进程**与内存/句柄泄漏，绘制 24h 资源趋势图。 | Android GVM 进程<br>Native 守护进程 | **负责**：资源数据的统计、归因与异常阈值判定；<br>**不负责**：操作系统的资源调度策略 (Scheduler)。 |
| **系统级性能监控**| **描述**：具备对**操作系统级**关键性能指标的监测能力，重点涵盖系统启动耗时及磁盘整体负载。<br>**目标**：确保座舱冷启动（Cold Boot）时间达标，监控存储设备寿命与性能衰减。 | Android Boot Process<br>Storage Device (UFS/eMMC) | **负责**：各启动阶段（BootLoader/Kernel/UserSpace）的耗时分解；<br>**不负责**：缩短硬件初始化时间。 |


### 现场还原与协同能力

**目标**：解决“有报警无日志”的痛点，构建端云协同的自动化取证与远程诊断通道。

| 能力名称 | 能力描述与目标 | 适用范围 | 责任边界 |
| --- | --- | --- | --- |
| **标准化事件协议体系** | **描述**：基于《全局事件注册表》构建统一的事件定义、序列化与解析能力。<br>**目标**：确保端侧上报数据与云端解析引擎的语义一致性，支持协议动态扩展。 | 端侧 Agent, 车云 SDK, 云端解析服务 | 负责协议的定义与维护工具链；不限制业务 Payload 的具体内容。 |
| **智能现场快照** | **描述**：具备“事件驱动”的自动化日志聚合能力，在异常发生瞬间关联并打包 Trace、Logcat 及系统状态信息。<br>**目标**：实现 Event 与 Log 文件的 1:1 精准索引。 | 本地日志系统, 文件系统 | 负责日志的定位、截取与压缩；不负责日志内容的语义分析。 |
| **远程诊断执行** | **描述**：具备安全可控的云端指令接收与本地执行能力，支持下发 Shell 脚本或调试命令。<br>**目标**：在不打扰用户的前提下获取更深度的运行时信息。| Shell 环境, Debug 接口 | 负责指令通道的建立与执行结果回传；严禁执行未授权的高危写操作，不支持批量执行、默认灰度单车、需显式授权、强审计。  |

### 数据智能与运营能力

**目标**：将海量原始数据转化为可行动的洞察（Actionable Insights），支撑研发与质量团队的决策。

| 能力名称 | 能力描述与目标 | 适用范围 | 责任边界 |
| --- | --- | --- | --- |
| **端云数据自动关联** | **描述**：具备在海量存储中，根据索引自动将结构化事件与非结构化日志文件进行绑定的能力。<br>**目标**：消除人工查找日志的成本。 | 云端存储层 | 负责数据的逻辑关联与存储生命周期管理。 |
| **实时风险预警** | **描述**：具备基于时间窗口的流式计算能力，识别线上故障的爆发趋势并触发告警。<br>**目标**：实现故障感知。 | 计算引擎| 负责告警策略的计算与推送；不负责告警后的工单流转。 |
| **多维质量可视化** | **描述**：具备多维度（版本/车型/时间/地区）的数据聚合与图表展示能力。<br>**目标**：提供从“宏观大盘”到“微观个案”的钻取分析视图。 | 数据仓库, 可视化前端 | 负责数据的可视化呈现。 |


## 系统总体方案

### 总体设计概述

Polaris 1.0 基于 **Hypervisor 虚拟化架构** 设计，旨在构建跨越 **GVM (Guest VM - Android)**、**PVM (Primary VM - Linux)** 及 **MCU** 的端云一体化全栈监控系统。
系统采用 **分层架构** 与 **模块化服务设计**。在控制面上，通过 **注册表驱动（Registry-Driven）** 机制实现业务埋点定义与底层采集逻辑的解耦；在数据面上，通过 **双守护进程（Dual Daemon）** 机制打通异构芯片与系统的通信壁垒。系统将计算能力前置至端侧，通过 `PolarisAgentService` 实现数据的实时清洗、流控与现场关联，仅将高价值的结构化数据与诊断日志同步至云端。

### 系统总体架构图

![](../../static/images/Polaris1.0.drawio.png)

### 架构分层详解

#### 业务应用与接口层

本层负责定义数据采集的标准接口，通过自动代码生成技术屏蔽底层通信细节：

* **Polaris SDK**: 面向上层业务应用（如 Launcher, Maps）。该组件由《全局事件注册表》编译生成，提供强类型的事件对象封装与校验逻辑，负责将业务数据序列化并传递给 Framework 层。
* **System Internal SDK**: 面向 SystemServer 内部服务（如 AMS, WMS）。与 Polaris SDK 同源生成，专门用于系统关键服务内部的插桩（Instrumentation），以捕获服务级异常与状态变更。
* **Host SDK**: 面向 PVM 侧的 Linux 应用程序（如 Cluster HMI）、系统核心服务，提供 C++ 标准上报接口，负责将 PVM 侧业务数据发送至 Host Daemon。

#### 框架传输与核心服务层

本层位于 Android GVM，是数据汇聚、策略执行与处理的核心区域：

* **Polaris SDK (Framework API)**: 部署于 `AppFramework API` 层。作为系统级的传输接口实现，它承接来自上层业务的调用请求，并维护与*PolarisAgentService的 IPC 通信链路，确保数据的可靠投递。

* **PolarisAgentService**: 常驻系统服务，内部包含五个核心功能模块：
  * **EventCollector**: **统一接入模块**。作为 Binder 服务端接收 Polaris SDK 请求；同时作为 LocalSocket 客户端，在服务启动时主动连接 Native Daemon 建立长连接通道，并通过后台线程实时拉取 Native 侧上报的事件流。
  * **ConfigManager**: **配置管理模块**。负责加载本地注册表文件的配置，解析采样率、阈值及采集开关策略。
  * **FlowController**: **流量控制模块**。对输入事件进行频率限制，防止异常爆发导致系统资源耗尽。
  * **ContextEngine**: **现场聚合模块**。在事件通过流控后，负责生成唯一 EventID，挂载系统时间戳，并根据事件类型关联 Logcat、Trace 文件及进程快照，生成索引信息。
  * **DiagnoseHandler**: **诊断执行模块**。负责校验并执行来自云端的诊断指令（Shell Command），并管理执行结果的回传。

#### 原生与异构跨域层

本层负责 Android Runtime 之外的底层环境监控及跨虚拟机通信：

* **Polaris Native Daemon (GVM)**:
* **本地采集**: 负责监控 Native 进程崩溃（Tombstone）、系统资源、及 HAL 层状态。
* **跨域网关**: 作为 GVM 侧的通信端点，维护与 PVM/MCU 的连接，接收跨域透传的数据。
  
* **Polaris Host Daemon (PVM)**:
* **宿主监控**: 负责监控 PVM 侧的 `systemd` 服务状态、关键驱动状态及虚拟机管理服务（qcrosvm/VMM）。

#### 传输通道与云平台

* **VlmAgent**: **统一传输网关**。作为端侧唯一的数据出口，负责接收来自 `PolarisAgentService` 的结构化事件,以及日志文件（按需拉取），执行断点续传、数据压缩与网络流量调度。
* **Cloud Platform**: 负责数据的计算、存储与可视化。

### 核心设计原则

1. 进程级隔离与服务化：PolarisAgentService 设计为独立系统进程，而非 SystemServer 的内部线程。这种设计带来了两大优势：
    * 稳定性：监控服务的异常（如 OOM）不会导致系统核心服务（SystemServer）崩溃，反之亦然。
    * 高性能：独立的进程空间避免了与 AMS/WMS 争抢主线程资源，确保了监控逻辑的独立调度。
2. 系统核心即客户端：确立 SystemServer 在监控体系中的 Client 身份。AMS、WMS 等核心服务通过 System Internal SDK，以跨进程调用（IPC）的方式向 Polaris 上报数据。这种“旁路监控”模式确保了对系统原有逻辑的最小侵入。
3. 异构接入抽象化：针对 MCU 等异构单元，系统采用 "HAL 驱动适配 + Daemon 统一采集" 的接入原则。不强依赖特定的物理连接方式（如直连或透传），而是通过 Native 层的适配层（Adapter/HAL）屏蔽硬件连接差异，确保架构在不同车型硬件拓扑下的通用性与兼容性。

## 功能性需求

### 稳定性全栈感知能力

#### 应用层稳定性监控

##### FR-STAB-001 应用 Java 崩溃 (Java Crash) 捕获

| 属性 | 内容 |
| --- | --- |
| **优先级** | P0 |
| **前置条件** | 1.系统层已部署全局监控探针。<br>2. 监控功能的配置开关处于开启状态。 |
| **输入** | **触发源**：<br>应用运行环境（Android Runtime）抛出的**未捕获异常信号**（Uncaught Exception）。<br>**数据**：<br>1. 异常堆栈信息（StackTrace）。<br>2. 异常类型与描述消息（Exception Message）。 |
| **处理逻辑** | 1. **异常拦截**：<br>在应用进程因异常即将终止前，拦截异常信号，挂起当前线程以确保有足够的 CPU 时间片执行数据采集。<br>2. **上下文捕获**：<br>提取崩溃时刻的运行时环境信息，包括但不限于：<br> - 进程名称、线程名称及 ID。<br> - 应用的前后台状态。<br> - 当前 Activity 页面栈信息（用于还原用户路径）。<br>3. **流控策略**：<br>执行本地频次控制策略。检查该进程在设定时间窗口（如 10 分钟）内的崩溃次数，若超限则降级处理（仅记录统计计数，不抓取详细堆栈），防止日志写入引发 IO 阻塞。<br>4. **透传退出**：<br>数据采集完成后，**必须**将异常信号交还给系统默认处理程序，确保应用能够按照 Android 系统规范正常退出，防止应用界面假死或进程僵滞。 |
| **输出** | 1. **结构化事件**：生成包含完整上下文信息的 `GVM_APP_CRASH` 事件对象。<br/>2. **本地日志**：在本地持久化存储区保留一份异常日志备份（作为兜底）。 <br/>3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》|

##### FR-STAB-002 应用无响应 (ANR) 捕获

| 属性 | 内容 |
| --- | --- |
| **优先级** | P0 |
| **前置条件** | 1. 系统层已部署全局监控探针。<br>2. 监控功能的配置开关处于开启状态。 |
| **输入** | **触发源**：系统框架层（Framework）识别到的**应用无响应信号**（AppNotResponding）。<br>**数据**：<br>1. 目标应用进程标识（PID/ProcessName）。<br>2. 系统生成的**堆栈跟踪文件**（Trace File，通常位于 `/data/anr/` 目录）。 |
| **处理逻辑** | 1. **信号识别**：<br>实时接收系统 ActivityManagerService 发出的 ANR 通知。<br>2. **目标过滤**：<br>根据配置白名单判断是否采集该进程，过滤非关注应用的 ANR 事件。<br/>3. **堆栈截取**：<br>读取系统生成的 Trace 文件，根据目标 PID **精准截取**该进程及其子线程的堆栈片段（需剔除文件中的其他无关进程数据，以减少数据体积）。<br>4. **快照关联**：<br>获取 ANR 发生时刻的系统负载信息（Load Avg / CPU Usage / IO Wait）并与堆栈信息打包。<br>5. **流控策略**：<br>执行本地频次控制策略。检查该进程在设定时间窗口（如 10 分钟）内的 ANR 次数，若超限则仅记录计数，不再执行堆栈截取操作。 |
| **输出** | 1. **结构化事件**：生成包含 Trace 附件索引（Reference）的 `GVM_APP_ANR` 事件对象。<br>2. **本地日志**：在本地持久化存储区生成关联的证据包（包含截取的 Trace 片段与系统负载快照）。<br>3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》 |


##### FR-STAB-003 应用 Native 库崩溃 (App JNI Crash) 捕获

| 属性 | 内容 |
| :--- | :--- |
| **优先级** | P0 |
| **前置条件** | 1. 系统层已部署全局监控探针（Native Daemon）。<br>2. 监控功能的配置开关处于开启状态。 |
| **输入** | **触发源**：<br>应用进程（APP）加载的 JNI 动态库触发致命信号（SIGSEGV/SIGABRT）。<br>**数据**：<br>1. 系统生成的 Tombstone 崩溃文件（通常位于 `/data/tombstones/`）。<br>2. 进程退出信号（Signal Code）。 |
| **处理逻辑** | 1. **监听与解析**：<br>实时监听系统 Tombstone 文件的生成事件，读取文件头部信息。<br>2. **身份识别**：<br>检查崩溃进程的 UID 或进程名称。若属于**非系统核心进程**（即普通 App），则执行应用级采集逻辑；若为系统服务则忽略（交由系统框架监控处理）。<br>3. **指纹去重**：<br>基于“应用名称 + 崩溃堆栈关键帧”生成唯一指纹，在端侧聚合重复的崩溃事件，防止日志风暴。<br>4. **事件生成**：<br>将非结构化的 Tombstone 数据转换为标准化的事件对象。 |
| **输出** | 1. **结构化事件**：生成 `GVM_APP_NATIVE_CRASH` 事件对象。<br>2. **本地日志**：建立事件 ID 与原始 Tombstone 文件的索引关联。<br>3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》 |


##### FR-STAB-004 应用 OOM (App OOM) 事件监控

| 属性 | 内容 |
| :--- | :--- |
| **优先级** | P0 |
| **前置条件** | 1. 系统层已部署全局监控探针。<br>2. 监控功能的配置开关处于开启状态。<br>3. 具备获取应用进程退出详细原因的能力（如 ApplicationExitInfo 或类似机制）。 |
| **输入** | **触发源**：<br>应用进程**意外终止信号**。<br>**数据**：<br>1. 进程退出原因描述（Exit Reason，需区分系统回收/异常崩溃）。<br>2. 进程终止前的内存使用统计数据（如 PSS/RSS/VSS）。 |
| **处理逻辑** | 1. **原因甄别**：<br>在进程退出后，识别退出原因。准确区分是**系统低内存查杀 (LMK)**（通常表现为 `REASON_LOW_MEMORY`）还是**Java 堆内存耗尽**（通常表现为 `OutOfMemoryError` 导致的 Crash）引发的异常。<br>2. **内存快照回溯**：<br>尝试关联该进程在终止前最近一次采集的内存统计数据（如 PSS/RSS），以辅助判断是否存在内存泄漏。<br>3. **风暴抑制**：<br>针对前台应用因 OOM 导致的反复重启进行检测。若同一应用在短时间内（如 5 分钟）连续触发 OOM，则实施指数退避策略，减少上报频次。<br>4. **事件生成**：<br>组装 OOM 事件负载，标记明确的 OOM 类型（System LMK / Java OOM）。 |
| **输出** | 1. **结构化事件**：生成包含内存快照信息的 `GVM_APP_OOM` 事件对象。<br>2. **本地日志**：记录关联的系统内存水位信息（MemInfo）。<br>3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》 |


#### 系统框架稳定性监控

##### FR-STAB-005 SystemServer Watchdog (死锁) 监控

| 属性 | 内容 |
| :--- | :--- |
| **优先级** | P0 |
| **前置条件** | 1. 监控探针已植入系统看门狗（Watchdog）模块或具备监听能力。<br>2. 监控功能的配置开关处于开启状态。 |
| **输入** | **触发源**：<br>系统关键锁或核心线程（如 UI Thread, IoThread）**等待超时信号**（通常阈值为 60秒）。<br>**数据**：<br>1. 阻塞线程的完整堆栈信息（Stack Traces）。<br>2. 持锁状态与锁竞争信息（Lock Contention）。 |
| **处理逻辑** | 1. **重启前拦截**：<br>在系统触发看门狗复位（Soft Reboot / Restart）流程前，优先执行监控逻辑，确保有短暂的时间窗口进行数据转存。<br>2. **现场固化**：<br>立即将当前的系统全量线程堆栈（Traces.txt）复制或转存至持久化存储区，**防止系统重启过程清理现场文件**，导致关键证据丢失。<br>3. **异常标记**：<br>在磁盘特定位置写入“非正常重启”标志位（Flag），以便系统下次启动时进行归因统计，区分正常关机与异常重启。<br>4. **事件上报**：<br>尝试通过 Native 通道（因为 Java 层可能已挂死）发送死锁事件。 |
| **输出** | 1. **结构化事件**：生成包含死锁堆栈索引的 `GVM_SYS_WATCHDOG` 事件对象。<br>2. **本地日志**：在持久化目录保留死锁现场的 Trace 文件。<br>3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》 |

##### FR-STAB-006 Android 系统异常重启监控

| 属性 | 内容 |
| :--- | :--- |
| **优先级** | P0 |
| **前置条件** | 1. 系统完成启动初始化流程（Boot Completed）。<br>2. 具备读取系统启动属性（Boot Reason）及持久化存储的权限。 |
| **输入** | **触发源**：<br>系统**启动完成广播** (Boot Completed) 或同等时机的初始化信号。<br>**数据**：<br>1. 系统启动原因属性（如 `sys.boot.reason` 或 `ro.boot.bootreason`）。<br>2. 持久化存储中的**历史状态标记**（包含上一次启动时间戳、Watchdog/Crash 遗留的异常标志位）。 |
| **处理逻辑** | 1. **原因推断**：<br>对比本次启动原因与上一次运行状态进行逻辑仲裁：<br> - **已知异常**：若存在 Watchdog 或 Core Crash 遗留的标记，判定为对应的系统级故障重启。<br> - **内核恐慌**：若启动属性标识为 Kernel Panic 或 WDT（硬件看门狗），判定为内核级重启。<br> - **正常重启**：若标识为用户主动关机、OTA 升级或常规电源管理操作，判定为正常重启。<br> - **掉电/未知**：若无任何异常标记且非正常重启，判定为异常掉电或未知原因重启。<br>2. **时长计算**：<br>基于上一次记录的启动时间戳，计算上一次系统正常运行的时长（Uptime），用于评估系统平均无故障时间（MTBF）。<br>3. **状态重置**：<br>分析完成后，清除历史异常标记，更新本次启动时间戳，为下一次监控周期做准备。 |
| **输出** | 1. **结构化事件**：生成包含重启原因分类（Category）及运行时长（Duration）的 `GVM_SYS_RESTART` 事件对象。<br>2. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》 |

##### FR-STAB-007 全路径系统重启归因监控

| 属性 | 内容 |
| :--- | :--- |
| **优先级** | P0 |
| **目标** | 建立跨越 Host、GVM、Kernel、Framework 四层架构的重启感知能力，提供统一的重启归因数据源。 |
| **前置条件** | 1. 监控服务具备获取 Hypervisor 状态及 SOC 硬件复位标志的权限。<br>2. 已集成 **FR-STAB-006** 的 Android 内部重启判定结果。 |
| **处理逻辑** | 1. **全路径层次判定**：<br>系统启动后，根据硬件寄存器、Bootloader 传参及 Android 属性进行综合仲裁，确定重启发生的最高级别：<br> - **Linux Host层**：检测到 SOC 硬件复位或宿主机 Kernel Panic，判定为 Host 重启。<br> - **GVM层**：Host 未重启，但虚拟机管理器（Hypervisor）强制拉起 Android 域，判定为 GVM 重启。<br> - **Android Kernel层**：基于 **FR-STAB-006** 判定，若为内核崩溃且 GVM 未重启，归类于此层。<br> - **Android Framework层**：仅 SystemServer 进程重启，底层 Linux 内核连续运行，归类于此层。<br>2. **异常分类同步**：<br> - 读取 `sys.boot.reason.last` 等关键属性，识别是 [异常:死锁/崩溃/掉电] 还是 [正常:用户重启/OTA]。 |
| **输出** | 1. **结构化事件**：`GVM_SYSTEM_REBOOT_EVENT` <br> - **boot_reason**: 原始启动原因字符串<br> - **is_unexpected**: 布尔值，用于云端统计严重故障率。<br>2. 关联日志路径及 ID 注册参考《Polaris 1.0 全局事件ID与注册表规范》。 |

##### FR-STAB-008 核心服务崩溃监控

| 属性 | 内容 |
| :--- | :--- |
| **优先级** | P0 |
| **前置条件** | 1. 监控进程具备监听系统服务管理器（ServiceManager）或 init 进程状态的能力。<br>2. 核心进程白名单配置已加载。 |
| **输入** | **触发源**：<br>1. Native 守护进程崩溃产生的 Tombstone 文件。<br>2. ServiceManager 发出的 `DeathRecipient` 通知。<br>3. init 进程发出的 `SIGCHLD` 信号。<br>**数据**：<br>1. 崩溃进程名称（Process Name）及 PID。<br>2. 进程退出状态码或终止信号。 |
| **处理逻辑** | 1. **核心识别**：<br>匹配崩溃进程名称是否在**核心白名单**中（如 `surfaceflinger`, `audioserver`, `netd`, `lmkd`）。若不在白名单，则视为普通 Native Crash 处理（参考 FR-STAB-003）。<br>2. **多源仲裁**：<br>优先使用 Tombstone 信息（包含详细堆栈），若未生成 Tombstone（如被系统强杀或 Watchdog 处决），则使用 ServiceManager 通知作为补充来源。<br>3. **等级判定**：<br>根据服务重要性标记故障等级（例如 SurfaceFlinger 崩溃标记为“致命”，会导致屏幕黑屏或系统软重启）。<br>4. **事件生成**：<br>组装核心服务崩溃事件，记录服务名称、崩溃时间及退出原因。 |
| **输出** | 1. **结构化事件**：生成包含服务名及影响等级的 `GVM_CORE_CRASH` 事件对象。<br>2. **本地日志**：关联该时间点附近的系统日志（Logcat）与崩溃堆栈。<br>3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》 |

##### FR-STAB-009 系统低内存 (LMK) 事件监控

| 属性 | 内容 |
| :--- | :--- |
| **优先级** | P0 |
| **前置条件** | 1. 系统启用 Low Memory Killer 机制（如 Userspace LMKD）。<br>2. 监控组件具备接收系统内存管理模块通知的权限。 |
| **输入** | **触发源**：<br>系统内存管理守护进程（lmkd）执行的**进程查杀动作**。<br>**数据**：<br>1. 目标进程信息（PID、UID、Process Name）。<br>2. 查杀时的决策依据（OOM Score Adj）。<br>3. 触发查杀时的系统内存压力状态（Memory Pressure State / PSI）。 |
| **处理逻辑** | 1. **动作捕获**：<br>实时感知 LMK 的查杀行为。**推荐方案**：采用源码插桩（Instrumentation）方式，在 `lmkd` 执行 kill 操作的原子逻辑处植入通知钩子，以获取零延迟、高精度的上下文信息；（备选方案：监听 EventLog 中的 `lmk_kill` 标签）。<br>2. **水位快照**：<br>同步记录系统当前的内存水位详情（MemTotal, MemFree, SwapUsed, Cached），用于后续分析是物理内存耗尽还是虚拟内存（Swap）耗尽。<br>3. **聚合去噪**：<br>执行时间窗口聚合策略。由于内存压力常导致短时间内连续查杀多个进程，需将同一压力波峰内（如 1 秒）的一组查杀事件聚合，避免产生告警风暴。<br>4. **严重性判定**：<br>识别被杀进程的类型。若被杀进程为前台可见应用或关键服务，标记为“高影响”事件。 |
| **输出** | 1. **结构化事件**：生成包含被杀进程列表及内存水位的 `GVM_SYS_LMK` 事件对象。<br>2. **本地日志**：保留查杀时刻的 `meminfo` 快照。<br>3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》 |

##### FR-STAB-010 Binder 通信异常监控

| 属性 | 内容 |
| :--- | :--- |
| **优先级** | P1 |
| **前置条件** | 1. 监控探针具备访问内核 Binder 驱动节点或 Hook `libbinder` 的能力。<br>2. 监控配置已定义 Binder 线程池水位的告警阈值。 |
| **输入** | **触发源**：<br>1. Binder 驱动层的**事务失败信号**（如 `BR_FAILED_REPLY`, `BR_DEAD_REPLY`）。<br>2. 进程 Binder 线程池的**资源耗尽状态**。<br>**数据**：<br>1. 通信双方身份（Caller PID/UID, Callee PID/UID）。<br>2. 接口描述符（Interface Descriptor）或事务代码（Transaction Code）。<br>3. 失败原因（如 `TransactionTooLarge`, `DeadObject`, `Timeout`）。 |
| **处理逻辑** | 1. **异常捕获**：<br>监测 IPC 通信链路健康度。**推荐方案**：在 Native `libbinder` 层进行插桩，拦截 `IPCThreadState` 中的错误返回码，从而在第一现场捕获异常。<br>2. **资源枯竭识别 (Starvation)**：<br>周期性或事件驱动地检查关键进程的 Binder 线程池状态。若活跃线程数达到上限（默认 16）且仍有请求积压，判定为 **Binder 线程耗尽**。<br>3. **大负载识别**：<br>识别 `TransactionTooLargeException`，记录传输过大数据的接口名称，辅助排查跨进程传输大图或大列表导致的性能问题。<br>4. **链路还原**：<br>在异常发生时，自动解析并记录“谁调用谁”（Client -> Server），明确责任方。 |
| **输出** | 1. **结构化事件**：生成包含通信双方及错误类型的 `GVM_BINDER_ERROR` 事件对象。<br>2. **本地日志**：记录 `/sys/kernel/debug/binder/transaction_log` (若可用) 或相关 Logcat 片段。<br>3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》 |

##### FR-STAB-011 文件句柄 (FD) 泄漏监控

| 属性 | 内容 |
| :--- | :--- |
| **优先级** | P1 |
| **前置条件** | 1. 监控探针具备读取 `/proc/[pid]/fd` 目录或执行 `lsof` 类指令的权限。<br>2. 针对不同类型的进程（System/App）配置了相应的 FD 数量告警阈值。 |
| **输入** | **触发源**：<br>1. **周期性采样**：定时检查系统内进程的资源占用情况。<br>2. **被动触发**：捕获到系统日志中抛出的 `EMFILE` ("Too many open files") 错误信号。<br>**Data**：<br>1. 目标进程当前打开的文件句柄总数。<br>2. 具体的句柄指向路径（Symlinks in `/proc/pid/fd/`）。 |
| **处理逻辑** | 1. **水位监测**：<br>对关键进程进行周期性（如每 5 分钟）的 FD 数量扫描。对比系统设定的软限制（Soft Limit）与硬限制（Hard Limit）。<br>2. **超限识别**：<br>当某进程 FD 数量超过预警阈值（例如 > 800 或占比 > 80%）时，判定为存在泄漏风险。<br>3. **现场快照**：<br>在检测到超限瞬间，遍历该进程的 `/proc/[pid]/fd/` 目录，生成句柄分布快照。**智能分类**：统计不同类型句柄的占比（如 Socket, Anon_inode, Regular File），快速定位是网络连接泄漏还是文件未关闭。<br>4. **趋势分析**：<br>结合历史数据，识别 FD 数量是否呈“持续上升且不回落”的阶梯状趋势，以排除正常的业务并发高峰。<br> |
| **输出** | 1. **结构化事件**：生成包含 FD 总数及分类统计的 `GVM_FD_LEAK` 事件对象。<br>2. **本地日志**：保留 top N 的句柄路径列表（Evidence List）。<br>3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》 |

#### 异构运行环境监控

##### FR-STAB-012 Linux Host (PVM) 重启与状态监控

| 属性 | 内容 |
| :--- | :--- |
| **优先级** | P0 |
| **前置条件** | 1. PVM (Linux Host) 侧已部署 Host Daemon 并具备读取系统启动日志（如 `/sys/fs/pstore` 或 systemd journal）的权限。<br>2. PVM 与 GVM 之间的跨域通信通道在启动后能够建立连接。 |
| **输入** | **触发源**：<br>1. **PVM 启动完成**：Host Daemon 随系统启动初始化。<br>2. **连接建立**：PVM 与 GVM 建立首次握手成功。<br>**数据**：<br>1. PVM 本次启动原因（Boot Reason）。<br>2. 历史持久化日志（上一周期的 Kernel Panic Log 或 Watchdog 记录）。<br>3. 实时心跳报文。 |
| **处理逻辑** | 1. **启动回溯（Post-Boot Analysis）**：<br>Host Daemon 在 PVM 启动初期，检查持久化存储中的上一次关机状态。识别是**正常关机**、**掉电**还是**异常重启**（如 Kernel Panic 导致的 WDT Reset）。<br>2. **事件缓存**：<br>若判定为异常重启，Host Daemon 生成重启事件对象并暂存于本地内存或磁盘队列中，等待跨域通道就绪。<br>3. **延迟同步（Delayed Sync）**：<br>当监测到 GVM (Android) 侧的 `PolarisNativeDaemon` 上线并建立连接后，立即将缓存的“上一次重启事件”发送给 GVM。<br>4. **运行时状态监测**：<br>在连接建立后的运行期间，Host Daemon 周期性向 GVM 发送心跳包与健康度状态（如 Systemd Failed Units），供 GVM 侧记录实时趋势。 |
| **输出** | 1. **结构化事件**：生成 `PVM_SYS_RESTART`（携带重启原因的历史事件）或 `PVM_STATUS_REPORT`（运行时状态）。<br>2. **本地日志**：在 PVM 侧保留原始的重启原因分析日志。<br>3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》 |

##### FR-STAB-013 MCU 故障码与心跳监控

| 属性 | 内容 |
| :--- | :--- |
| **优先级** | P1 |
| **前置条件** | 1. 硬件抽象层（HAL）或驱动层已完成 MCU 通信协议适配。<br>2. 监控守护进程（Native Daemon）具备读取 MCU 状态接口的权限。 |
| **输入** | **触发源**：<br>1. MCU 周期性上报的**状态报文**（Status Message）。<br>2. 硬件中断或底层驱动回调。<br>**数据**：<br>1. 存活心跳计数器（Rolling Counter）。<br>2. 硬件诊断故障码（DTC - Diagnostic Trouble Code）。<br>3. 外设关键状态字（如电源模式、复位原因）。 |
| **处理逻辑** | 1. **存活判定**：<br>通过监测心跳计数器的连续性和变化率来判断 MCU 状态。若计数器在设定时间窗口（**TBD**）内停止跳变或非法跳变，判定为 **MCU 挂死或通信中断**。<br>2. **协议映射**：<br>建立 MCU 原始故障码与平台统一错误定义的映射表。将厂商特定的十六进制 DTC（如 `0x1234`）转换为可读的平台标准错误码（如 `ERR_MCU_PMIC_FAIL`）。<br>3. **信号去抖**：<br>对偶发的故障信号进行软件滤波（De-bounce）。只有在连续 N 帧报文中确认同一故障码，或故障持续时长超过阈值时，才确认为有效故障，防止因总线干扰导致的误报。<br>4. **复位检测**：<br>监测 MCU 的复位原因寄存器。若发现异常复位标识（如 WDT Reset），记录异常复位事件。 |
| **输出** | 1. **结构化事件**：生成 `MCU_HEARTBEAT_LOST`（失联）或 `MCU_HARDWARE_FAULT`（硬件故障）事件对象。<br>2. **本地日志**：记录原始报文数据（Raw Data）以便后续校验。<br>3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》 |

##### FR-STAB-014 异构关键进程 (PVM Critical Process) 稳定性监控

| 属性 | 内容 |
| :--- | :--- |
| **优先级** | P0 |
| **前置条件** | 1. 目标关键进程（如 Audio Server, Display Composer, GSL HAL 等）已在 Host 侧启动。<br>2. Polaris Host Daemon 具备对目标进程状态的查询或监听权限。 |
| **输入** | **触发源**：<br>1. 操作系统（Linux Host）发出的**进程终止信号**（如 SIGCHLD）。<br>2. 服务管理框架（如 Systemd）抛出的**服务状态变更通知**（Service Unit Status Change）。<br>3. 目标进程输出到标准错误流（Stderr）的**致命错误日志**。<br>**数据**：<br>1. 进程标识（PID, Process Name, Unit Name）。<br>2. 退出状态码（Exit Code）或终止信号（Signal）。 |
| **处理逻辑** | 1. **通用监听**：<br>采用非侵入式手段实时感知关键进程的生命周期。针对受 Systemd 托管的服务，订阅其 D-Bus 状态变更信号；针对独立进程，采用 PID 存活轮询或父进程信号监听机制。<br>2. **状态判定**：<br> - **异常退出**：识别进程非预期的终止（Exit Code != 0）。<br> - **僵死/挂起**：若具备条件，监测进程是否长时间处于 D 状态（Uninterruptible Sleep）或对心跳接口无响应。<br>3. **抖动抑制 (Flapping Detection)**：<br>针对具有“自动重启”机制的关键服务，在设定时间窗口内（如 10秒）若检测到多次反复重启，应将其聚合为单次“服务抖动”事件上报，防止告警风暴。<br>4. **现场记录**：<br>在进程崩溃瞬间，尝试捕获其最后输出的标准错误日志（Stderr）或 Journalctl 片段，作为归因线索。 |
| **输出** | 1. **结构化事件**：生成包含进程名、退出码及故障频次的 `PVM_PROCESS_CRASH` 事件对象。<br>2. **本地日志**：Host 侧保留相关的系统日志片段。<br>3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》 |

##### FR-STAB-015 温度监控

| 属性 | 内容 |
| :--- | :--- |
| **优先级** | P1 |
| **前置条件** | 1. 系统底层具备热管理子系统（Thermal HAL / Thermal Daemon）。<br>2. 监控探针具备读取 `/sys/class/thermal` 节点或订阅 `IThermalService` 回调的权限。 |
| **输入** | **触发源**：<br>1. **被动接收**：Thermal HAL 上报的热状态变更回调（如 `onStatusChanged`）。<br>2. **主动采样**：周期性读取关键热区（Thermal Zone）的温度传感器数值。<br>**数据**：<br>1. 热区名称（Zone Name, 如 `cpu`, `gpu`, `battery`, `soc`）。<br>2. 当前温度值（Temperature in m°C）。<br>3. 热状态等级（Thermal Status: NONE, LIGHT, MODERATE, SEVERE, CRITICAL, SHUTDOWN）。 |
| **处理逻辑** | 1. **状态监听**：<br>实时订阅系统热管理服务的状态变更通知。一旦热状态跨越阈值（例如从 `NONE` 变为 `SEVERE`），立即触发记录逻辑。<br>2. **降频关联**：<br>当检测到温度过高触发温控策略（Throttling）时，尝试关联当前的 CPU/GPU 频率限制状态，以解释可能伴随发生的卡顿或掉帧现象（辅助性能分析）。<br>3. **危急保护记录**：<br>当收到 `SHUTDOWN` 级别的热信号时，视为“过热关机前兆”，必须以最高优先级将当前温度快照写入持久化存储，作为系统异常重启（FR-STAB-006）的直接归因证据。<br>4. **趋势采样**：<br>在非危急状态下，按低频（如每 5 分钟）采样 SoC 核心温度，用于绘制温度变化趋势图。 |
| **输出** | 1. **结构化事件**：生成 `GVM_SYS_THERMAL_EVENT`（包含热区名称、温度值及温控等级）。<br>2. **本地日志**：保留过热时刻的 `thermalservice` 状态或相关节点快照。<br>3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》 |


### 性能与资源度量能力

#### 交互体验量化

##### FR-PERF-001 应用启动耗时 (App Launch Time) 监控

| 属性 | 内容 |
| :--- | :--- |
| **优先级** | P1 |
| **前置条件** | 1. 监控探针已 Hook 或插桩至 AMS 启动流程及 Activity 生命周期关键回调。<br>2. 目标应用白名单已配置。 |
| **输入** | **触发源**：<br>应用进程创建及 Activity 界面绘制完成信号。<br>**数据**：<br>1. **启动类型**：冷启动 (Cold)、热启动 (Hot/Warm)。<br>2. **关键时间戳**（仅采集内存中的系统时钟 `SystemClock.uptimeMillis()`）：<br> - `T0`: Intent 发送/用户点击图标时刻。<br> - `T1`: 进程创建成功 (Process Forked)。<br> - `T2`: 应用页面初始化 (`Activity.onCreate/onStart`)。<br> - `T3`: 首帧绘制完成 (ReportFullyDrawn / Window Focus)。 |
| **处理逻辑** | 1. **零干扰采集**：<br>在启动的关键路径上，**严禁**执行任何文件读取、复杂的字符串处理或 IPC 调用。仅在内存中记录长整型时间戳，确保监控逻辑对应用启动速度的影响趋近于零。<br>2. **端到端计算**：<br>启动结束后，异步计算总耗时及分段耗时：<br> - **系统调度耗时 (T1 - T0)**：反映系统资源紧张程度或 Zygote 响应速度。<br> - **应用初始化耗时 (T2 - T1)**：反映 Application 级初始化逻辑耗时。<br> - **页面渲染耗时 (T3 - T2)**：反映 Activity 布局加载与渲染耗时。<br>3. **异常判定与分级上报**：<br> - **正常启动**：总耗时未超过基线。上报事件，但留空诊断字段。<br> - **慢启动**：总耗时超过基线。标记 `status=SLOW`，并触发关联逻辑。<br>4. **关联归因 (Correlation)**：<br>仅针对“慢启动”事件进行事后时间窗口匹配：<br> - **主线程阻塞**：检索启动期间是否触发了 **FR-PERF-002** (主线程卡顿) 事件。<br> - **资源竞争**：检索启动期间系统整体 LoadAvg 或 IO 负载是否处于高位 (由 **FR-PERF-004** 采集)。 |
| **输出** | 1. **结构化事件**：生成 `GVM_APP_LAUNCH` 事件。<br> - **必选字段**：应用名、启动类型、总耗时、分段耗时、状态(Normal/Slow)。<br> - **可选字段**（仅 Slow 状态填充）：关联的异常事件 ID (Ref_Event_ID)、Trace 索引。 |

##### FR-PERF-002 主线程响应与健康度监控

| 属性 | 内容 |
| :--- | :--- |
| **优先级** | P1 |
| **前置条件** | 1. 监控探针已集成至目标应用主线程 Looper。<br>2. 监控配置中定义了卡顿阈值（如 `BlockThreshold = 200ms`）。 |
| **输入** | **触发源**：<br>主线程 Looper 分发消息（Message Dispatch）的开始与结束时刻。<br>**数据**：<br>1. **消息执行耗时**：墙钟耗时 (Wall Duration) 与 线程 CPU 耗时 (Thread CPU Duration)。<br>2. **消息签名**：目标 Handler 类名、Runnable 类名或 Message.what 标识。<br>3. **队列状态**：MessageQueue 当前积压的消息数量 (Pending Count)。 |
| **处理逻辑** | 1. **双重计时监测**：<br>在消息分发前后打点。**关键逻辑**：同时记录“墙钟时间”和“CPU 时间”。<br> - 若墙钟时间长且 CPU 时间长 $\rightarrow$ **计算密集型卡顿** (算法复杂、大循环)。<br> - 若墙钟时间长但 CPU 时间短 $\rightarrow$ **IO/锁等待型卡顿** (主线程读写磁盘、Binder 阻塞、等锁)。<br>2. **堆栈抓取 (Sample & Dump)**：<br>采用“看门狗”机制。当检测到当前消息执行已超过阈值（如 > 200ms）但在结束前，**主动抓取**主线程瞬时堆栈。避免等消息执行完再抓取导致“现场已过”的问题。<br>3. **拥堵识别 (Congestion)**：<br>即使单条消息未超时，若 MessageQueue 待处理消息数持续超过阈值（如 > 50个），判定为**调度拥堵**。记录拥堵期间的“头部分发者” (Top Senders)。<br>4. **聚合去噪**：<br>对短时间内连续发生的相同堆栈/相同签名的卡顿事件进行聚合，仅上报一次并附带发生次数 (Count)。 |
| **输出** | 1. **结构化事件**：生成 `GVM_APP_MAIN_THREAD_BLOCK` 事件。<br> - **字段**：应用名、卡顿类型(CPU/Wait)、耗时、消息签名、堆栈摘要(StackHash)。<br>2. **本地日志**：记录完整的卡顿堆栈 (Full Stack Trace) 及当时的消息队列快照。 <br> 3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》|

##### FR-PERF-003 界面流畅度 (UI Jank/FPS) 监控

| 属性 | 内容 |
| :--- | :--- |
| **优先级** | P1 |
| **前置条件** | 1. 监控探针已通过 `Window.addOnFrameMetricsAvailableListener` 注册监听。<br>2. 目标应用处于前台可见状态。 |
| **输入** | **触发源**：<br>系统 `FrameMetrics` 回调。<br>**数据**：<br>1. **核心耗时**：`TOTAL_DURATION`, `DEADLINE`。<br>2. **归因耗时**：UI 相关 (`LAYOUT`, `DRAW`...), GPU 相关 (`GPU_DURATION`, `SWAP`...)。 |
| **处理逻辑** | 1. **生命周期聚合**：<br>以页面会话（onResume -> onPause）为单位进行统计，**不上报单帧数据**。<br>2. **轻量级计算**：<br> - **计数**：统计总帧数 (`total`)、掉帧数 (`jank`, Total > Deadline)、冻结帧数 (`frozen`, Total > 700ms)。<br> - **极值**：记录会话期间的最大帧耗时。<br> - **均值**：累加 UI 耗时与 GPU 耗时，计算平均每帧的 CPU/GPU 开销分布。<br>3. **异常判定**：<br>若掉帧率超过阈值（如 10%）或存在冻结帧，标记 `is_laggy=true`。 |
| **输出** | 1. **结构化事件**：`GVM_APP_JANK_STATS`。<br> - **字段**：`activity_name`, `total_frames`, `jank_count`, `frozen_count` (冻结帧数), `max_frame_ms`, `avg_ui_ms`, `avg_gpu_ms`。<br> - **作用**：云端可直接计算出“某页面的平均掉帧率”以及“卡顿主要是因为 UI 逻辑还是 GPU 渲染”。 <br> 2. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》|

#### 资源水位画像

##### FR-PERF-004 进程 CPU 负载监控

| 属性 | 内容 |
| :--- | :--- |
| **优先级** | P1 |
| **前置条件** | 1. Android/Host 端监控进程具备 `/proc` 读取权限。<br>2. 跨域通信通道正常。 |
| **输入** | **触发源**：<br>定时器触发（端侧采样周期：30秒）。<br>**数据源**：<br>解析 `/proc/stat` (System) 和 `/proc/[pid]/stat` (Process)。**严禁**使用 top 命令。 |
| **处理逻辑** | 1. **端侧高频采样**：<br>每 **30秒** 采集一次快照，计算瞬时系统总负载及各进程负载。不立即上报，暂存内存。<br>2. **长周期聚合 (Long-Term Aggregation)**：<br>每 **30分钟** 为一个常规上报周期（包含 60 个采样点）。<br> - **计算均值**：计算该 30 分钟内的系统平均负载。<br> - **锁定峰值**：找出该周期内负载最高的那个时间点（Peak Snapshot），并提取该时刻的 Top 5 进程。<br>3. **异常快速通道 (Immediate Alert)**：<br>在每次采样后进行实时判断。若检测到**系统总负载 > 80% 且持续 2 个采样周期（1分钟）**，则**绕过** 30分钟的聚合等待，**立即触发**一条异常告警事件。<br>4. **跨域打包**：<br>Linux Host 端数据通过跨域通道透传至 Android 端，统一打标 `domain` (ANDROID/HOST) 后上传。 |
| **输出** | 1. **结构化事件**：`GVM_SYS_CPU_TOP`。<br> - **频率**：30分钟/次 (常规) 或 立即 (异常)。<br> - **字段**：`timestamp`, `sys_load_avg` (30min均值), `sys_load_peak` (峰值), `top_processes` (峰值时刻的 Top 5 列表)。<br>2. **流量预估**：约 20KB/天/车 (极低)。 <br> 3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》|

##### FR-PERF-005 进程内存消耗监控

| 属性 | 内容 |
| :--- | :--- |
| **优先级** | P1 |
| **前置条件** | 1. Android/Host 端监控进程具备 `/proc` 读取权限。<br>2. `/log/perf/meminfo/` 目录已创建且具备写权限。 |
| **输入** | **触发源**：<br>定时器触发（端侧采样周期：30秒）。<br>**数据源**：<br>1. **全局水位**：读取 `/proc/meminfo` (关注 `MemAvailable`)。<br>2. **进程水位**：读取 `/proc/[pid]/statm` (关注 `RSS` - Resident Set Size)。 |
| **处理逻辑** | 1. **端侧高频采样**：<br>每 **30秒** 读取一次全局内存及所有活跃进程的 RSS。<br>2. **长周期聚合 (30min Window)**：<br>每 **30分钟** 为一个上报周期。<br> - **系统趋势**：记录周期内 `MemAvailable` 的最低点。<br> - **Top 进程**：找出周期内 `RSS` 峰值最高的 Top 5 进程。<br> - **异常膨胀识别**：计算进程在周期首尾的差值 ($\Delta RSS = RSS_{End} - RSS_{Start}$)。若净增量 > **200MB** (可配置)，标记为异常。<br>3. **异常快速通道 (Immediate Alert)**：<br> - **系统持续高压**：若 `MemAvailable / MemTotal <` **20%** 且持续时长 > **3分钟**，判定为内存紧张，**立即上报**。<br> - **进程大内存**：若某非白名单进程 `RSS > 1GB` (或配置阈值) 且持续 > **3分钟**，判定为异常占用，**立即上报**。<br> - **现场固化**：触发上述任一条件时，立即执行 `dumpsys meminfo [pid]` 并写入日志文件。 |
| **输出** | 1. **本地日志 (Local Dump)**：<br> - **路径**：`/log/perf/meminfo/`。<br> - **文件名格式**：`{process_name}_{pid}_{timestamp}.txt` (注：进程名中的 `:` 需替换为 `_`，如 `com_android_systemui`)。<br> - **内容**：完整的 `dumpsys meminfo` 文本输出 (包含 Java Heap, Native Heap, Graphics 等 PSS 详情)。<br>2. **结构化事件**：`GVM_PROC_MEM_TOP`。<br> - **频率**：30分钟/次 (常规) 或 立即 (异常)。<br> - **字段**：`timestamp`, `sys_mem_available_min` (MB), `top_processes` (List: name, pid, rss_peak_mb, rss_growth_mb)。<br> - **关联字段**：`logf` (值为上述生成的日志文件名。仅在触发快速通道时填充，常规上报为空)。 <br> 3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》|

##### FR-PERF-006 进程磁盘 I/O 吞吐量与系统压力监控

| 属性 | 内容 |
| :--- | :--- |
| **优先级** | P1 |
| **前置条件** | 1. Android/Host 端监控进程具备读取 `/proc/[pid]/io` 及 `/proc/stat` 的权限。<br>2. 内核配置开启 `TASK_IO_ACCOUNTING` 选项。 |
| **输入** | **触发源**：<br>定时器触发（端侧采样周期：30秒）。<br>**数据源**：<br>1. **进程 I/O**：读取 `/proc/[pid]/io` (`read_bytes`, `write_bytes`)。<br>2. **系统 I/O 压力**：读取 `/proc/stat` (用于计算全局 `iowait`)。 |
| **处理逻辑** | 1. **端侧高频采样**：<br>每 **30秒** 遍历活跃进程计算 I/O 增量，同时记录系统 `iowait` 快照。<br>2. **长周期聚合 (30min Window)**：<br>每 **30分钟** 为一个上报周期。<br> - **系统压力**：利用周期初和周期末的 `/proc/stat` 快照，计算该 30分钟内的**平均 `iowait`**。<br> - **累计总量**：计算周期内所有进程的总写入量。<br> - **Top 进程**：找出周期内 **I/O 吞吐量** 最高的 Top 5 进程。<br>3. **异常快速通道 (Immediate Alert)**：<br> - **高负载写入**：若某进程写速 > **10MB/s** (可配置) 且持续 > **1分钟**，判定为“异常写入 (Abnormal Write)”，**立即上报**。<br> - **高负载读取**：若某进程读速 > **50MB/s** (可配置) 且持续 > **1分钟**，判定为读取密集，可能导致界面卡顿 (ANR)，**立即上报**。<br> - **I/O 阻塞**：若系统全局 `iowait` > **40%** (可配置) 且持续 > **1分钟**，判定为磁盘性能瓶颈，**立即上报**。<br>4. **跨域打包**：<br>Linux Host 端数据透传至 Android 端合并上报。 |
| **输出** | 1. **结构化事件**：`GVM_PROC_IO_TOP`。<br> - **频率**：30分钟/次 (常规) 或 立即 (异常)。<br> - **字段**：`timestamp`, `sys_iow_avg` (平均IO等待率 %), `total_write_mb` (周期总写量), `top_processes` (List: name, pid, read_rate_mbps, write_rate_mbps)。<br>2. **本地日志**：触发异常时，记录 `/proc/[pid]/io` 快照及 `/proc/stat` 详情。<br>3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》|

#### 系统级性能监控

##### FR-PERF-007 系统冷启动耗时 (Cold Boot) 监控

| 属性 | 内容 |
| :--- | :--- |
| **优先级** | P2 |
| **前置条件** | 1. **Host 端**: 集成 `bootchart`，并将解析出的内核/用户态启动耗时传递给 Android。<br>2. **Android 端**: 能够接收 Host 数据，且能访问本地日志目录。 |
| **输入** | **触发源**：<br>接收到 `BOOT_COMPLETED` 广播。<br>**数据源**：<br>1. **Linux**: Host 侧 `bootchart` 统计时长。<br>2. **Android**: `SystemClock.uptimeMillis()`。 |
| **处理逻辑** | 1. **计算总耗时**：<br> $Total = T_{Linux} + T_{Android}$。<br>2. **本地落盘**：<br>无论是否超时，将本次启动的耗时数据记录在本地数据库/日志中，并保留 Host 传输过来的 `bootchart.tgz` 文件。<br>3. **异常上报**：<br>若 $Total >$ **30s**，触发云端上报，并携带 bootchart 日志路径。 |
| **输出** | 1. **结构化事件**：`GVM_BOOT_COLD`<br> - **字段 (极简)**：<br>   - `dur` (Int): 总耗时 (ms)<br>   - `lin` (Int): Linux Host 耗时 (ms)<br>   - `logf` (Str): 关联的日志文件名 (如 `bootchart_20251020.tgz`)<br>2. **本地日志**：保留 Linux 生成的 bootchart 压缩包。<br> 3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》 |

##### FR-PERF-008 系统热唤醒耗时 (STR Resume) 监控

| 属性 | 内容 |
| :--- | :--- |
| **优先级** | P2 |
| **前置条件** | 1. 监控服务有权限读取 Kernel 唤醒中断时间戳。<br>2. 监控服务能捕获 Android 界面首帧绘制信号 (First Frame)。 |
| **输入** | **触发源**：<br>STR 唤醒流程结束，屏幕点亮。<br>**数据源**：<br>1. **起点**: Kernel 接收到唤醒中断 (IRQ) 的时间戳。<br>2. **终点**: Android 界面第一帧绘制完成 (SurfaceFlinger/WindowManager) 的时间戳。 |
| **处理逻辑** | 1. **计算耗时**：<br> $Duration = T_{FirstFrame} - T_{WakeupIRQ}$。<br>2. **异常上报**：<br>若 $Duration >$ **5s**，判定为唤醒过慢，触发云端上报。<br>3. **现场固化**：<br>仅在超时时，抓取当前的 Kernel Log (`dmesg`) 和 Android Log (`logcat -b events`) 片段写入文件，用于分析是驱动阻塞还是应用渲染慢。 |
| **输出** | 1. **结构化事件**：`GVM_BOOT_STR`<br> - **字段 (极简)**：<br>   - `dur` (Int): 唤醒总耗时 (ms)<br>   - `logf` (Str): 关联的日志文件名 (如 `str_trace_20251020.txt`)<br>2. **本地日志**：包含唤醒时间段内的 `dmesg` 和关键系统日志。 <br> 3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》|

##### FR-PERF-009 全局存储健康度与多分区空间监控

| 属性 | 内容 |
| :--- | :--- |
| **优先级** | P1 |
| **前置条件** | 1. 监控服务持有需监控的分区白名单配置（如 `["/data", "/mnt/camera", "/log"]`）及其各自的报警阈值（如 Camera > 95%, Data > 90%）。<br>2. 具备读取 UFS/eMMC 硬件寿命寄存器及执行 `statfs` 的权限。 |
| **输入** | **触发源**：<br>定时器触发（端侧采样周期：**15分钟**）。<br>**数据源**：<br>1. **硬件寿命**：UFS/eMMC `Life Time Estimation` (Type A/B)。<br>2. **分区空间**：遍历白名单中的每个挂载点，使用 `statfs` (系统调用) 获取 Total/Used/Free 块数量。 |
| **处理逻辑** | 1. **空间写满判定**：<br> - **低频采样**：每 15 分钟检查一次各分区使用率。<br> - **防抖确认**：若发现某分区使用率 > 阈值，**立即在 60秒后进行第二次采样**。<br> - **异常触发**：若两次采样均超标，标记为“写满确诊”，**立即上报**异常事件。<br>2. **硬件寿命监测**：<br>每天检查一次。若 Life A/B $\ge$ **0x09** (90%)，标记为“寿命耗尽”，**立即上报**。<br>3. **长周期聚合**：<br>每 **30分钟** (即每 2 个采样周期) 上报一次常规状态。<br> - 打包所有被监控分区的当前使用率快照。 |
| **输出** | 1. **结构化事件**：`GVM_DISK_STAT`<br> - **Type字段**：`typ` (0=Routine, 1=Alert_Full, 2=Alert_EOL)<br> - **公共字段**：`la`/`lb` (寿命等级)<br> - **常规上报字段 (typ=0)**：<br>   `parts`: `[{"n":"data","u":45}, {"n":"camera","u":80}, {"n":"log","u":10}]` (n=name, u=usage%)<br> - **异常上报字段 (typ=1)**：<br>   `tgt`: `"camera"` (报警的具体分区名)<br>   `val`: `98` (当前使用率)<br>2. **本地日志**：仅在触发 Alert 时，执行 `df -h` 和 `du -sh *` 写入日志文件。<br>3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》|


### 现场还原与协同能力

#### FR-DIAG-001 标准化事件协议体系

系统对于上报事件应该具有统一规范的编码，具体编码规则参考 《Polaris 1.0 全局事件ID与注册表规范》。

#### FR-DIAG-002 智能现场快照

上报事件所产生的日志文件应该按照类型存放在指定的目录，参考 《Polaris 1.0 全局事件ID与注册表规范》。

#### FR-DIAG-003 远程诊断执行

| 属性 | 内容 |
| :--- | :--- |
| **优先级** | P1 |
| **目标** | 在不打扰用户的前提下，通过云端下发安全指令获取更深度的系统运行时信息。 |
| **前置条件** | 1. 端云建立安全加密指令通道。<br>2. **密钥预置**：端侧 Agent 已预置用于验签的云端公钥。<br>3. **安全状态**：部分交互类指令仅允许在非行车状态下执行。 |
| **输入** | **触发源**：<br>云端下发的诊断指令包 `CMD_EXEC_DIAG`。<br>**参数**：<br>`cmd_code` (指令码), `params` (参数列表), `request_id` (云端生成的唯一追踪ID), `timestamp`, `sign` (数字签名)。 |
| **处理逻辑** | 1. **安全沙箱校验**：<br> - **验签策略**：Agent 使用内置公钥验证 `sign`，确保指令未被篡改。<br> - **防重放**：校验 `timestamp` 有效性，并检查 `request_id` 是否已处理过。<br> - **白名单过滤**：**严禁**直接执行 `eval(raw_shell)`。仅允许执行预埋的**标准化指令集**。<br>2. **指令执行**：<br>在独立的子进程中执行对应逻辑，设置硬性超时时间（如 5s）。<br>3. **结果截取与落盘**：<br>捕获标准输出 (`stdout`) 和标准错误 (`stderr`)。<br> - **数据**：输出内容写入本地文件。<br>   - **存储目录**：`/log/perf/diag/`<br>   - **命名规则**：`diag_{cmd_code}_{request_id}_{timestamp}.txt`<br>   - **返回数据**：Payload 中**仅返回生成的文件名**（如 `diag_PING_req123_170982.txt`），后续由 VlmAgent 根据文件名及预置路径策略进行拉取。<br>4. **审计记录**：<br>将执行记录写入本地安全审计日志。 |
| **输出** | 1. **结构化事件**：`GVM_DIAG_RESULT`<br> - **字段**：`req_id` (回传云端下发的ID), `code` (0=Success, 1=Fail), `output` (小数据结果内容), `logf` (大数据结果的文件名)。<br>2. **本地日志**：`/log/perf/diag/` 下的诊断结果文件。<br>3. 详细结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》 |


### 数据智能与运营能力

#### FR-DATA-001 端云数据关联与检索

| 属性 | 内容 |
| :--- | :--- |
| **优先级** | P0 (核心能力) |
| **目标** | 消除人工查找日志的成本。确保研发人员在查看报警详情时，能够直接获取到故障现场的日志文件，实现“所见即所得”。 |
| **输入数据** | 1. **结构化事件**：包含 `evid` (事件ID), `vin`, `timestamp`, `logf` (关联的日志文件名) 等字段。<br>2. **日志文件**：端侧 VlmAgent 上传至对象存储的 ZIP/TXT 文件。 |
| **业务处理规则** | 1. **自动关联逻辑**：<br>平台需建立自动化索引机制。当接收到结构化事件时，读取其 `logf` 字段，以此为 Key 在存储桶中查找对应的文件。无论“事件先到”还是“文件先到”，最终必须在界面上实现绑定。<br>2. **生命周期管理**：<br>普通日志文件默认保留 **30天**，高危/严重级别的故障日志保留 **180天**。过期后自动清理以节省存储成本。 |
| **功能/展示要求** | **Event详情页**：<br> - **日志区域**：在事件详情页必须包含显著的“关联日志附件”板块。<br> - **状态展示**：<br> 若文件尚未上传完毕，显示状态为 `上传中...` <br>若文件已就绪，显示文件大小（如 5MB），并提供 **[下载]** 按钮。|

#### FR-DATA-002 实时预警与消息推送

| 属性 | 内容 |
| :--- | :--- |
| **优先级** | P0 |
| **目标** | 建立从“故障发生”到“责任人获知”的分钟级自动化闭环，确保高危问题被即时响应。 |
| **业务处理规则** | 1. **灵活阈值策略**：<br> - 支持自定义报警规则（固定阈值或环比突增）。<br>2. **智能路由**：<br> - 自动读取《全局事件注册表》中的 `Owner` 字段。<br> - 维护“Owner - 飞书群/个人ID”映射关系表，实现报警精准派单。 |

#### FR-DATA-003 核心指标统计与报表

| 属性 | 内容 |
| :--- | :--- |
| **优先级** | P0 |
| **目标** | 提供多维度的质量大盘报表，支持日报、周报、月报的自动统计与趋势分析，覆盖**千车严重故障率**与**应用崩溃率**。 |
| **统计维度** | 支持按 **车型**、**系统版本**、**时间周期** (日/周/月) 进行交叉筛选。 |
| **业务处理规则** | **1. 千车严重故障率**<br> - **定义**：每 1000 辆活跃车中，发生严重故障的车辆数。<br> - **严重故障集**：EventID 在开发过程中提供。<br> - **公式**：$$(\text{发生严重故障的去重VIN数} / \text{活跃去重VIN数}) \times 1000$$<br> - **精度**：保留整数。<br><br>**2. 应用崩溃率**<br> - **定义**：衡量应用运行的稳定性。<br> - **公式**：$$(\text{Crash事件总数} / \text{App启动事件总数}) \times 100\%$$<br> - **精度**：保留两位小数。 |
| **功能/展示要求** | **质量驾驶舱 (Dashboard)**：<br> - **核心卡片**：展示上述指标的当前值。<br> - **趋势分析**：展示 日环比趋势箭头（红色代表劣化，绿色代表改善）。 |


#### FR-DATA-004 稳定性专项分析工作台

| 属性 | 内容 |
| :--- | :--- |
| **优先级** | P1 |
| **目标** | 1. 提供 **应用稳定性黑榜**，快速识别 Crash/ANR 严重的组件。<br>2. 提供 **系统重启原因分析**，定位导致系统非预期重启的根因（如 Watchdog、Kernel Panic）。 |
| **业务处理规则** | **1. 应用稳定性聚合**：<br> - 以 `PackageName` (包名) 为维度，统计选定系统版本下的 Crash/ANR 总数与影响车数。<br>**2. 系统重启分类逻辑**：<br> - 依据 `boot_reason` 字段进行自动化分类。 boot_reason的详细分类在开发过程中提供。<br>**3. 排序策略**：<br> - 默认按 **“影响车数” 降序** 排列。<br>**4. 数据清洗**：<br> - 自动过滤白名单内的测试车辆数据。 |
| **功能/展示要求** | **一、 应用稳定性排行榜**：<br> - **列定义**：排名 \| 应用名称 \| 归属部门 \| Crash 影响车数 \| Crash 次数 \| ANR 影响车数 \| ANR 次数。<br><br>**二、 系统重启分析视图**：<br> - **分布饼图**：直观展示“正常重启”与“异常重启”的比例；点击“异常”扇区可联动下方列表。<br> - **重启原因列表**：<br>   * **列定义**：重启分类 (如 Watchdog) \| 具体原因 (boot_reason) \| **影响车数** \| 累计发生次数。<br><br>**三、 交互交互**：<br> - 点击应用或重启原因，跳转至对应的 **Event 详情页**，以便直接下载关联的日志文件。 |

#### FR-DATA-005 性能与体验专项分析工作台

| 属性 | 内容 |
| :--- | :--- |
| **优先级** | P1 |
| **目标** | 量化用户交互体验，通过 **应用掉帧 (Jank)** 与 **冻结 (Freeze)** 指标识别核心场景的性能瓶颈。 |
| **输入数据** | **源事件**：`GVM_APP_JANK_STATS`<br>**关键字段**：<br> - `activity_name` (页面名)<br> - `total_frames` (总帧数)<br> - `jank_count` (掉帧数)<br> - `frozen_count` (冻结帧数, >700ms)<br> - `avg_ui_ms` (平均UI耗时), `avg_gpu_ms` (平均GPU耗时) |
| **业务处理规则** | 1. **核心指标计算**：<br> - **平均掉帧率 (Jank Rate)**：$$(\sum \text{jank\_count} / \sum \text{total\_frames}) \times 100\%$$<br> - **页面冻结率 (Freeze Session Rate)**：衡量有多少次页面浏览发生了严重卡死。<br>   $$(\text{Count(Events where frozen\_count > 0)} / \text{Count(Total Events)}) \times 100\%$$<br> - **卡顿归因倾向 (Bottleneck Check)**：<br>   * 若 `avg_ui_ms` > `avg_gpu_ms`，标记为 **CPU/MainThread Bound** (主线程逻辑重)。<br>   * 若 `avg_gpu_ms` > `avg_ui_ms`，标记为 **GPU/Render Bound** (渲染负载重)。<br>2. **分位值统计**：<br> - 计算 **掉帧率 P90**：排除偶发波动，反映绝大多数用户的真实体验底线。 |
| **功能/展示要求** | **流畅度分析视图**：<br>1. **趋势分析**：<br> - 展示核心应用（如 Map, Launcher）的掉帧率 P90 趋势曲线。<br>2. **红黑榜 (Red/Black List)**：<br> - **最卡应用 Top 5**：按平均掉帧率降序。<br> - **最冻结页面 Top 10**：按页面冻结率降序。<br>3. **归因辅助**：<br> - 在榜单中显示“主要瓶颈”标签（如 <span style="color:red">CPU</span> / <span style="color:blue">GPU</span>），基于 UI/GPU 耗时均值自动判定。 |

## 非功能需求

## 端云交互协议设计

## 安全与隐私

## 风险 & 限制 & 依赖

## 实施计划

### 阶段划分

### 资源需求计划

## 附录