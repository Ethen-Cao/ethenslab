#!/usr/bin/python3
# -*- coding: utf-8 -*-

"""
æ”¶é›†æºç /é…ç½®æ–‡ä»¶åˆ°å•ä¸€æ–‡æœ¬ï¼Œä¾¿äº AI åˆ†æã€‚
å®‰å…¨å¢å¼ºï¼š
- è·³è¿‡è½¯é“¾ä¸éå¸¸è§„æ–‡ä»¶ï¼›é˜²ç›®å½•é€ƒé€¸ï¼ˆrealpath ä»é¡»åœ¨æ‰«ææ ¹å†…ï¼‰
- é¿å…è‡ªåƒè¾“å‡ºï¼ˆè·³è¿‡æ­£åœ¨å†™çš„è¾“å‡ºæ–‡ä»¶ï¼‰
- é»˜è®¤æ’é™¤å¸¸è§å¯†é’¥/è¯ä¹¦ç­‰æ•æ„Ÿåç¼€ï¼ˆå¯ç”¨ --unsafe å…³é—­ï¼‰
- æ›´ç¨³å¥äºŒè¿›åˆ¶åˆ¤å®šï¼ˆNUL + ä¸å¯æ‰“å°æ¯”ä¾‹ï¼‰
- ä½“é‡é™æµï¼š--max-bytes, --max-files
åŠŸèƒ½å¢å¼ºï¼š
- --types/-t æŒ‡å®šç±»å‹ï¼Œä»…æ”¶é›†åŒ¹é…çš„æ–‡ä»¶ï¼ˆYocto é…ç½®/é…æ–¹ã€è„šæœ¬ã€Python ç­‰ï¼‰
- --list-types æŸ¥çœ‹å¯ç”¨ç±»å‹ä¸åŒ¹é…è§„åˆ™
- --types-config è½½å…¥ JSON æ‰©å±•/è¦†ç›–ç±»å‹æ˜ å°„ï¼ˆexts/names/patterns/shebangsï¼‰
"""

import os
import sys
import time
import json
import fnmatch
import argparse
import stat
from typing import Set, List, Dict, Tuple

# ----------------- é»˜è®¤æ’é™¤è§„åˆ™ -----------------
EXCLUDE_DIRS: Set[str] = {
    '.git', '__pycache__', 'node_modules', 'build',
    'dist', 'target', '.vscode', '.idea', 'venv', '.env'
}

EXCLUDE_EXTS: Set[str] = {
    # ç¼–è¯‘äº§ç‰©
    '.pyc', '.pyo', '.o', '.so', '.a', '.dll', '.exe', '.class', '.jar',
    # å›¾ç‰‡
    '.png', '.jpg', '.jpeg', '.gif', '.bmp', '.ico', '.svg', '.webp',
    # éŸ³è§†é¢‘
    '.mp3', '.wav', '.mp4', '.mov', '.avi', '.mkv', '.flac',
    # å‹ç¼©/å½’æ¡£
    '.zip', '.tar', '.gz', '.rar', '.7z',
    '.xz', '.zst', '.zstd', '.lz4', '.lz', '.bz2', '.tgz', '.tbz', '.txz',
    # æ–‡æ¡£å’Œå­—ä½“
    '.pdf', '.doc', '.docx', '.xls', '.xlsx', '.ppt', '.pptx',
    '.eot', '.ttf', '.woff', '.woff2',
    # æ•°æ®åº“
    '.db', '.sqlite3'
}

# æ•æ„Ÿåç¼€ï¼ˆé»˜è®¤ä¹Ÿæ’é™¤ï¼Œå¯ç”¨ --unsafe å…³é—­ï¼‰
SENSITIVE_EXTS: Set[str] = {
    '.pem', '.der', '.crt', '.cer',
    '.key', '.pk8', '.p12', '.pfx',
    '.jks', '.keystore', '.asc', '.gpg'
}

# ----------------- å†…ç½®ç±»å‹æ˜ å°„ï¼ˆå¯è¢« --types-config è¦†å†™/æ‰©å±•ï¼‰ -----------------
FILE_TYPE_GROUPS: Dict[str, Dict[str, List[str]]] = {
    # å…¸å‹ Yocto/BitBake ç›¸å…³
    "yocto": {
        "exts": [".bb", ".bbappend", ".bbclass", ".inc", ".conf", ".wks", ".wic", ".wks.in"],
        "names": ["local.conf", "bblayers.conf", "layer.conf"],
        "patterns": ["conf/*.conf", "conf/*.inc", "*/conf/layer.conf", "*.bbmask"],
        "shebangs": []
    },
    # Shell è„šæœ¬
    "scripts": {
        "exts": [".sh", ".bash"],
        "names": [],
        "patterns": ["scripts/*", "*/scripts/*"],
        "shebangs": ["bash", "sh", "zsh"]
    },
    # Python
    "python": {
        "exts": [".py"],
        "names": [],
        "patterns": [],
        "shebangs": ["python"]
    },
    # CMake/Make
    "cmake": {
        "exts": [".cmake"],
        "names": ["CMakeLists.txt"],
        "patterns": [],
        "shebangs": []
    },
    "make": {
        "exts": [".mk"],
        "names": ["Makefile", "makefile", "GNUmakefile"],
        "patterns": [],
        "shebangs": []
    },
    # è¡¥ä¸
    "patches": {
        "exts": [".patch", ".diff"],
        "names": [],
        "patterns": [],
        "shebangs": []
    },
    # è®¾å¤‡æ ‘
    "dts": {
        "exts": [".dts", ".dtsi"],
        "names": [],
        "patterns": [],
        "shebangs": []
    },
    # INI/CFG
    "ini": {
        "exts": [".ini", ".cfg"],
        "names": [],
        "patterns": [],
        "shebangs": []
    }
}

# ----------------- å·¥å…·å‡½æ•° -----------------
def sanitize_for_header(s: str) -> str:
    """é¿å…æ–‡ä»¶åä¸­çš„æ§åˆ¶å­—ç¬¦ç ´ååˆ†éš”ç»“æ„ã€‚"""
    return s.replace('\n', '\\n').replace('\r', '\\r').replace('\t', '\\t')

def looks_binary_by_chars(buf: bytes) -> bool:
    """å¯å‘å¼ï¼šä¸å¯æ‰“å°å­—ç¬¦å æ¯”è¿‡é«˜è§†ä¸ºäºŒè¿›åˆ¶ã€‚"""
    if not buf:
        return False
    texty = sum((32 <= b <= 126) or b in (9, 10, 13) for b in buf)
    return (texty / len(buf)) < 0.85

def is_regular_file(path: str) -> bool:
    try:
        st = os.lstat(path)
        return stat.S_ISREG(st.st_mode)
    except Exception:
        return False

def is_symlink(path: str) -> bool:
    try:
        return os.path.islink(path)
    except Exception:
        return False

def is_binary(filepath: str, chunk_size: int = 4096) -> bool:
    """
    æ›´å®½æ¾ä¸”æ›´å‡†ç¡®çš„æ–‡æœ¬åˆ¤å®šï¼š
    1) è‹¥åŒ…å« NUL ç›´æ¥è®¤ä¸ºäºŒè¿›åˆ¶ï¼ˆUTF-16/32 BOM è±å…ï¼‰ã€‚
    2) å¦åˆ™å°è¯•ä»¥ UTF-8 ä¸¥æ ¼è§£ç â€”â€”èƒ½è§£ç åˆ™è§†ä¸ºæ–‡æœ¬ã€‚
    3) ä¸¥æ ¼è§£ç å¤±è´¥æ—¶ï¼Œå†ç”¨â€œä¸å¯æ‰“å°æ¯”ä¾‹â€å¯å‘å¼å…œåº•ã€‚
    4) è¯»é”™/æ— æƒé™ç­‰å¼‚å¸¸ï¼Œä¿å®ˆå½“ä½œäºŒè¿›åˆ¶ä»¥é¿å…å¡æ­»ã€‚
    """
    try:
        with open(filepath, 'rb') as f:
            chunk = f.read(chunk_size)
        if b'\x00' in chunk:
            if chunk.startswith((b'\xff\xfe', b'\xfe\xff', b'\xff\xfe\x00\x00', b'\x00\x00\xfe\xff')):
                return False
            return True
        # å°è¯•ä¸¥æ ¼ UTF-8 è§£ç 
        chunk.decode('utf-8')   # æˆåŠŸå³æ˜¯æ–‡æœ¬
        return False
    except UnicodeDecodeError:
        # å…œåº•ï¼šä¸å¯æ‰“å°æ¯”ä¾‹å¾ˆé«˜æ‰å½“äºŒè¿›åˆ¶ï¼ˆé˜ˆå€¼æ”¾å®½åˆ° 0.5ï¼‰
        def looks_binary_by_chars(buf: bytes) -> bool:
            if not buf:
                return False
            texty = sum((32 <= b <= 126) or b in (9, 10, 13) for b in buf)
            return (texty / len(buf)) < 0.5
        return looks_binary_by_chars(chunk)
    except (IOError, PermissionError, OSError):
        return True


def read_shebang(filepath: str) -> str:
    """è¯»å–é¦–è¡Œ shebangï¼ˆè‹¥å­˜åœ¨ï¼‰ï¼Œè¿”å›å°å†™å­—ç¬¦ä¸²ã€‚"""
    try:
        with open(filepath, 'rb') as f:
            first = f.readline(256)
        if first.startswith(b'#!'):
            return first.decode('utf-8', errors='ignore').strip().lower()
    except Exception:
        pass
    return ""

def generate_output_filename(base_name: str) -> str:
    """å¦‚æœè¾“å‡ºæ–‡ä»¶å·²å­˜åœ¨ï¼Œåˆ™ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–°æ–‡ä»¶åã€‚"""
    if not os.path.exists(base_name):
        return base_name
    name, ext = os.path.splitext(base_name)
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    return f"{name}_{timestamp}{ext}"

def norm_ext(ext: str) -> str:
    """æ ‡å‡†åŒ–åç¼€ï¼šå°å†™ + ä»¥ . å¼€å¤´ã€‚"""
    ext = ext.strip()
    if not ext:
        return ext
    if not ext.startswith('.'):
        ext = '.' + ext
    return ext.lower()

def merge_type_groups(base: Dict[str, Dict[str, List[str]]],
                      override: Dict[str, Dict[str, List[str]]]) -> Dict[str, Dict[str, List[str]]]:
    """åˆå¹¶ç±»å‹é…ç½®ï¼šæ”¯æŒè¦†å†™ä¸æ‰©å±•ã€‚"""
    result = {k: {kk: vv[:] for kk, vv in v.items()} for k, v in base.items()}
    for group, spec in override.items():
        if group not in result:
            result[group] = {"exts": [], "names": [], "patterns": [], "shebangs": []}
        dst = result[group]
        for key in ("exts", "names", "patterns", "shebangs"):
            vals = spec.get(key, [])
            if key == "exts":
                vals = [norm_ext(x) for x in vals]
            for x in vals:
                if x not in dst.setdefault(key, []):
                    dst[key].append(x)
    return result

def build_active_filters(groups: Dict[str, Dict[str, List[str]]],
                         selected: List[str]) -> Dict[str, Set[str]]:
    """æ„å»ºåˆå¹¶åçš„è¿‡æ»¤å™¨ï¼ˆç”¨äºå¿«é€Ÿåˆ¤æ–­æ˜¯å¦åŒ¹é…ï¼‰ã€‚"""
    filt_exts: Set[str] = set()
    filt_names: Set[str] = set()
    filt_patterns: Set[str] = set()
    filt_shebangs: Set[str] = set()
    for g in selected:
        spec = groups.get(g)
        if not spec:
            continue
        filt_exts.update(norm_ext(e) for e in spec.get("exts", []))
        filt_names.update(spec.get("names", []))
        filt_patterns.update(spec.get("patterns", []))
        filt_shebangs.update(s.lower() for s in spec.get("shebangs", []))
    return {
        "exts": filt_exts,
        "names": filt_names,
        "patterns": filt_patterns,
        "shebangs": filt_shebangs
    }

def file_matches_types(file_path: str, rel_header_path: str, filt: Dict[str, Set[str]]) -> bool:
    """ä»…ç”¨äºè¿‡æ»¤ï¼šåˆ¤æ–­æ–‡ä»¶æ˜¯å¦åŒ¹é…é€‰ä¸­çš„ç±»å‹è§„åˆ™ã€‚"""
    basename = os.path.basename(file_path)
    _, ext = os.path.splitext(basename)
    ext = ext.lower()

    if ext in filt["exts"]:
        return True
    if basename in filt["names"]:
        return True
    for pat in filt["patterns"]:
        if fnmatch.fnmatch(rel_header_path, pat) or fnmatch.fnmatch(basename, pat):
            return True
    if filt["shebangs"]:
        sb = read_shebang(file_path)
        if sb and any(tok in sb for tok in filt["shebangs"]):
            return True
    return False

def detect_matched_groups(file_path: str, rel_header_path: str,
                          all_groups: Dict[str, Dict[str, List[str]]]) -> List[str]:
    """ä»…ç”¨äºå±•ç¤ºï¼šæ£€æµ‹æ–‡ä»¶åŒ¹é…çš„æ‰€æœ‰ç»„åï¼ˆç”¨äºè¾“å‡ºæ ‡æ³¨ï¼‰ã€‚"""
    basename = os.path.basename(file_path)
    _, ext = os.path.splitext(basename)
    ext = ext.lower()
    sb = read_shebang(file_path)

    matched: List[str] = []
    for g, spec in all_groups.items():
        exts = {norm_ext(e) for e in spec.get("exts", [])}
        names = set(spec.get("names", []))
        patterns = set(spec.get("patterns", []))
        shebangs = {s.lower() for s in spec.get("shebangs", [])}

        hit = False
        if ext in exts or basename in names:
            hit = True
        else:
            for pat in patterns:
                if fnmatch.fnmatch(rel_header_path, pat) or fnmatch.fnmatch(basename, pat):
                    hit = True
                    break
            if not hit and shebangs and sb:
                if any(tok in sb for tok in shebangs):
                    hit = True
        if hit:
            matched.append(g)
    return matched

def _build_abs_excludes_for_root(abs_root_dir: str, exclude_dirs: Set[str]) -> Set[str]:
    """
    å°†ç”¨æˆ·æä¾›çš„æ’é™¤ç›®å½•æ˜ å°„ä¸ºâ€œé’ˆå¯¹è¯¥ root çš„ç»å¯¹å‰ç¼€é›†åˆâ€ï¼š
    - ç»å¯¹è·¯å¾„ï¼šç›´æ¥åŠ å…¥ï¼ˆåŠå…¶ realpathï¼‰
    - ç›¸å¯¹è·¯å¾„ï¼šä¸ root æ‹¼æ¥ååŠ å…¥ï¼ˆåŠå…¶ realpathï¼‰
    éƒ½ä»¥æœ«å°¾åŠ  os.sep çš„å½¢å¼ä½œä¸ºâ€œå‰ç¼€â€åš startswith åˆ¤æ–­ã€‚
    """
    out: Set[str] = set()
    for d in exclude_dirs:
        # åŸæ ·ç»å¯¹/ç›¸å¯¹ä¸¤è·¯éƒ½è€ƒè™‘
        cands = []
        if os.path.isabs(d):
            cands.append(d)
        cands.append(os.path.join(abs_root_dir, d))

        for c in cands:
            try:
                p = os.path.abspath(c)
                out.add(p.rstrip(os.sep) + os.sep)
                rp = os.path.realpath(p)
                out.add(rp.rstrip(os.sep) + os.sep)
            except Exception:
                continue
    return out

# ----------------- ä¸»æ”¶é›†é€»è¾‘ -----------------
def collect_files_to_single_file(
    root_dirs: List[str],
    output_filename: str,
    extra_exclude_dirs: List[str],
    selected_types: List[str],
    type_groups: Dict[str, Dict[str, List[str]]],
    max_bytes: int,
    max_files: int,
    unsafe: bool,
    quiet: bool
) -> None:
    """éå†ç›®å½•ï¼Œå°†ç¬¦åˆæ¡ä»¶çš„æ–‡æœ¬æ–‡ä»¶å†…å®¹åˆå¹¶åˆ°ä¸€ä¸ªè¾“å‡ºæ–‡ä»¶ã€‚"""
    include_all_text = not selected_types
    active_filter = build_active_filters(type_groups, selected_types) if selected_types else None

    # åˆå¹¶æ’é™¤ç›®å½•ï¼ˆç›®å½•åè§„åˆ™ + ç”¨æˆ·è§„åˆ™ï¼‰
    normalized_extra_excludes = {os.path.normpath(d.rstrip('/')) for d in extra_exclude_dirs}
    name_based_excludes = EXCLUDE_DIRS.union(normalized_extra_excludes)

    # è¾“å‡ºæ–‡ä»¶åä¸å…¶ç»å¯¹è·¯å¾„
    safe_output_filename = generate_output_filename(output_filename)
    safe_output_abs = os.path.abspath(safe_output_filename)

    # æœ‰æ•ˆåç¼€æ’é™¤
    effective_exclude_exts = set(EXCLUDE_EXTS)
    if not unsafe:
        effective_exclude_exts |= SENSITIVE_EXTS

    file_count = 0

    try:
        with open(safe_output_filename, 'w', encoding='utf-8', errors='ignore') as outfile:
            for root_dir in root_dirs:
                abs_root_dir = os.path.abspath(root_dir)
                if not os.path.isdir(abs_root_dir):
                    if not quiet:
                        print(f"âš ï¸  è·³è¿‡ï¼šç›®å½• '{root_dir}' ä¸å­˜åœ¨ã€‚")
                    continue

                real_root = os.path.realpath(abs_root_dir)
                # é’ˆå¯¹è¯¥ root çš„ç»å¯¹æ’é™¤å‰ç¼€é›†åˆ
                abs_exclude_prefixes = _build_abs_excludes_for_root(abs_root_dir, name_based_excludes)

                if not quiet:
                    print(f"\nğŸ“ å¼€å§‹å¤„ç†ç›®å½•: {abs_root_dir}")

                for dirpath, dirnames, filenames in os.walk(abs_root_dir, topdown=True, followlinks=False):
                    # ç›®å½•å±‚è¿‡æ»¤ï¼šæŒ‰ç›®å½•åã€ç»å¯¹è·¯å¾„å‰ç¼€ã€ä»¥åŠè½¯é“¾ç›®å½•è·³è¿‡
                    kept_dirnames = []
                    for d in dirnames:
                        full = os.path.join(dirpath, d)
                        # åç§°æ’é™¤
                        if d in name_based_excludes:
                            continue
                        # ç»å¯¹æ’é™¤å‰ç¼€
                        abs_full = os.path.abspath(full)
                        real_full = os.path.realpath(abs_full)
                        if any(abs_full.startswith(p) or real_full.startswith(p) for p in abs_exclude_prefixes):
                            continue
                        # è½¯é“¾ç›®å½•ä¸è¿›å…¥
                        if is_symlink(full):
                            continue
                        kept_dirnames.append(d)
                    dirnames[:] = kept_dirnames  # å‘Šè¯‰ os.walk ä¸è¦æ·±å…¥è¢«ä¸¢å¼ƒçš„ç›®å½•

                    for filename in filenames:
                        # é™æµï¼šæ–‡ä»¶æ•°é‡
                        if max_files and file_count >= max_files:
                            if not quiet:
                                print(f"â¹ï¸ è¾¾åˆ° --max-files é™åˆ¶ï¼ˆ{max_files}ï¼‰ï¼Œåœæ­¢ã€‚")
                            return

                        file_path = os.path.join(dirpath, filename)

                        # è·³è¿‡è¾“å‡ºæ–‡ä»¶è‡ªèº«
                        try:
                            if os.path.samefile(file_path, safe_output_abs):
                                continue
                        except Exception:
                            pass

                        # ä»…å¤„ç†å¸¸è§„æ–‡ä»¶ï¼›è·³è¿‡è½¯é“¾
                        if not is_regular_file(file_path) or is_symlink(file_path):
                            continue

                        # åç¼€æ’é™¤ï¼ˆå«æ•æ„Ÿï¼‰
                        lname = filename.lower()
                        if any(lname.endswith(ext) for ext in effective_exclude_exts):
                            continue

                        # çœŸå®è·¯å¾„å¿…é¡»ä»åœ¨æ‰«ææ ¹å†…ï¼ˆé˜²ç›®å½•é€ƒé€¸ï¼‰
                        real_file = os.path.realpath(file_path)
                        if not (real_file == real_root or real_file.startswith(real_root + os.sep)):
                            continue

                        # äºŒè¿›åˆ¶åˆ¤å®š
                        if is_binary(file_path):
                            continue

                        try:
                            # header path ä½¿ç”¨â€œç›¸å¯¹é¡¹ç›®æ ¹â€çš„å½¢å¼ï¼Œé¿å…æ³„éœ²ç³»ç»Ÿè·¯å¾„
                            relative_path = os.path.relpath(file_path, abs_root_dir)
                            header_path = sanitize_for_header(os.path.join(root_dir, relative_path).replace(os.sep, '/'))

                            # ç±»å‹è¿‡æ»¤ï¼ˆå½“æŒ‡å®š --types æ—¶ï¼‰
                            if not include_all_text:
                                if not file_matches_types(file_path, header_path, active_filter):
                                    continue

                            # å±•ç¤ºç”¨ï¼šæ ‡æ³¨åŒ¹é…ç»„
                            if include_all_text:
                                matched_str = "all-text"
                            else:
                                matched_groups = detect_matched_groups(file_path, header_path, type_groups)
                                matched_str = ", ".join(matched_groups) if matched_groups else "unknown"

                            # å†™å…¥å¤´
                            outfile.write(f"--- æ–‡ä»¶è·¯å¾„: {header_path}\n")
                            outfile.write(f"--- æ–‡ä»¶ç±»å‹: {matched_str}\n")
                            outfile.write(f"--- æ–‡ä»¶å¼€å§‹ ---\n\n")

                            # ä½“é‡é™æµï¼šæŒ‰ max_bytes è¯»å–
                            truncated = False
                            if max_bytes and max_bytes > 0:
                                # å…ˆæŒ‰å­—èŠ‚è¯»ï¼Œç²—æš´ä½†å®‰å…¨ï¼›ç¼–ç æŒ‰ utf-8 å®¹é”™
                                with open(file_path, 'rb') as rb:
                                    data = rb.read(max_bytes + 1)
                                if len(data) > max_bytes:
                                    data = data[:max_bytes]
                                    truncated = True
                                text = data.decode('utf-8', errors='ignore')
                                outfile.write(text)
                            else:
                                with open(file_path, 'r', encoding='utf-8', errors='ignore') as infile:
                                    for line in infile:
                                        outfile.write(line)

                            if truncated:
                                outfile.write("\n\n--- â­ å†…å®¹å·²æŒ‰ --max-bytes æˆªæ–­ ---")

                            outfile.write("\n--- æ–‡ä»¶ç»“æŸ ---\n\n")
                            file_count += 1

                            if not quiet:
                                print(f"  âœ… å·²æ·»åŠ : {relative_path}  ({matched_str})")

                        except Exception as e:
                            if not quiet:
                                print(f"  âŒ é”™è¯¯ï¼šæ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}")

    except IOError as e:
        print(f"è‡´å‘½é”™è¯¯ï¼šæ— æ³•å†™å…¥åˆ°è¾“å‡ºæ–‡ä»¶ {safe_output_filename}: {e}", file=sys.stderr)
        sys.exit(1)

    if not quiet:
        print("\n" + "="*60)
        print(f"ğŸ‰ å¤„ç†å®Œæˆï¼å…± {file_count} ä¸ªæ–‡ä»¶è¢«å†™å…¥åˆ° '{safe_output_filename}' ä¸­ã€‚")
        print("="*60)

# ----------------- é…ç½®åŠ è½½/å±•ç¤º -----------------
def load_types_config(path: str) -> Dict[str, Dict[str, List[str]]]:
    """åŠ è½½å¤–éƒ¨ JSON ç±»å‹é…ç½®å¹¶åˆå¹¶ã€‚"""
    try:
        with open(path, 'r', encoding='utf-8') as f:
            cfg = json.load(f)
        if not isinstance(cfg, dict):
            raise ValueError("ç±»å‹é…ç½®å¿…é¡»æ˜¯ JSON å¯¹è±¡ï¼ˆæœ€å¤–å±‚å­—å…¸ï¼‰")
        normed: Dict[str, Dict[str, List[str]]] = {}
        for k, v in cfg.items():
            if not isinstance(v, dict):
                continue
            normed[k] = {
                "exts": [norm_ext(x) for x in v.get("exts", [])],
                "names": v.get("names", []),
                "patterns": v.get("patterns", []),
                "shebangs": v.get("shebangs", [])
            }
        return merge_type_groups(FILE_TYPE_GROUPS, normed)
    except Exception as e:
        print(f"âš ï¸  è½½å…¥ç±»å‹é…ç½®å¤±è´¥ï¼š{e}ï¼Œæ”¹ç”¨å†…ç½®ç±»å‹ã€‚")
        return FILE_TYPE_GROUPS

def list_types(groups: Dict[str, Dict[str, List[str]]]) -> None:
    print("å¯ç”¨ç±»å‹ï¼ˆ--types å¯é€‰å€¼ï¼‰ï¼š\n")
    for name, spec in groups.items():
        print(f"[{name}]")
        print(f"  exts     : {', '.join(spec.get('exts', [])) or '-'}")
        print(f"  names    : {', '.join(spec.get('names', [])) or '-'}")
        print(f"  patterns : {', '.join(spec.get('patterns', [])) or '-'}")
        print(f"  shebangs : {', '.join(spec.get('shebangs', [])) or '-'}")
        print("")

# ----------------- ä¸»å…¥å£ -----------------
def main() -> None:
    parser = argparse.ArgumentParser(
        description="å°†ä¸€ä¸ªæˆ–å¤šä¸ªç›®å½•ä¸‹çš„æºä»£ç /é…ç½®åˆå¹¶ä¸ºä¸€ä¸ªæ–‡æœ¬æ–‡ä»¶ï¼Œç”¨äº AI ä»£ç åˆ†æï¼ˆå®‰å…¨æ¨¡å¼é»˜è®¤å¼€å¯ï¼‰ã€‚",
        formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument("directories", nargs="*", default=["."],
                        help="è¦æ‰«æçš„ç›®å½•ï¼ˆé»˜è®¤ï¼šå½“å‰ç›®å½•ï¼‰")
    parser.add_argument("--output", "-o", default="combined_code.txt",
                        help="è¾“å‡ºæ–‡ä»¶åï¼ˆé»˜è®¤ï¼šcombined_code.txtï¼‰")
    parser.add_argument("--exclude-dirs", "-e", nargs="+", default=[], metavar="DIR",
                        help="é¢å¤–æ’é™¤çš„ç›®å½•åæˆ–è·¯å¾„ï¼ˆç›¸å¯¹è·¯å¾„æŒ‰æ¯ä¸ªæ‰«ææ ¹è§£æï¼‰")
    parser.add_argument("--types", "-t", nargs="+", default=[],
                        help="æŒ‡å®šæ”¶é›†çš„æ–‡ä»¶ç±»å‹ï¼ˆå¦‚ï¼šyocto scripts pythonï¼‰ï¼Œä¸æŒ‡å®šåˆ™æ”¶é›†æ‰€æœ‰æ–‡æœ¬æ–‡ä»¶")
    parser.add_argument("--list-types", action="store_true",
                        help="åˆ—å‡ºå¯ç”¨ç±»å‹å¹¶é€€å‡º")
    parser.add_argument("--types-config", default="",
                        help="JSON æ–‡ä»¶è·¯å¾„ï¼Œç”¨äºè‡ªå®šä¹‰ç±»å‹æ˜ å°„ï¼ˆexts/names/patterns/shebangsï¼‰")
    parser.add_argument("--max-bytes", type=int, default=8*1024*1024,
                        help="å•æ–‡ä»¶æœ€å¤§è¯»å–å­—èŠ‚æ•°ï¼ˆé»˜è®¤ 8 MiBï¼›0 è¡¨ç¤ºä¸é™åˆ¶ï¼‰")
    parser.add_argument("--max-files", type=int, default=0,
                        help="æœ€å¤šé‡‡é›†çš„æ–‡ä»¶æ•°ï¼ˆé»˜è®¤ 0=ä¸é™åˆ¶ï¼‰")
    parser.add_argument("--unsafe", action="store_true",
                        help="å…³é—­æ•æ„Ÿåç¼€å±è”½ï¼ˆ.pem/.key/.pk8/.jks ç­‰ï¼‰ï¼Œæ…ç”¨")
    parser.add_argument("--quiet", action="store_true",
                        help="é™é»˜æ¨¡å¼ï¼Œå‡å°‘æ§åˆ¶å°è¾“å‡º")

    args = parser.parse_args()
    args.exclude_dirs = [os.path.normpath(p) for p in args.exclude_dirs]

    # åŠ è½½ç±»å‹é…ç½®
    groups = load_types_config(args.types_config) if args.types_config else FILE_TYPE_GROUPS

    if args.list_types:
        list_types(groups)
        sys.exit(0)

    # æ ¡éªŒç±»å‹
    unknown = [t for t in args.types if t and t not in groups]
    if unknown:
        print(f"âš ï¸  æœªçŸ¥ç±»å‹ï¼š{', '.join(unknown)}ã€‚å¯ç”¨ç±»å‹è§ --list-typesã€‚å°†å¿½ç•¥æœªçŸ¥ç±»å‹ã€‚")
        args.types = [t for t in args.types if t in groups]

    collect_files_to_single_file(
        args.directories,
        args.output,
        args.exclude_dirs,
        args.types,
        groups,
        max_bytes=args.max_bytes,
        max_files=args.max_files,
        unsafe=args.unsafe,
        quiet=args.quiet
    )

if __name__ == '__main__':
    main()
