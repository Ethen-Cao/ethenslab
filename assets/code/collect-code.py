#!/usr/bin/python3
# -*- coding: utf-8 -*-

"""
æ”¶é›†æºç /é…ç½®æ–‡ä»¶åˆ°å•ä¸€æ–‡æœ¬ï¼Œä¾¿äº AI åˆ†æã€‚
å®‰å…¨å¢å¼ºï¼š
- è·³è¿‡è½¯é“¾ä¸éå¸¸è§„æ–‡ä»¶ï¼›é˜²ç›®å½•é€ƒé€¸ï¼ˆrealpath ä»é¡»åœ¨æ‰«ææ ¹å†…ï¼‰
- é¿å…è‡ªåƒè¾“å‡ºï¼ˆè·³è¿‡æ­£åœ¨å†™çš„è¾“å‡ºæ–‡ä»¶ï¼‰
- é»˜è®¤æ’é™¤å¸¸è§å¯†é’¥/è¯ä¹¦ç­‰æ•æ„Ÿåç¼€ï¼ˆå¯ç”¨ --unsafe å…³é—­ï¼‰
- æ›´ç¨³å¥äºŒè¿›åˆ¶åˆ¤å®šï¼ˆNUL + UTF-8 æ¢æµ‹ + å­—ç¬¦å¯†åº¦å¯å‘å¼ï¼‰
- ä½“é‡é™æµï¼š--max-bytes, --max-files
åŠŸèƒ½å¢å¼ºï¼š
- æ”¯æŒæ··åˆè¾“å…¥ï¼šå¯åŒæ—¶æŒ‡å®šç›®å½•ï¼ˆé€’å½’æ‰«æï¼‰å’Œæ–‡ä»¶ï¼ˆç›´æ¥æ·»åŠ ï¼‰
- --types/-t æŒ‡å®šç±»å‹ï¼Œä»…æ”¶é›†åŒ¹é…çš„æ–‡ä»¶
- --list-types æŸ¥çœ‹å¯ç”¨ç±»å‹ä¸åŒ¹é…è§„åˆ™
- --types-config è½½å…¥ JSON æ‰©å±•/è¦†ç›–ç±»å‹æ˜ å°„
"""

import os
import sys
import time
import json
import fnmatch
import argparse
import stat
from typing import Set, List, Dict, Tuple, Optional

# ----------------- é»˜è®¤æ’é™¤è§„åˆ™ -----------------
EXCLUDE_DIRS: Set[str] = {
    '.git', '__pycache__', 'node_modules', 
    'dist','.vscode', '.idea', 'venv', '.env',
    # 'target',
    # 'build'
}

EXCLUDE_EXTS: Set[str] = {
    # ç¼–è¯‘äº§ç‰©
    '.pyc', '.pyo', '.o', '.so', '.a', '.dll', '.exe', '.class', '.jar',
    # å›¾ç‰‡
    '.png', '.jpg', '.jpeg', '.gif', '.bmp', '.ico', '.svg', '.webp',
    # éŸ³è§†é¢‘
    '.mp3', '.wav', '.mp4', '.mov', '.avi', '.mkv', '.flac',
    # å‹ç¼©/å½’æ¡£
    '.zip', '.tar', '.gz', '.rar', '.7z',
    '.xz', '.zst', '.zstd', '.lz4', '.lz', '.bz2', '.tgz', '.tbz', '.txz',
    # æ–‡æ¡£å’Œå­—ä½“
    '.pdf', '.doc', '.docx', '.xls', '.xlsx', '.ppt', '.pptx',
    '.eot', '.ttf', '.woff', '.woff2',
    # æ•°æ®åº“
    '.db', '.sqlite3'
}

# æ•æ„Ÿåç¼€ï¼ˆé»˜è®¤ä¹Ÿæ’é™¤ï¼Œå¯ç”¨ --unsafe å…³é—­ï¼‰
SENSITIVE_EXTS: Set[str] = {
    '.pem', '.der', '.crt', '.cer',
    '.key', '.pk8', '.p12', '.pfx',
    '.jks', '.keystore', '.asc', '.gpg'
}

# ----------------- å†…ç½®ç±»å‹æ˜ å°„ï¼ˆå¯è¢« --types-config è¦†å†™/æ‰©å±•ï¼‰ -----------------
FILE_TYPE_GROUPS: Dict[str, Dict[str, List[str]]] = {
    # å…¸å‹ Yocto/BitBake ç›¸å…³
    "yocto": {
        "exts": [".bb", ".bbappend", ".bbclass", ".inc", ".conf", ".wks", ".wic", ".wks.in"],
        "names": ["local.conf", "bblayers.conf", "layer.conf"],
        "patterns": ["conf/*.conf", "conf/*.inc", "*/conf/layer.conf", "*.bbmask"],
        "shebangs": []
    },
    # Shell è„šæœ¬
    "scripts": {
        "exts": [".sh", ".bash"],
        "names": [],
        "patterns": ["scripts/*", "*/scripts/*"],
        "shebangs": ["bash", "sh", "zsh"]
    },
    # Python
    "python": {
        "exts": [".py"],
        "names": [],
        "patterns": [],
        "shebangs": ["python"]
    },
    # CMake/Make
    "cmake": {
        "exts": [".cmake"],
        "names": ["CMakeLists.txt"],
        "patterns": [],
        "shebangs": []
    },
    "make": {
        "exts": [".mk"],
        "names": ["Makefile", "makefile", "GNUmakefile"],
        "patterns": [],
        "shebangs": []
    },
    # è¡¥ä¸
    "patches": {
        "exts": [".patch", ".diff"],
        "names": [],
        "patterns": [],
        "shebangs": []
    },
    # è®¾å¤‡æ ‘
    "dts": {
        "exts": [".dts", ".dtsi",".dtso"],
        "names": [],
        "patterns": [],
        "shebangs": []
    },
    # INI/CFG
    "ini": {
        "exts": [".ini", ".cfg"],
        "names": [],
        "patterns": [],
        "shebangs": []
    },
    # qnx_build_files
    "qnx_build_files": {
        "exts": [".ini", ".cfg",".tmpl",".build",".mk",".cmake",".sh", ".bash",".py"],
        "names": [],
        "patterns": [],
        "shebangs": ["bash", "sh", "zsh","python"]
    },
}

# ----------------- å·¥å…·å‡½æ•° -----------------
def sanitize_for_header(s: str) -> str:
    return s.replace('\n', '\\n').replace('\r', '\\r').replace('\t', '\\t')

def looks_binary_by_chars(buf: bytes, threshold: float = 0.85) -> bool:
    """
    å¯å‘å¼ï¼šæ£€æŸ¥ buffer ä¸­æ–‡æœ¬å­—ç¬¦çš„å æ¯”ã€‚
    å¦‚æœ (æ–‡æœ¬å­—ç¬¦æ•° / æ€»å­—èŠ‚æ•°) < thresholdï¼Œåˆ™è§†ä¸ºäºŒè¿›åˆ¶ã€‚
    """
    if not buf:
        return False
    # æ–‡æœ¬å­—ç¬¦ï¼š32-126 (ASCII å¯æ‰“å°), 9 (\t), 10 (\n), 13 (\r)
    texty = sum((32 <= b <= 126) or b in (9, 10, 13) for b in buf)
    return (texty / len(buf)) < threshold

def is_binary(filepath: str, chunk_size: int = 4096) -> bool:
    """
    åˆ¤æ–­æ–‡ä»¶æ˜¯å¦ä¸ºäºŒè¿›åˆ¶æ–‡ä»¶ã€‚
    ç­–ç•¥ï¼š
    1. NUL å­—èŠ‚æ£€æŸ¥ (å¿½ç•¥ BOM)ã€‚
    2. UTF-8 ä¸¥æ ¼è§£ç å°è¯•ã€‚
    3. å¤±è´¥åˆ™å›é€€åˆ°å­—ç¬¦å¯†åº¦æ£€æµ‹ (é˜ˆå€¼é™ä½åˆ° 0.5)ã€‚
    """
    try:
        with open(filepath, 'rb') as f:
            chunk = f.read(chunk_size)
        
        # 1. åŒ…å« NUL å­—èŠ‚é€šå¸¸æ„å‘³ç€äºŒè¿›åˆ¶ï¼Œä½†è¦æ’é™¤ UTF-16/32 BOM çš„æƒ…å†µ
        if b'\x00' in chunk:
            # å¸¸è§çš„ BOM å¤´
            if chunk.startswith((b'\xff\xfe', b'\xfe\xff', b'\xff\xfe\x00\x00', b'\x00\x00\xfe\xff')):
                # æœ‰ BOMï¼Œå¯èƒ½æ˜¯æ–‡æœ¬ï¼Œæš‚ä¸æŒ‰ NUL åˆ¤æ­»åˆ‘ï¼Œäº¤ç»™åé¢çš„è§£ç /å¯†åº¦æ£€æŸ¥
                pass 
            else:
                return True
        
        # 2. å°è¯•ä¸¥æ ¼ UTF-8 è§£ç 
        try:
            chunk.decode('utf-8')
            return False  # æˆåŠŸè§£ç ï¼Œè‚¯å®šæ˜¯æ–‡æœ¬
        except UnicodeDecodeError:
            pass

        # 3. è§£ç å¤±è´¥ï¼Œä½¿ç”¨å¯å‘å¼å…œåº•
        # æ—¢ç„¶ UTF-8 è§£ç å¤±è´¥äº†ï¼Œå¦‚æœå®ƒè¿˜æ˜¯æ–‡æœ¬ï¼Œé‚£è¯´æ˜æ˜¯å…¶ä»–ç¼–ç  (å¦‚ GBK, Latin-1)ã€‚
        # è¿™é‡Œæˆ‘ä»¬æ”¾å®½é˜ˆå€¼åˆ° 0.5ï¼Œåªè¦æœ‰ä¸€åŠåƒæ–‡æœ¬ï¼Œå°±å§‘ä¸”è®¤ä¸ºæ˜¯æ–‡æœ¬ã€‚
        return looks_binary_by_chars(chunk, threshold=0.5)

    except (IOError, PermissionError, OSError):
        # è¯»ä¸åˆ°æ–‡ä»¶ï¼Œä¿å®ˆè§†ä¸ºäºŒè¿›åˆ¶ä»¥å…æŠ¥é”™ä¸­æ–­
        return True

def is_regular_file(path: str) -> bool:
    try:
        st = os.lstat(path)
        return stat.S_ISREG(st.st_mode)
    except Exception:
        return False

def is_symlink(path: str) -> bool:
    try:
        return os.path.islink(path)
    except Exception:
        return False

def read_shebang(filepath: str) -> str:
    try:
        with open(filepath, 'rb') as f:
            first = f.readline(256)
        if first.startswith(b'#!'):
            return first.decode('utf-8', errors='ignore').strip().lower()
    except Exception:
        pass
    return ""

def generate_output_filename(base_name: str) -> str:
    if not os.path.exists(base_name):
        return base_name
    name, ext = os.path.splitext(base_name)
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    return f"{name}_{timestamp}{ext}"

def norm_ext(ext: str) -> str:
    ext = ext.strip()
    if not ext:
        return ext
    if not ext.startswith('.'):
        ext = '.' + ext
    return ext.lower()

def merge_type_groups(base: Dict[str, Dict[str, List[str]]],
                      override: Dict[str, Dict[str, List[str]]]) -> Dict[str, Dict[str, List[str]]]:
    result = {k: {kk: vv[:] for kk, vv in v.items()} for k, v in base.items()}
    for group, spec in override.items():
        if group not in result:
            result[group] = {"exts": [], "names": [], "patterns": [], "shebangs": []}
        dst = result[group]
        for key in ("exts", "names", "patterns", "shebangs"):
            vals = spec.get(key, [])
            if key == "exts":
                vals = [norm_ext(x) for x in vals]
            for x in vals:
                if x not in dst.setdefault(key, []):
                    dst[key].append(x)
    return result

def build_active_filters(groups: Dict[str, Dict[str, List[str]]],
                         selected: List[str]) -> Dict[str, Set[str]]:
    filt_exts: Set[str] = set()
    filt_names: Set[str] = set()
    filt_patterns: Set[str] = set()
    filt_shebangs: Set[str] = set()
    for g in selected:
        spec = groups.get(g)
        if not spec:
            continue
        filt_exts.update(norm_ext(e) for e in spec.get("exts", []))
        filt_names.update(spec.get("names", []))
        filt_patterns.update(spec.get("patterns", []))
        filt_shebangs.update(s.lower() for s in spec.get("shebangs", []))
    return {
        "exts": filt_exts,
        "names": filt_names,
        "patterns": filt_patterns,
        "shebangs": filt_shebangs
    }

def file_matches_types(file_path: str, rel_header_path: str, filt: Dict[str, Set[str]]) -> bool:
    basename = os.path.basename(file_path)
    _, ext = os.path.splitext(basename)
    ext = ext.lower()

    if ext in filt["exts"]:
        return True
    if basename in filt["names"]:
        return True
    for pat in filt["patterns"]:
        if fnmatch.fnmatch(rel_header_path, pat) or fnmatch.fnmatch(basename, pat):
            return True
    if filt["shebangs"]:
        sb = read_shebang(file_path)
        if sb and any(tok in sb for tok in filt["shebangs"]):
            return True
    return False

def detect_matched_groups(file_path: str, rel_header_path: str,
                          all_groups: Dict[str, Dict[str, List[str]]]) -> List[str]:
    basename = os.path.basename(file_path)
    _, ext = os.path.splitext(basename)
    ext = ext.lower()
    sb = read_shebang(file_path)

    matched: List[str] = []
    for g, spec in all_groups.items():
        exts = {norm_ext(e) for e in spec.get("exts", [])}
        names = set(spec.get("names", []))
        patterns = set(spec.get("patterns", []))
        shebangs = {s.lower() for s in spec.get("shebangs", [])}

        hit = False
        if ext in exts or basename in names:
            hit = True
        else:
            for pat in patterns:
                if fnmatch.fnmatch(rel_header_path, pat) or fnmatch.fnmatch(basename, pat):
                    hit = True
                    break
            if not hit and shebangs and sb:
                if any(tok in sb for tok in shebangs):
                    hit = True
        if hit:
            matched.append(g)
    return matched

def _build_abs_excludes_for_root(abs_root_dir: str, exclude_dirs: Set[str]) -> Set[str]:
    """
    å°†æ’é™¤ç›®å½•æ˜ å°„ä¸ºâ€œé’ˆå¯¹è¯¥ root çš„ç»å¯¹å‰ç¼€é›†åˆâ€ã€‚
    ä¼˜åŒ–ï¼šåŒºåˆ†ç»å¯¹è·¯å¾„å’Œç›¸å¯¹è·¯å¾„ï¼Œé¿å…ä¸å¿…è¦çš„ joinã€‚
    """
    out: Set[str] = set()
    for d in exclude_dirs:
        if os.path.isabs(d):
            p = d
        else:
            p = os.path.join(abs_root_dir, d)

        try:
            # ç»Ÿä¸€æ·»åŠ  abspath å’Œ realpath ä¸¤ç§å½¢å¼
            # ç¡®ä¿ä»¥ os.sep ç»“å°¾ï¼Œç”¨äº startswith å‰ç¼€åŒ¹é…
            abs_p = os.path.abspath(p)
            out.add(abs_p.rstrip(os.sep) + os.sep)
            
            real_p = os.path.realpath(abs_p)
            out.add(real_p.rstrip(os.sep) + os.sep)
        except Exception:
            continue
    return out

# ----------------- æ ¸å¿ƒé€»è¾‘ï¼šå¤„ç†å¹¶å†™å…¥å•ä¸ªæ–‡ä»¶ -----------------
def process_and_write_file(
    file_path: str,
    display_path: str,
    outfile,
    effective_exclude_exts: Set[str],
    active_filter: Optional[Dict[str, Set[str]]],
    type_groups: Dict[str, Dict[str, List[str]]],
    max_bytes: int,
    include_all_text: bool,
    quiet: bool,
    is_explicit_file: bool = False
) -> bool:
    """
    å¤„ç†å•ä¸ªæ–‡ä»¶ï¼šæ£€æŸ¥æ’é™¤è§„åˆ™ã€äºŒè¿›åˆ¶ã€ç±»å‹åŒ¹é…ï¼Œç„¶åå†™å…¥ã€‚
    è¿”å› True è¡¨ç¤ºæˆåŠŸå†™å…¥ï¼ŒFalse è¡¨ç¤ºè¢«è·³è¿‡ã€‚
    """
    # 1. åŸºç¡€æ£€æŸ¥
    if not is_explicit_file:
        if not is_regular_file(file_path) or is_symlink(file_path):
            return False
    else:
        # æ˜¾å¼æ¨¡å¼ä¸‹ï¼Œå¦‚æœä¸å­˜åœ¨ï¼Œç›´æ¥è¿”å›
        if not os.path.exists(file_path):
             if not quiet:
                 print(f"  âŒ è·³è¿‡ï¼šæ–‡ä»¶ä¸å­˜åœ¨ {file_path}")
             return False
        # æ˜¾å¼æ¨¡å¼ä¸‹ï¼Œå¦‚æœæ˜¯ç›®å½•ï¼Œè¿”å› False (åº”ç”±ä¸»å¾ªç¯å¤„ç†)
        if os.path.isdir(file_path):
            return False

    # 2. åç¼€æ’é™¤
    lname = os.path.basename(file_path).lower()
    if any(lname.endswith(ext) for ext in effective_exclude_exts):
        if is_explicit_file and not quiet:
            print(f"  âš ï¸  è­¦å‘Šï¼šæ–‡ä»¶ {display_path} åŒ¹é…æ’é™¤åç¼€ï¼Œå·²è·³è¿‡ã€‚")
        return False

    # 3. äºŒè¿›åˆ¶åˆ¤å®š (ä½¿ç”¨ç»Ÿä¸€ä¼˜åŒ–åçš„é€»è¾‘)
    if is_binary(file_path):
        if is_explicit_file and not quiet:
             print(f"  âš ï¸  è­¦å‘Šï¼šæ–‡ä»¶ {display_path} åˆ¤å®šä¸ºäºŒè¿›åˆ¶ï¼Œå·²è·³è¿‡ã€‚")
        return False

    # 4. ç±»å‹è¿‡æ»¤
    if not include_all_text:
        if not file_matches_types(file_path, display_path, active_filter):
            return False

    # 5. å‡†å¤‡å…ƒæ•°æ®
    if include_all_text:
        matched_str = "all-text"
    else:
        matched_groups = detect_matched_groups(file_path, display_path, type_groups)
        matched_str = ", ".join(matched_groups) if matched_groups else "unknown"

    # 6. å†™å…¥å†…å®¹
    try:
        outfile.write(f"--- æ–‡ä»¶è·¯å¾„: {display_path}\n")
        outfile.write(f"--- æ–‡ä»¶ç±»å‹: {matched_str}\n")
        outfile.write(f"--- æ–‡ä»¶å¼€å§‹ ---\n\n")

        truncated = False
        if max_bytes and max_bytes > 0:
            with open(file_path, 'rb') as rb:
                data = rb.read(max_bytes + 1)
            if len(data) > max_bytes:
                data = data[:max_bytes]
                truncated = True
            text = data.decode('utf-8', errors='ignore')
            outfile.write(text)
        else:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as infile:
                for line in infile:
                    outfile.write(line)

        if truncated:
            outfile.write("\n\n--- â­ å†…å®¹å·²æŒ‰ --max-bytes æˆªæ–­ ---")

        outfile.write("\n--- æ–‡ä»¶ç»“æŸ ---\n\n")
        
        if not quiet:
            print(f"  âœ… å·²æ·»åŠ : {display_path}  ({matched_str})")
        return True

    except Exception as e:
        if not quiet:
            print(f"  âŒ é”™è¯¯ï¼šæ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}")
        return False


# ----------------- ä¸»æ”¶é›†é€»è¾‘ -----------------
def collect_files_to_single_file(
    paths: List[str],
    output_filename: str,
    extra_exclude_dirs: List[str],
    selected_types: List[str],
    type_groups: Dict[str, Dict[str, List[str]]],
    max_bytes: int,
    max_files: int,
    unsafe: bool,
    quiet: bool
) -> None:
    """éå†è·¯å¾„åˆ—è¡¨ï¼ˆç›®å½•é€’å½’/æ–‡ä»¶ç›´æ¥ï¼‰ï¼Œåˆå¹¶å†…å®¹ã€‚"""
    include_all_text = not selected_types
    active_filter = build_active_filters(type_groups, selected_types) if selected_types else None

    # åˆå¹¶æ’é™¤ç›®å½•
    normalized_extra_excludes = {os.path.normpath(d.rstrip('/')) for d in extra_exclude_dirs}
    name_based_excludes = EXCLUDE_DIRS.union(normalized_extra_excludes)

    safe_output_filename = generate_output_filename(output_filename)
    safe_output_abs = os.path.abspath(safe_output_filename)

    effective_exclude_exts = set(EXCLUDE_EXTS)
    if not unsafe:
        effective_exclude_exts |= SENSITIVE_EXTS

    file_count = 0

    try:
        with open(safe_output_filename, 'w', encoding='utf-8', errors='ignore') as outfile:
            
            for input_path in paths:
                abs_input_path = os.path.abspath(input_path)
                
                # ----------- æƒ…å†µ A: è¾“å…¥æ˜¯æ–‡ä»¶ -----------
                if os.path.isfile(abs_input_path):
                    # æ£€æŸ¥æ˜¯å¦æ˜¯è¾“å‡ºæ–‡ä»¶æœ¬èº«
                    if abs_input_path == safe_output_abs:
                        continue
                    
                    # é™æµ
                    if max_files and file_count >= max_files:
                        if not quiet: print(f"â¹ï¸ è¾¾åˆ° --max-files é™åˆ¶ï¼ˆ{max_files}ï¼‰ï¼Œåœæ­¢ã€‚")
                        return

                    # å¯¹äºæ˜¾å¼æŒ‡å®šçš„æ–‡ä»¶ï¼ŒDisplay Path ä½¿ç”¨ç›¸å¯¹å½“å‰ç›®å½•çš„è·¯å¾„
                    display_path = os.path.relpath(abs_input_path, os.getcwd())
                    
                    success = process_and_write_file(
                        file_path=abs_input_path,
                        display_path=display_path,
                        outfile=outfile,
                        effective_exclude_exts=effective_exclude_exts,
                        active_filter=active_filter,
                        type_groups=type_groups,
                        max_bytes=max_bytes,
                        include_all_text=include_all_text,
                        quiet=quiet,
                        is_explicit_file=True
                    )
                    if success:
                        file_count += 1
                    continue

                # ----------- æƒ…å†µ B: è¾“å…¥æ˜¯ç›®å½• -----------
                if not os.path.isdir(abs_input_path):
                    if not quiet:
                        print(f"âš ï¸  è·³è¿‡ï¼šè·¯å¾„ '{input_path}' ä¸å­˜åœ¨æˆ–ä¸æ˜¯ç›®å½•/æ–‡ä»¶ã€‚")
                    continue

                # ç›®å½•å¤„ç†é€»è¾‘
                root_dir = input_path # ä¿æŒåŸå§‹è¾“å…¥ä»¥ä¾¿åš relpath
                real_root = os.path.realpath(abs_input_path)
                abs_exclude_prefixes = _build_abs_excludes_for_root(abs_input_path, name_based_excludes)

                if not quiet:
                    print(f"\nğŸ“ å¼€å§‹æ‰«æç›®å½•: {abs_input_path}")

                for dirpath, dirnames, filenames in os.walk(abs_input_path, topdown=True, followlinks=False):
                    # ç›®å½•å‰ªæ
                    kept_dirnames = []
                    for d in dirnames:
                        full = os.path.join(dirpath, d)
                        if d in name_based_excludes: continue
                        
                        abs_full = os.path.abspath(full)
                        real_full = os.path.realpath(abs_full)
                        if any(abs_full.startswith(p) or real_full.startswith(p) for p in abs_exclude_prefixes):
                            continue
                        if is_symlink(full): continue
                        kept_dirnames.append(d)
                    dirnames[:] = kept_dirnames

                    for filename in filenames:
                        if max_files and file_count >= max_files:
                            if not quiet: print(f"â¹ï¸ è¾¾åˆ° --max-files é™åˆ¶ï¼ˆ{max_files}ï¼‰ï¼Œåœæ­¢ã€‚")
                            return

                        file_path = os.path.join(dirpath, filename)
                        
                        # è·³è¿‡è¾“å‡ºæ–‡ä»¶è‡ªèº«
                        try:
                            if os.path.samefile(file_path, safe_output_abs): continue
                        except Exception: pass

                        # é˜²ç›®å½•é€ƒé€¸ï¼šçœŸå®è·¯å¾„å¿…é¡»ä»åœ¨æ‰«ææ ¹å†…
                        real_file = os.path.realpath(file_path)
                        if not (real_file == real_root or real_file.startswith(real_root + os.sep)):
                            continue

                        # è®¡ç®—ç›¸å¯¹å¤´è·¯å¾„
                        relative_path = os.path.relpath(file_path, abs_input_path)
                        header_path = sanitize_for_header(os.path.join(root_dir, relative_path).replace(os.sep, '/'))

                        success = process_and_write_file(
                            file_path=file_path,
                            display_path=header_path,
                            outfile=outfile,
                            effective_exclude_exts=effective_exclude_exts,
                            active_filter=active_filter,
                            type_groups=type_groups,
                            max_bytes=max_bytes,
                            include_all_text=include_all_text,
                            quiet=quiet,
                            is_explicit_file=False
                        )
                        if success:
                            file_count += 1

    except IOError as e:
        print(f"è‡´å‘½é”™è¯¯ï¼šæ— æ³•å†™å…¥åˆ°è¾“å‡ºæ–‡ä»¶ {safe_output_filename}: {e}", file=sys.stderr)
        sys.exit(1)

    if not quiet:
        print("\n" + "="*60)
        print(f"ğŸ‰ å¤„ç†å®Œæˆï¼å…± {file_count} ä¸ªæ–‡ä»¶è¢«å†™å…¥åˆ° '{safe_output_filename}' ä¸­ã€‚")
        print("="*60)

# ----------------- é…ç½®åŠ è½½/å±•ç¤º -----------------
def load_types_config(path: str) -> Dict[str, Dict[str, List[str]]]:
    try:
        with open(path, 'r', encoding='utf-8') as f:
            cfg = json.load(f)
        if not isinstance(cfg, dict): raise ValueError("ç±»å‹é…ç½®å¿…é¡»æ˜¯ JSON å¯¹è±¡")
        normed = {}
        for k, v in cfg.items():
            if not isinstance(v, dict): continue
            normed[k] = {
                "exts": [norm_ext(x) for x in v.get("exts", [])],
                "names": v.get("names", []),
                "patterns": v.get("patterns", []),
                "shebangs": v.get("shebangs", [])
            }
        return merge_type_groups(FILE_TYPE_GROUPS, normed)
    except Exception as e:
        print(f"âš ï¸  è½½å…¥ç±»å‹é…ç½®å¤±è´¥ï¼š{e}ï¼Œæ”¹ç”¨å†…ç½®ç±»å‹ã€‚")
        return FILE_TYPE_GROUPS

def list_types(groups: Dict[str, Dict[str, List[str]]]) -> None:
    print("å¯ç”¨ç±»å‹ï¼ˆ--types å¯é€‰å€¼ï¼‰ï¼š\n")
    for name, spec in groups.items():
        print(f"[{name}]")
        print(f"  exts     : {', '.join(spec.get('exts', [])) or '-'}")
        print(f"  names    : {', '.join(spec.get('names', [])) or '-'}")
        print(f"  patterns : {', '.join(spec.get('patterns', [])) or '-'}")
        print(f"  shebangs : {', '.join(spec.get('shebangs', [])) or '-'}")
        print("")

# ----------------- ä¸»å…¥å£ -----------------
def main() -> None:
    parser = argparse.ArgumentParser(
        description="å°†æºç /é…ç½®æ–‡ä»¶åˆå¹¶ä¸ºä¸€ä¸ªæ–‡æœ¬æ–‡ä»¶ã€‚\næ”¯æŒæ¨¡å¼ï¼š\n1. ç›®å½•æ‰«æï¼špython collect.py dir1 dir2\n2. æŒ‡å®šæ–‡ä»¶ï¼špython collect.py file1.py file2.cpp\n3. æ··åˆæ¨¡å¼ï¼špython collect.py src/ main.py",
        formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument("paths", nargs="*", default=["."],
                        help="è¦æ”¶é›†çš„è·¯å¾„ï¼ˆç›®å½•æˆ–æ–‡ä»¶ï¼‰ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•")
    parser.add_argument("--output", "-o", default="output.txt",
                        help="è¾“å‡ºæ–‡ä»¶åï¼ˆé»˜è®¤ï¼šoutput.txtï¼‰")
    parser.add_argument("--exclude-dirs", "-e", nargs="+", default=[], metavar="DIR",
                        help="é¢å¤–æ’é™¤çš„ç›®å½•åæˆ–è·¯å¾„ï¼ˆä»…å¯¹ç›®å½•æ‰«ææœ‰æ•ˆï¼‰")
    parser.add_argument("--types", "-t", nargs="+", default=[],
                        help="æŒ‡å®šæ”¶é›†çš„æ–‡ä»¶ç±»å‹ï¼ˆå¦‚ï¼šyocto scripts pythonï¼‰")
    parser.add_argument("--list-types", action="store_true",
                        help="åˆ—å‡ºå¯ç”¨ç±»å‹å¹¶é€€å‡º")
    parser.add_argument("--types-config", default="",
                        help="JSON æ–‡ä»¶è·¯å¾„ï¼Œç”¨äºè‡ªå®šä¹‰ç±»å‹æ˜ å°„")
    parser.add_argument("--max-bytes", type=int, default=8*1024*1024,
                        help="å•æ–‡ä»¶æœ€å¤§è¯»å–å­—èŠ‚æ•°ï¼ˆé»˜è®¤ 8 MiBï¼‰")
    parser.add_argument("--max-files", type=int, default=0,
                        help="æœ€å¤šé‡‡é›†çš„æ–‡ä»¶æ•°ï¼ˆé»˜è®¤ 0=ä¸é™åˆ¶ï¼‰")
    parser.add_argument("--unsafe", action="store_true",
                        help="å…³é—­æ•æ„Ÿåç¼€å±è”½")
    parser.add_argument("--quiet", action="store_true",
                        help="é™é»˜æ¨¡å¼")

    args = parser.parse_args()
    args.exclude_dirs = [os.path.normpath(p) for p in args.exclude_dirs]

    groups = load_types_config(args.types_config) if args.types_config else FILE_TYPE_GROUPS

    if args.list_types:
        list_types(groups)
        sys.exit(0)

    unknown = [t for t in args.types if t and t not in groups]
    if unknown:
        print(f"âš ï¸  æœªçŸ¥ç±»å‹ï¼š{', '.join(unknown)}ã€‚å¯ç”¨ç±»å‹è§ --list-typesã€‚å°†å¿½ç•¥æœªçŸ¥ç±»å‹ã€‚")
        args.types = [t for t in args.types if t in groups]

    collect_files_to_single_file(
        args.paths,
        args.output,
        args.exclude_dirs,
        args.types,
        groups,
        max_bytes=args.max_bytes,
        max_files=args.max_files,
        unsafe=args.unsafe,
        quiet=args.quiet
    )

if __name__ == '__main__':
    main()