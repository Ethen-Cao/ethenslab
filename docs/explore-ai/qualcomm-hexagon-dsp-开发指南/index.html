<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Qualcomm Hexagon DSP 开发指南：AI 推理与通用计算 | Ethen 的实验室</title><meta name=keywords content="Hexagon SDK,QNN,FastRPC,ONNX"><meta name=description content="1. 概述
在 Qualcomm Hexagon DSP 的开发生态中，资源的使用方式并非单一路径。根据应用场景、开发难度及工具链的不同，开发模式被明确划分为两条主要赛道：

赛道一：AI 推理 (AI Inference) —— 核心逻辑为 &ldquo;模型即代码&rdquo;。利用现成的推理引擎运行神经网络。
赛道二：通用计算 (General Compute) —— 核心逻辑为 &ldquo;手写算子&rdquo;。利用底层 SDK 开发任意 C/C++ 算法。

本文档将详细解析这两条赛道的技术细节、架构区别及选型策略。

2. 赛道一：AI 推理 (AI Inference)
这是目前移动端最主流的 DSP 用法，旨在利用 DSP/NPU 加速深度学习模型。
2.1 核心特征

关键词：TFLite, ONNX Runtime, SNPE, QNN, NNAPI
输入物：训练好的神经网络模型文件（如 .onnx, .tflite, .qnn）。
开发模式：配置式开发。开发者通常不需要编写 DSP 侧代码，只需在应用层配置“代理”（Delegate）或“后端”（Backend）。

2.2 技术原理
在这条赛道中，IDL（接口定义语言）是隐形的。

高通或第三方框架（如 Google）已经预置了通用的 DSP 骨架库（例如 libQnnDsp.so 或 libhexagon_nn_skel.so）。
这些预置库充当“万能翻译官”，它们能读取神经网络层（如 Conv2d, Softmax）的定义，并将其转换为 DSP 指令执行。

2.3 适用场景
本质上，此模式仅适用于可以用张量运算描述的任务：

计算机视觉 (CV)：物体检测 (YOLO)、图像分类 (ResNet)、语义分割、人脸关键点。
音频 AI：关键词唤醒 (KWS)、AI 降噪 (RNN/LSTM)。
自然语言处理 (NLP)：意图识别、Transformer 类模型。

2.4 优缺点分析


优点："><meta name=author content><link rel=canonical href=https://ethen-cao.github.io/ethenslab/explore-ai/qualcomm-hexagon-dsp-%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97/><link crossorigin=anonymous href=/ethenslab/assets/css/stylesheet.a1917769c3c78460b110da6d7905321bb53af4a56f22ba4cc0de824cf4d097ab.css integrity="sha256-oZF3acPHhGCxENpteQUyG7U69KVvIrpMwN6CTPTQl6s=" rel="preload stylesheet" as=style><link rel=icon href=https://ethen-cao.github.io/ethenslab/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://ethen-cao.github.io/ethenslab/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://ethen-cao.github.io/ethenslab/favicon-32x32.png><link rel=apple-touch-icon href=https://ethen-cao.github.io/ethenslab/apple-touch-icon.png><link rel=mask-icon href=https://ethen-cao.github.io/ethenslab/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://ethen-cao.github.io/ethenslab/explore-ai/qualcomm-hexagon-dsp-%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://ethen-cao.github.io/ethenslab/explore-ai/qualcomm-hexagon-dsp-%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97/"><meta property="og:site_name" content="Ethen 的实验室"><meta property="og:title" content="Qualcomm Hexagon DSP 开发指南：AI 推理与通用计算"><meta property="og:description" content="1. 概述 在 Qualcomm Hexagon DSP 的开发生态中，资源的使用方式并非单一路径。根据应用场景、开发难度及工具链的不同，开发模式被明确划分为两条主要赛道：
赛道一：AI 推理 (AI Inference) —— 核心逻辑为 “模型即代码”。利用现成的推理引擎运行神经网络。 赛道二：通用计算 (General Compute) —— 核心逻辑为 “手写算子”。利用底层 SDK 开发任意 C/C++ 算法。 本文档将详细解析这两条赛道的技术细节、架构区别及选型策略。
2. 赛道一：AI 推理 (AI Inference) 这是目前移动端最主流的 DSP 用法，旨在利用 DSP/NPU 加速深度学习模型。
2.1 核心特征 关键词：TFLite, ONNX Runtime, SNPE, QNN, NNAPI 输入物：训练好的神经网络模型文件（如 .onnx, .tflite, .qnn）。 开发模式：配置式开发。开发者通常不需要编写 DSP 侧代码，只需在应用层配置“代理”（Delegate）或“后端”（Backend）。 2.2 技术原理 在这条赛道中，IDL（接口定义语言）是隐形的。
高通或第三方框架（如 Google）已经预置了通用的 DSP 骨架库（例如 libQnnDsp.so 或 libhexagon_nn_skel.so）。 这些预置库充当“万能翻译官”，它们能读取神经网络层（如 Conv2d, Softmax）的定义，并将其转换为 DSP 指令执行。 2.3 适用场景 本质上，此模式仅适用于可以用张量运算描述的任务：
计算机视觉 (CV)：物体检测 (YOLO)、图像分类 (ResNet)、语义分割、人脸关键点。 音频 AI：关键词唤醒 (KWS)、AI 降噪 (RNN/LSTM)。 自然语言处理 (NLP)：意图识别、Transformer 类模型。 2.4 优缺点分析 优点："><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="explore-ai"><meta property="article:published_time" content="2025-08-27T17:17:50+08:00"><meta property="article:modified_time" content="2025-08-27T17:17:50+08:00"><meta property="article:tag" content="Hexagon SDK"><meta property="article:tag" content="QNN"><meta property="article:tag" content="FastRPC"><meta property="article:tag" content="ONNX"><meta name=twitter:card content="summary"><meta name=twitter:title content="Qualcomm Hexagon DSP 开发指南：AI 推理与通用计算"><meta name=twitter:description content="1. 概述
在 Qualcomm Hexagon DSP 的开发生态中，资源的使用方式并非单一路径。根据应用场景、开发难度及工具链的不同，开发模式被明确划分为两条主要赛道：

赛道一：AI 推理 (AI Inference) —— 核心逻辑为 &ldquo;模型即代码&rdquo;。利用现成的推理引擎运行神经网络。
赛道二：通用计算 (General Compute) —— 核心逻辑为 &ldquo;手写算子&rdquo;。利用底层 SDK 开发任意 C/C++ 算法。

本文档将详细解析这两条赛道的技术细节、架构区别及选型策略。

2. 赛道一：AI 推理 (AI Inference)
这是目前移动端最主流的 DSP 用法，旨在利用 DSP/NPU 加速深度学习模型。
2.1 核心特征

关键词：TFLite, ONNX Runtime, SNPE, QNN, NNAPI
输入物：训练好的神经网络模型文件（如 .onnx, .tflite, .qnn）。
开发模式：配置式开发。开发者通常不需要编写 DSP 侧代码，只需在应用层配置“代理”（Delegate）或“后端”（Backend）。

2.2 技术原理
在这条赛道中，IDL（接口定义语言）是隐形的。

高通或第三方框架（如 Google）已经预置了通用的 DSP 骨架库（例如 libQnnDsp.so 或 libhexagon_nn_skel.so）。
这些预置库充当“万能翻译官”，它们能读取神经网络层（如 Conv2d, Softmax）的定义，并将其转换为 DSP 指令执行。

2.3 适用场景
本质上，此模式仅适用于可以用张量运算描述的任务：

计算机视觉 (CV)：物体检测 (YOLO)、图像分类 (ResNet)、语义分割、人脸关键点。
音频 AI：关键词唤醒 (KWS)、AI 降噪 (RNN/LSTM)。
自然语言处理 (NLP)：意图识别、Transformer 类模型。

2.4 优缺点分析


优点："><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Explore AI","item":"https://ethen-cao.github.io/ethenslab/explore-ai/"},{"@type":"ListItem","position":2,"name":"Qualcomm Hexagon DSP 开发指南：AI 推理与通用计算","item":"https://ethen-cao.github.io/ethenslab/explore-ai/qualcomm-hexagon-dsp-%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Qualcomm Hexagon DSP 开发指南：AI 推理与通用计算","name":"Qualcomm Hexagon DSP 开发指南：AI 推理与通用计算","description":"1. 概述 在 Qualcomm Hexagon DSP 的开发生态中，资源的使用方式并非单一路径。根据应用场景、开发难度及工具链的不同，开发模式被明确划分为两条主要赛道：\n赛道一：AI 推理 (AI Inference) —— 核心逻辑为 \u0026ldquo;模型即代码\u0026rdquo;。利用现成的推理引擎运行神经网络。 赛道二：通用计算 (General Compute) —— 核心逻辑为 \u0026ldquo;手写算子\u0026rdquo;。利用底层 SDK 开发任意 C/C++ 算法。 本文档将详细解析这两条赛道的技术细节、架构区别及选型策略。\n2. 赛道一：AI 推理 (AI Inference) 这是目前移动端最主流的 DSP 用法，旨在利用 DSP/NPU 加速深度学习模型。\n2.1 核心特征 关键词：TFLite, ONNX Runtime, SNPE, QNN, NNAPI 输入物：训练好的神经网络模型文件（如 .onnx, .tflite, .qnn）。 开发模式：配置式开发。开发者通常不需要编写 DSP 侧代码，只需在应用层配置“代理”（Delegate）或“后端”（Backend）。 2.2 技术原理 在这条赛道中，IDL（接口定义语言）是隐形的。\n高通或第三方框架（如 Google）已经预置了通用的 DSP 骨架库（例如 libQnnDsp.so 或 libhexagon_nn_skel.so）。 这些预置库充当“万能翻译官”，它们能读取神经网络层（如 Conv2d, Softmax）的定义，并将其转换为 DSP 指令执行。 2.3 适用场景 本质上，此模式仅适用于可以用张量运算描述的任务：\n计算机视觉 (CV)：物体检测 (YOLO)、图像分类 (ResNet)、语义分割、人脸关键点。 音频 AI：关键词唤醒 (KWS)、AI 降噪 (RNN/LSTM)。 自然语言处理 (NLP)：意图识别、Transformer 类模型。 2.4 优缺点分析 优点：\n","keywords":["Hexagon SDK","QNN","FastRPC","ONNX"],"articleBody":"1. 概述 在 Qualcomm Hexagon DSP 的开发生态中，资源的使用方式并非单一路径。根据应用场景、开发难度及工具链的不同，开发模式被明确划分为两条主要赛道：\n赛道一：AI 推理 (AI Inference) —— 核心逻辑为 “模型即代码”。利用现成的推理引擎运行神经网络。 赛道二：通用计算 (General Compute) —— 核心逻辑为 “手写算子”。利用底层 SDK 开发任意 C/C++ 算法。 本文档将详细解析这两条赛道的技术细节、架构区别及选型策略。\n2. 赛道一：AI 推理 (AI Inference) 这是目前移动端最主流的 DSP 用法，旨在利用 DSP/NPU 加速深度学习模型。\n2.1 核心特征 关键词：TFLite, ONNX Runtime, SNPE, QNN, NNAPI 输入物：训练好的神经网络模型文件（如 .onnx, .tflite, .qnn）。 开发模式：配置式开发。开发者通常不需要编写 DSP 侧代码，只需在应用层配置“代理”（Delegate）或“后端”（Backend）。 2.2 技术原理 在这条赛道中，IDL（接口定义语言）是隐形的。\n高通或第三方框架（如 Google）已经预置了通用的 DSP 骨架库（例如 libQnnDsp.so 或 libhexagon_nn_skel.so）。 这些预置库充当“万能翻译官”，它们能读取神经网络层（如 Conv2d, Softmax）的定义，并将其转换为 DSP 指令执行。 2.3 适用场景 本质上，此模式仅适用于可以用张量运算描述的任务：\n计算机视觉 (CV)：物体检测 (YOLO)、图像分类 (ResNet)、语义分割、人脸关键点。 音频 AI：关键词唤醒 (KWS)、AI 降噪 (RNN/LSTM)。 自然语言处理 (NLP)：意图识别、Transformer 类模型。 2.4 优缺点分析 优点：\n开发门槛低，无需掌握汇编或嵌入式编程。\n模型迭代快，直接替换模型文件即可。\n缺点：\n灵活性受限：无法处理非神经网络逻辑（如复杂的 if-else 逻辑、传统图像算法）。\n3. 赛道二：通用计算 (General Compute) 这是传统的嵌入式开发用法，用于处理非神经网络的计算密集型任务，或者为 AI 赛道提供自定义算子支持。\n3.1 核心特征 关键词：Hexagon SDK, FastRPC, IDL, QAIC, HVX/HMX 输入物：C/C++ 源代码 + .idl 接口定义文件。 开发模式：全栈式开发。需同时编写 CPU 侧的调用代码和 DSP 侧的实现代码。 3.2 工作流程 (FastRPC 机制) 定义接口：编写 .idl 文件，定义 CPU 与 DSP 的函数签名。 生成胶水代码：使用 QAIC 编译器生成 Stub (CPU 侧桩代码) 和 Skel (DSP 侧骨架代码)。 实现算法：在 DSP 侧用 C/C++ 实现业务逻辑。 性能优化：为榨干 DSP 性能，通常需使用 Hexagon Intrinsics 编写 HVX 向量化代码。 3.3 适用场景 适用于逻辑复杂、依赖数学公式或特定标准的任务：\n传统 ISP：Bayer 转 RGB、自动白平衡 (AWB)、畸变校正。 传统 CV：特征点匹配 (ORB, SIFT)、RANSAC 算法。 编解码：H.264 解析、MP3/AAC 解码。 传感器融合：卡尔曼滤波 (Kalman Filter)、IMU 数据处理。 3.4 优缺点分析 优点：\n极高的自由度：可实现任何 C/C++ 逻辑。\n极致性能：可手动控制内存和向量指令。\n缺点：\n门槛极高，需精通内存管理 (ION/DMA-BUF)、多线程同步及打包签名流程。\n4. 赛道对比与交集 4.1 维度对比表 特性 赛道 1: AI 框架 (TFLite/ONNX) 赛道 2: 通用 DSP 开发 (FastRPC) 核心驱动力 神经网络模型文件 C/C++ 源码 中间工具 模型转换器 (Converter) QAIC 编译器 运行实体 通用引擎 (libQnnHtp.so) 自定义库 (lib_skel.so) IDL 需求 不需要 (框架内置) 必须 (开发者定义) 主要难点 量化精度、算子支持度 内存管理、并行编程、HVX 优化 4.2 关键交集：自定义算子 (Custom Operator) 赛道 2 是赛道 1 的底层基石。\n当 AI 模型中包含一个框架不支持的特殊层（例如某种新型 Attention）时，开发流程如下：\n使用 赛道 2 (Hexagon SDK) 编写该算子的底层 DSP 实现，并编译为 Op Package (.so)。 在 赛道 1 (QNN SDK) 中注册该 Op Package。 推理引擎在运行模型时，会自动调度该自定义库来执行特定节点。 5. SDK 架构深度解析：Hexagon SDK vs. QNN SDK 理解这两个 SDK 的关系是选型的关键。\n5.1 核心定位 Hexagon SDK: 面向 底层嵌入式开发者。提供裸机级别的访问能力（寄存器、HVX、FastRPC）。 QNN SDK: 面向 AI 应用开发者。它是基于 Hexagon SDK 构建的高级抽象层，屏蔽了底层的 FastRPC 和硬件细节。 5.2 架构依赖关系 QNN SDK 的 HTP Backend 本质上是一个由高通官方使用 Hexagon SDK 开发的复杂 FastRPC 应用。\n@startuml !theme plain skinparam backgroundColor white skinparam linetype ortho title 软件栈层级关系 package \"Android Application Layer\" { component \"User App\" as App } package \"High-Level SDK (QNN)\" #e1f5fe { component \"QNN API\" as QNN_API component \"HTP Backend\\n(libQnnHtp.so)\" as HTP_Backend note right of HTP_Backend 这是 QNN 的核心 它负责图调度 end note } package \"Low-Level SDK (Hexagon)\" #fff9c4 { component \"FastRPC Lib\\n(libadsprpc.so)\" as FastRPC component \"QuRT OS\\n(DSP Kernel)\" as QuRT } package \"DSP Hardware\" { component \"libQnnHtpVxxSkel.so\" as QnnSkel #e1f5fe note bottom of QnnSkel 高通写的 Skel 用于执行 AI 图 end note component \"libmy_algo_skel.so\" as MyAlgo #fff9c4 note bottom of MyAlgo 你自己写的 Skel 用于通用计算 end note } ' 关系连线 App --\u003e QNN_API : 1. Load Model QNN_API --\u003e HTP_Backend HTP_Backend --\u003e FastRPC : 2. Invoke (Built-in) FastRPC --\u003e QnnSkel : 3. Execute Graph App ..\u003e FastRPC : 1. Invoke (Custom) FastRPC ..\u003e MyAlgo : 2. Execute C Code @enduml 6. 附录：AI 模型部署模式详解 在 QNN 或其他推理框架中，模型的加载方式主要分为两种：\n6.1 解释执行模式 (Interpreted Mode) 别名：Standard Mode, File Mode。 原理：Runtime 像“厨师看菜谱”一样，运行时读取 .onnx 文件，解析节点结构，动态在内存中构建计算图。 优点：灵活性高，支持模型热更新（只需下发新文件）。 缺点：初始化耗时较长（需解析和构图）。 适用：快速迭代、需动态下发模型的 App。 6.2 模型库模式 (Model Library Mode) 别名：Native Mode, Compiled Mode (.so)。 原理：使用工具链像“背下菜谱”一样，将模型结构和权重编译为二进制 .so 库。App 运行时直接加载库，跳过解析步骤。 优点：极致冷启动速度，零解析开销；模型结构安全性高（难以逆向）。 缺点：集成复杂（模型更新需重新编译发版 APK）；灵活性低。 适用：系统级应用、相机冷启动、核心算法保密场景。 ","wordCount":"474","inLanguage":"en","datePublished":"2025-08-27T17:17:50+08:00","dateModified":"2025-08-27T17:17:50+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://ethen-cao.github.io/ethenslab/explore-ai/qualcomm-hexagon-dsp-%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97/"},"publisher":{"@type":"Organization","name":"Ethen 的实验室","logo":{"@type":"ImageObject","url":"https://ethen-cao.github.io/ethenslab/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://ethen-cao.github.io/ethenslab/ accesskey=h title="Ethen 的实验室 (Alt + H)">Ethen 的实验室</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://ethen-cao.github.io/ethenslab/android-dev/ title=Android系统开发><span>Android系统开发</span></a></li><li><a href=https://ethen-cao.github.io/ethenslab/android-automotive-os-dev/ title="Android Automotive"><span>Android Automotive</span></a></li><li><a href=https://ethen-cao.github.io/ethenslab/qnx/ title=QNX开发><span>QNX开发</span></a></li><li><a href=https://ethen-cao.github.io/ethenslab/gunyah/ title=Gunyah><span>Gunyah</span></a></li><li><a href=https://ethen-cao.github.io/ethenslab/ivi-solution/ title=智能座舱方案><span>智能座舱方案</span></a></li><li><a href=https://ethen-cao.github.io/ethenslab/explore-ai title="Explore AI"><span>Explore AI</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://ethen-cao.github.io/ethenslab/>Home</a>&nbsp;»&nbsp;<a href=https://ethen-cao.github.io/ethenslab/explore-ai/>Explore AI</a></div><h1 class="post-title entry-hint-parent">Qualcomm Hexagon DSP 开发指南：AI 推理与通用计算</h1><div class=post-meta><span title='2025-08-27 17:17:50 +0800 CST'>August 27, 2025</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;474 words</div></header><div class=post-content><h2 id=1-概述>1. 概述<a hidden class=anchor aria-hidden=true href=#1-概述>#</a></h2><p>在 Qualcomm Hexagon DSP 的开发生态中，资源的使用方式并非单一路径。根据应用场景、开发难度及工具链的不同，开发模式被明确划分为两条主要赛道：</p><ul><li><strong>赛道一：AI 推理 (AI Inference)</strong> —— 核心逻辑为 <strong>&ldquo;模型即代码&rdquo;</strong>。利用现成的推理引擎运行神经网络。</li><li><strong>赛道二：通用计算 (General Compute)</strong> —— 核心逻辑为 <strong>&ldquo;手写算子&rdquo;</strong>。利用底层 SDK 开发任意 C/C++ 算法。</li></ul><p>本文档将详细解析这两条赛道的技术细节、架构区别及选型策略。</p><hr><h2 id=2-赛道一ai-推理-ai-inference>2. 赛道一：AI 推理 (AI Inference)<a hidden class=anchor aria-hidden=true href=#2-赛道一ai-推理-ai-inference>#</a></h2><p>这是目前移动端最主流的 DSP 用法，旨在利用 DSP/NPU 加速深度学习模型。</p><h3 id=21-核心特征>2.1 核心特征<a hidden class=anchor aria-hidden=true href=#21-核心特征>#</a></h3><ul><li><strong>关键词</strong>：<code>TFLite</code>, <code>ONNX Runtime</code>, <code>SNPE</code>, <code>QNN</code>, <code>NNAPI</code></li><li><strong>输入物</strong>：训练好的神经网络模型文件（如 <code>.onnx</code>, <code>.tflite</code>, <code>.qnn</code>）。</li><li><strong>开发模式</strong>：配置式开发。开发者通常不需要编写 DSP 侧代码，只需在应用层配置“代理”（Delegate）或“后端”（Backend）。</li></ul><h3 id=22-技术原理>2.2 技术原理<a hidden class=anchor aria-hidden=true href=#22-技术原理>#</a></h3><p>在这条赛道中，<strong>IDL（接口定义语言）是隐形的</strong>。</p><ul><li>高通或第三方框架（如 Google）已经预置了通用的 DSP 骨架库（例如 <code>libQnnDsp.so</code> 或 <code>libhexagon_nn_skel.so</code>）。</li><li>这些预置库充当“万能翻译官”，它们能读取神经网络层（如 <code>Conv2d</code>, <code>Softmax</code>）的定义，并将其转换为 DSP 指令执行。</li></ul><h3 id=23-适用场景>2.3 适用场景<a hidden class=anchor aria-hidden=true href=#23-适用场景>#</a></h3><p>本质上，此模式仅适用于<strong>可以用张量运算描述的任务</strong>：</p><ul><li><strong>计算机视觉 (CV)</strong>：物体检测 (YOLO)、图像分类 (ResNet)、语义分割、人脸关键点。</li><li><strong>音频 AI</strong>：关键词唤醒 (KWS)、AI 降噪 (RNN/LSTM)。</li><li><strong>自然语言处理 (NLP)</strong>：意图识别、Transformer 类模型。</li></ul><h3 id=24-优缺点分析>2.4 优缺点分析<a hidden class=anchor aria-hidden=true href=#24-优缺点分析>#</a></h3><ul><li><p><strong>优点</strong>：</p></li><li><p>开发门槛低，无需掌握汇编或嵌入式编程。</p></li><li><p>模型迭代快，直接替换模型文件即可。</p></li><li><p><strong>缺点</strong>：</p></li><li><p><strong>灵活性受限</strong>：无法处理非神经网络逻辑（如复杂的 <code>if-else</code> 逻辑、传统图像算法）。</p></li></ul><hr><h2 id=3-赛道二通用计算-general-compute>3. 赛道二：通用计算 (General Compute)<a hidden class=anchor aria-hidden=true href=#3-赛道二通用计算-general-compute>#</a></h2><p>这是传统的嵌入式开发用法，用于处理非神经网络的计算密集型任务，或者为 AI 赛道提供自定义算子支持。</p><h3 id=31-核心特征>3.1 核心特征<a hidden class=anchor aria-hidden=true href=#31-核心特征>#</a></h3><ul><li><strong>关键词</strong>：<code>Hexagon SDK</code>, <code>FastRPC</code>, <code>IDL</code>, <code>QAIC</code>, <code>HVX/HMX</code></li><li><strong>输入物</strong>：C/C++ 源代码 + <code>.idl</code> 接口定义文件。</li><li><strong>开发模式</strong>：全栈式开发。需同时编写 CPU 侧的调用代码和 DSP 侧的实现代码。</li></ul><h3 id=32-工作流程-fastrpc-机制>3.2 工作流程 (FastRPC 机制)<a hidden class=anchor aria-hidden=true href=#32-工作流程-fastrpc-机制>#</a></h3><ol><li><strong>定义接口</strong>：编写 <code>.idl</code> 文件，定义 CPU 与 DSP 的函数签名。</li><li><strong>生成胶水代码</strong>：使用 <code>QAIC</code> 编译器生成 <code>Stub</code> (CPU 侧桩代码) 和 <code>Skel</code> (DSP 侧骨架代码)。</li><li><strong>实现算法</strong>：在 DSP 侧用 C/C++ 实现业务逻辑。</li><li><strong>性能优化</strong>：为榨干 DSP 性能，通常需使用 <strong>Hexagon Intrinsics</strong> 编写 HVX 向量化代码。</li></ol><h3 id=33-适用场景>3.3 适用场景<a hidden class=anchor aria-hidden=true href=#33-适用场景>#</a></h3><p>适用于<strong>逻辑复杂、依赖数学公式或特定标准</strong>的任务：</p><ul><li><strong>传统 ISP</strong>：Bayer 转 RGB、自动白平衡 (AWB)、畸变校正。</li><li><strong>传统 CV</strong>：特征点匹配 (ORB, SIFT)、RANSAC 算法。</li><li><strong>编解码</strong>：H.264 解析、MP3/AAC 解码。</li><li><strong>传感器融合</strong>：卡尔曼滤波 (Kalman Filter)、IMU 数据处理。</li></ul><h3 id=34-优缺点分析>3.4 优缺点分析<a hidden class=anchor aria-hidden=true href=#34-优缺点分析>#</a></h3><ul><li><p><strong>优点</strong>：</p></li><li><p><strong>极高的自由度</strong>：可实现任何 C/C++ 逻辑。</p></li><li><p><strong>极致性能</strong>：可手动控制内存和向量指令。</p></li><li><p><strong>缺点</strong>：</p></li><li><p>门槛极高，需精通内存管理 (ION/DMA-BUF)、多线程同步及打包签名流程。</p></li></ul><hr><h2 id=4-赛道对比与交集>4. 赛道对比与交集<a hidden class=anchor aria-hidden=true href=#4-赛道对比与交集>#</a></h2><h3 id=41-维度对比表>4.1 维度对比表<a hidden class=anchor aria-hidden=true href=#41-维度对比表>#</a></h3><table><thead><tr><th>特性</th><th><strong>赛道 1: AI 框架 (TFLite/ONNX)</strong></th><th><strong>赛道 2: 通用 DSP 开发 (FastRPC)</strong></th></tr></thead><tbody><tr><td><strong>核心驱动力</strong></td><td>神经网络模型文件</td><td>C/C++ 源码</td></tr><tr><td><strong>中间工具</strong></td><td>模型转换器 (Converter)</td><td>QAIC 编译器</td></tr><tr><td><strong>运行实体</strong></td><td>通用引擎 (<code>libQnnHtp.so</code>)</td><td>自定义库 (<code>lib_skel.so</code>)</td></tr><tr><td><strong>IDL 需求</strong></td><td><strong>不需要</strong> (框架内置)</td><td><strong>必须</strong> (开发者定义)</td></tr><tr><td><strong>主要难点</strong></td><td>量化精度、算子支持度</td><td>内存管理、并行编程、HVX 优化</td></tr></tbody></table><h3 id=42-关键交集自定义算子-custom-operator>4.2 关键交集：自定义算子 (Custom Operator)<a hidden class=anchor aria-hidden=true href=#42-关键交集自定义算子-custom-operator>#</a></h3><p><strong>赛道 2 是赛道 1 的底层基石。</strong></p><p>当 AI 模型中包含一个框架不支持的特殊层（例如某种新型 Attention）时，开发流程如下：</p><ol><li>使用 <strong>赛道 2 (Hexagon SDK)</strong> 编写该算子的底层 DSP 实现，并编译为 Op Package (<code>.so</code>)。</li><li>在 <strong>赛道 1 (QNN SDK)</strong> 中注册该 Op Package。</li><li>推理引擎在运行模型时，会自动调度该自定义库来执行特定节点。</li></ol><hr><h2 id=5-sdk-架构深度解析hexagon-sdk-vs-qnn-sdk>5. SDK 架构深度解析：Hexagon SDK vs. QNN SDK<a hidden class=anchor aria-hidden=true href=#5-sdk-架构深度解析hexagon-sdk-vs-qnn-sdk>#</a></h2><p>理解这两个 SDK 的关系是选型的关键。</p><h3 id=51-核心定位>5.1 核心定位<a hidden class=anchor aria-hidden=true href=#51-核心定位>#</a></h3><ul><li><strong>Hexagon SDK</strong>: 面向 <strong>底层嵌入式开发者</strong>。提供裸机级别的访问能力（寄存器、HVX、FastRPC）。</li><li><strong>QNN SDK</strong>: 面向 <strong>AI 应用开发者</strong>。它是基于 Hexagon SDK 构建的高级抽象层，屏蔽了底层的 FastRPC 和硬件细节。</li></ul><h3 id=52-架构依赖关系>5.2 架构依赖关系<a hidden class=anchor aria-hidden=true href=#52-架构依赖关系>#</a></h3><p>QNN SDK 的 HTP Backend 本质上是一个由高通官方使用 Hexagon SDK 开发的复杂 FastRPC 应用。</p><pre class=plantuml-container hidden>
  <code class=language-plantuml>@startuml
!theme plain
skinparam backgroundColor white
skinparam linetype ortho

title 软件栈层级关系

package &#34;Android Application Layer&#34; {
    component &#34;User App&#34; as App
}

package &#34;High-Level SDK (QNN)&#34; #e1f5fe {
    component &#34;QNN API&#34; as QNN_API
    component &#34;HTP Backend\n(libQnnHtp.so)&#34; as HTP_Backend
    note right of HTP_Backend
        这是 QNN 的核心
        它负责图调度
    end note
}

package &#34;Low-Level SDK (Hexagon)&#34; #fff9c4 {
    component &#34;FastRPC Lib\n(libadsprpc.so)&#34; as FastRPC
    component &#34;QuRT OS\n(DSP Kernel)&#34; as QuRT
}

package &#34;DSP Hardware&#34; {
    component &#34;libQnnHtpVxxSkel.so&#34; as QnnSkel #e1f5fe
    note bottom of QnnSkel
        高通写的 Skel
        用于执行 AI 图
    end note
    
    component &#34;libmy_algo_skel.so&#34; as MyAlgo #fff9c4
    note bottom of MyAlgo
        你自己写的 Skel
        用于通用计算
    end note
}

&#39; 关系连线
App --&gt; QNN_API : 1. Load Model
QNN_API --&gt; HTP_Backend
HTP_Backend --&gt; FastRPC : 2. Invoke (Built-in)
FastRPC --&gt; QnnSkel : 3. Execute Graph

App ..&gt; FastRPC : 1. Invoke (Custom)
FastRPC ..&gt; MyAlgo : 2. Execute C Code

@enduml</code>
</pre><hr><h2 id=6-附录ai-模型部署模式详解>6. 附录：AI 模型部署模式详解<a hidden class=anchor aria-hidden=true href=#6-附录ai-模型部署模式详解>#</a></h2><p>在 QNN 或其他推理框架中，模型的加载方式主要分为两种：</p><h3 id=61-解释执行模式-interpreted-mode>6.1 解释执行模式 (Interpreted Mode)<a hidden class=anchor aria-hidden=true href=#61-解释执行模式-interpreted-mode>#</a></h3><ul><li><strong>别名</strong>：Standard Mode, File Mode。</li><li><strong>原理</strong>：Runtime 像“厨师看菜谱”一样，运行时读取 <code>.onnx</code> 文件，解析节点结构，动态在内存中构建计算图。</li><li><strong>优点</strong>：灵活性高，支持模型热更新（只需下发新文件）。</li><li><strong>缺点</strong>：初始化耗时较长（需解析和构图）。</li><li><strong>适用</strong>：快速迭代、需动态下发模型的 App。</li></ul><h3 id=62-模型库模式-model-library-mode>6.2 模型库模式 (Model Library Mode)<a hidden class=anchor aria-hidden=true href=#62-模型库模式-model-library-mode>#</a></h3><ul><li><strong>别名</strong>：Native Mode, Compiled Mode (<code>.so</code>)。</li><li><strong>原理</strong>：使用工具链像“背下菜谱”一样，将模型结构和权重编译为二进制 <code>.so</code> 库。App 运行时直接加载库，跳过解析步骤。</li><li><strong>优点</strong>：<strong>极致冷启动速度</strong>，零解析开销；模型结构安全性高（难以逆向）。</li><li><strong>缺点</strong>：集成复杂（模型更新需重新编译发版 APK）；灵活性低。</li><li><strong>适用</strong>：系统级应用、相机冷启动、核心算法保密场景。</li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://ethen-cao.github.io/ethenslab/tags/hexagon-sdk/>Hexagon SDK</a></li><li><a href=https://ethen-cao.github.io/ethenslab/tags/qnn/>QNN</a></li><li><a href=https://ethen-cao.github.io/ethenslab/tags/fastrpc/>FastRPC</a></li><li><a href=https://ethen-cao.github.io/ethenslab/tags/onnx/>ONNX</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2026 <a href=https://ethen-cao.github.io/ethenslab/>Ethen 的实验室</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>