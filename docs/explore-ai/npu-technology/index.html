<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Ethen 的实验室</title><meta name=keywords content><meta name=description content="Hexagon DSP 的生态
在 Qualcomm Hexagon DSP 的生态中，可以把资源的使用方式明确划分为两条主要赛道。它们针对的场景不同，开发难度不同，工具链也完全不同。
1. 第一条赛道：AI 推理 (AI Inference)
关键词：TFLite, ONNX, SNPE, QNN, NNAPI
核心逻辑：“模型即代码” (Model is the code)
这是目前最主流的用法，主要用于深度学习。

主要工作：

训练模型（在 PC 上用 PyTorch/TensorFlow）。
量化模型（把 float32 转成 int8，为了 DSP 效率）。
配置：你不需要写 DSP 代码，只需要在 App 里配置“代理”（Delegate）或“后端”（Backend）。


IDL 哪里去了？

高通（或 Google）已经提前写好了通用的 .idl 和 skel.so。
比如 libQnnDsp.so 或 libhexagon_nn_skel.so。这些库就像一个“万能翻译官”，它能读懂你的神经网络层（Conv2d, Softmax 等），并指挥 DSP 去执行。


优点：开发快，不用懂 DSP 汇编，只要模型能跑通就行。
缺点：只能做神经网络相关的任务。如果你想做个特殊的“图像去雾算法”或者“音频变声”，这套框架帮不了你。

2. 第二条赛道：通用计算 (General Compute / Heterogeneous Computing)
关键词：Hexagon SDK, FastRPC, IDL, QAIC, C/C++, HVX/HMX
核心逻辑：“手写算子” (Custom Implementation)"><meta name=author content><link rel=canonical href=https://ethen-cao.github.io/ethenslab/explore-ai/npu-technology/><link crossorigin=anonymous href=/ethenslab/assets/css/stylesheet.a1917769c3c78460b110da6d7905321bb53af4a56f22ba4cc0de824cf4d097ab.css integrity="sha256-oZF3acPHhGCxENpteQUyG7U69KVvIrpMwN6CTPTQl6s=" rel="preload stylesheet" as=style><link rel=icon href=https://ethen-cao.github.io/ethenslab/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://ethen-cao.github.io/ethenslab/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://ethen-cao.github.io/ethenslab/favicon-32x32.png><link rel=apple-touch-icon href=https://ethen-cao.github.io/ethenslab/apple-touch-icon.png><link rel=mask-icon href=https://ethen-cao.github.io/ethenslab/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://ethen-cao.github.io/ethenslab/explore-ai/npu-technology/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://ethen-cao.github.io/ethenslab/explore-ai/npu-technology/"><meta property="og:site_name" content="Ethen 的实验室"><meta property="og:title" content="Ethen 的实验室"><meta property="og:description" content="Hexagon DSP 的生态 在 Qualcomm Hexagon DSP 的生态中，可以把资源的使用方式明确划分为两条主要赛道。它们针对的场景不同，开发难度不同，工具链也完全不同。
1. 第一条赛道：AI 推理 (AI Inference) 关键词：TFLite, ONNX, SNPE, QNN, NNAPI 核心逻辑：“模型即代码” (Model is the code)
这是目前最主流的用法，主要用于深度学习。
主要工作： 训练模型（在 PC 上用 PyTorch/TensorFlow）。 量化模型（把 float32 转成 int8，为了 DSP 效率）。 配置：你不需要写 DSP 代码，只需要在 App 里配置“代理”（Delegate）或“后端”（Backend）。 IDL 哪里去了？ 高通（或 Google）已经提前写好了通用的 .idl 和 skel.so。 比如 libQnnDsp.so 或 libhexagon_nn_skel.so。这些库就像一个“万能翻译官”，它能读懂你的神经网络层（Conv2d, Softmax 等），并指挥 DSP 去执行。 优点：开发快，不用懂 DSP 汇编，只要模型能跑通就行。 缺点：只能做神经网络相关的任务。如果你想做个特殊的“图像去雾算法”或者“音频变声”，这套框架帮不了你。 2. 第二条赛道：通用计算 (General Compute / Heterogeneous Computing) 关键词：Hexagon SDK, FastRPC, IDL, QAIC, C/C++, HVX/HMX 核心逻辑：“手写算子” (Custom Implementation)"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="explore-ai"><meta name=twitter:card content="summary"><meta name=twitter:title content><meta name=twitter:description content="Hexagon DSP 的生态
在 Qualcomm Hexagon DSP 的生态中，可以把资源的使用方式明确划分为两条主要赛道。它们针对的场景不同，开发难度不同，工具链也完全不同。
1. 第一条赛道：AI 推理 (AI Inference)
关键词：TFLite, ONNX, SNPE, QNN, NNAPI
核心逻辑：“模型即代码” (Model is the code)
这是目前最主流的用法，主要用于深度学习。

主要工作：

训练模型（在 PC 上用 PyTorch/TensorFlow）。
量化模型（把 float32 转成 int8，为了 DSP 效率）。
配置：你不需要写 DSP 代码，只需要在 App 里配置“代理”（Delegate）或“后端”（Backend）。


IDL 哪里去了？

高通（或 Google）已经提前写好了通用的 .idl 和 skel.so。
比如 libQnnDsp.so 或 libhexagon_nn_skel.so。这些库就像一个“万能翻译官”，它能读懂你的神经网络层（Conv2d, Softmax 等），并指挥 DSP 去执行。


优点：开发快，不用懂 DSP 汇编，只要模型能跑通就行。
缺点：只能做神经网络相关的任务。如果你想做个特殊的“图像去雾算法”或者“音频变声”，这套框架帮不了你。

2. 第二条赛道：通用计算 (General Compute / Heterogeneous Computing)
关键词：Hexagon SDK, FastRPC, IDL, QAIC, C/C++, HVX/HMX
核心逻辑：“手写算子” (Custom Implementation)"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Explore AI","item":"https://ethen-cao.github.io/ethenslab/explore-ai/"},{"@type":"ListItem","position":2,"name":"","item":"https://ethen-cao.github.io/ethenslab/explore-ai/npu-technology/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"","name":"","description":"Hexagon DSP 的生态 在 Qualcomm Hexagon DSP 的生态中，可以把资源的使用方式明确划分为两条主要赛道。它们针对的场景不同，开发难度不同，工具链也完全不同。\n1. 第一条赛道：AI 推理 (AI Inference) 关键词：TFLite, ONNX, SNPE, QNN, NNAPI 核心逻辑：“模型即代码” (Model is the code)\n这是目前最主流的用法，主要用于深度学习。\n主要工作： 训练模型（在 PC 上用 PyTorch/TensorFlow）。 量化模型（把 float32 转成 int8，为了 DSP 效率）。 配置：你不需要写 DSP 代码，只需要在 App 里配置“代理”（Delegate）或“后端”（Backend）。 IDL 哪里去了？ 高通（或 Google）已经提前写好了通用的 .idl 和 skel.so。 比如 libQnnDsp.so 或 libhexagon_nn_skel.so。这些库就像一个“万能翻译官”，它能读懂你的神经网络层（Conv2d, Softmax 等），并指挥 DSP 去执行。 优点：开发快，不用懂 DSP 汇编，只要模型能跑通就行。 缺点：只能做神经网络相关的任务。如果你想做个特殊的“图像去雾算法”或者“音频变声”，这套框架帮不了你。 2. 第二条赛道：通用计算 (General Compute / Heterogeneous Computing) 关键词：Hexagon SDK, FastRPC, IDL, QAIC, C/C++, HVX/HMX 核心逻辑：“手写算子” (Custom Implementation)\n","keywords":[],"articleBody":"Hexagon DSP 的生态 在 Qualcomm Hexagon DSP 的生态中，可以把资源的使用方式明确划分为两条主要赛道。它们针对的场景不同，开发难度不同，工具链也完全不同。\n1. 第一条赛道：AI 推理 (AI Inference) 关键词：TFLite, ONNX, SNPE, QNN, NNAPI 核心逻辑：“模型即代码” (Model is the code)\n这是目前最主流的用法，主要用于深度学习。\n主要工作： 训练模型（在 PC 上用 PyTorch/TensorFlow）。 量化模型（把 float32 转成 int8，为了 DSP 效率）。 配置：你不需要写 DSP 代码，只需要在 App 里配置“代理”（Delegate）或“后端”（Backend）。 IDL 哪里去了？ 高通（或 Google）已经提前写好了通用的 .idl 和 skel.so。 比如 libQnnDsp.so 或 libhexagon_nn_skel.so。这些库就像一个“万能翻译官”，它能读懂你的神经网络层（Conv2d, Softmax 等），并指挥 DSP 去执行。 优点：开发快，不用懂 DSP 汇编，只要模型能跑通就行。 缺点：只能做神经网络相关的任务。如果你想做个特殊的“图像去雾算法”或者“音频变声”，这套框架帮不了你。 2. 第二条赛道：通用计算 (General Compute / Heterogeneous Computing) 关键词：Hexagon SDK, FastRPC, IDL, QAIC, C/C++, HVX/HMX 核心逻辑：“手写算子” (Custom Implementation)\n这是传统的嵌入式开发用法。\n主要工作： 定义接口：必须写 .idl 文件，告诉 CPU 和 DSP 怎么传参数。 生成胶水代码：使用 QAIC 编译 IDL，生成 Stub 和 Skel。 实现算法：在 DSP 侧写 C/C++ 代码（Skel 实现）。如果是为了高性能，你甚至需要用 Hexagon Intrinsics 手写向量化指令（利用 HVX 硬件加速）。 IDL 的作用： 因为你的函数是自定义的（例如 my_special_image_filter()），高通没法预知，所以必须由你通过 IDL 定义，并由 QAIC 生成专用的桥梁。 优点： 极高的自由度：可以做任何计算任务（图像处理、CV 算法、音频编解码、加密解密、传感器数据融合）。 极致性能：你可以手写汇编级优化，榨干 DSP 的每一个时钟周期。 缺点：门槛极高，需要懂内存管理、多线程同步、向量化编程，还要处理复杂的签名和打包流程。 对比总结表 特性 途径 1: AI 框架 (TFLite/ONNX) 途径 2: 普通 DSP 开发 (FastRPC) 输入物 神经网络模型文件 (.tflite, .onnx, .dlc) C/C++ 源代码 + .idl 接口定义 中间工具 模型转换器 (Converter / Quantizer) QAIC 编译器 运行库 通用推理引擎 (libQnnDsp.so, libSnpeDsp.so) 你编译生成的专用库 (lib_skel.so) 是否需要 IDL 不需要 (框架内部封装好了) 必须需要 主要难点 模型量化精度损失、算子支持度 内存管理、并行编程、HVX 向量化优化 典型场景 物体检测、人脸识别、语音识别 图像预处理(缩放/旋转)、ISP 算法、音频降噪 它们有交集吗？ 有，而且很重要。\n这就是所谓的 “Custom Operator” (自定义算子)。 假设你在跑一个 TFLite 模型，里面有一个很新的数学运算层（比如某种特殊的 Attention 机制），TFLite 的 DSP 代理不支持它。 这时候，你需要：\n走 途径 2：写 .idl，用 C++ 实现这个特殊的算子，编译成一个 DSP 库。 走 途径 1：告诉 TFLite，“遇到这个特殊的层，请调用我刚才写的那个库”。 所以，途径 2 其实是途径 1 的底层基石。\n神经网络相关的任务简介 当我们说“基于 TFLite/ONNX 等框架只能做神经网络相关的任务”时，意思是这套工具链的本质是**“解释器”（Interpreter）**。\n它不懂你的 C++ 业务逻辑，它只懂**“张量运算”（Matrix Math）**。它的唯一工作就是加载一个你训练好的模型文件，把输入数据喂进去，算出输出结果。\n具体来说，这些任务通常指的是可以用深度学习模型（Deep Learning Models）解决的问题。\n以下是这类任务的具体分类和典型例子：\n1. 计算机视觉 (Computer Vision - CV) 这是 DSP 上最常见的神经网络任务。输入是图片/视频帧，输出是识别结果。\n物体检测 (Object Detection): 识别画面里哪里有人、车、红绿灯。（典型模型：YOLO, SSD, EfficientDet）。 图像分类 (Image Classification): 判断这张图是“猫”还是“狗”。（典型模型：MobileNet, ResNet）。 语义分割 (Semantic Segmentation): 把背景虚化（比如视频会议换背景），或者自动驾驶中识别哪里是路面。（典型模型：DeepLab, UNet）。 人脸关键点 (Face Landmark): 识别眼睛、鼻子嘴巴的位置，用于美颜、贴纸特效。 超分辨率 (Super Resolution): 把 720p 的模糊视频通过 AI 猜想变成 1080p 清晰视频。 2. 音频与语音处理 (Audio \u0026 Speech) 输入是麦克风的音频流，输出是文字或增强后的音频。\n关键词唤醒 (Keyword Spotting): 手机待机时监听“Hey Siri”或“小爱同学”。这是一个极小的神经网络，常驻 DSP。 语音降噪 (AI Noise Suppression): 区分人声和背景噪音（如风扇声），只保留人声。（传统降噪是用滤波算法，现在流行用 RNN/LSTM 神经网络做）。 声纹识别 (Speaker Verification): 确认说话的人是不是机主。 3. 自然语言处理 (Natural Language - NLP) 虽然大模型（LLM）通常跑在 NPU 上，但 DSP 也可以处理轻量级的 NLP 任务。\n意图识别: 比如输入“定明天的闹钟”，模型判断这是一个“设置闹钟”的指令。 智能键盘预测: 预测你下一个要打的字。 关键区别：它“不能”做什么？ 为了更清楚边界在哪里，我们来看看哪些任务不属于“神经网络相关任务”，因此不能用 TFLite/ONNX 途径，而必须用 FastRPC + C++ (IDL) 的方式去开发：\n传统的 ISP 图像处理:\n比如：Bayer 格式转 RGB、白平衡算法 (AWB)、镜头畸变校正。 这些主要靠几何计算和查表，不是靠神经网络的“权重”算出来的。 虽然现在也有 AI-ISP，但传统流程依然是 C++ 算法的主场。 特征点匹配 (传统 CV):\n比如：ORB, SIFT, RANSAC 算法。 这些算法包含大量的 if-else 逻辑判断、循环和排序。神经网络框架（TFLite）处理大量的逻辑分支效率极低，它擅长的是乘法和加法。 编解码 (Codec):\n比如：解析 H.264 视频流，或者解码 MP3/AAC 音频。 这是严格标准的数学流程，不能用神经网络去“猜”。 传感器融合 (Sensor Fusion):\n比如：把加速度计、陀螺仪和 GPS 的数据结合起来计算车辆位置（卡尔曼滤波）。 这是一套纯数学公式，完全不需要神经网络。 总结 如果你有一个 .tflite 或 .onnx 文件，里面装满了卷积层（Conv）、激活层（Relu），那就是途径 1。 如果你有一堆 C++ 代码，里面充满了 for 循环、if 判断、数学公式（FFT、矩阵求逆），那就是途径 2。 TFLite/SNPE 就像是一个“播放器”，它只能播放“神经网络”这一种格式的“影片”。如果你想在这个播放器里运行一个 Excel 表格（复杂的逻辑控制），它是做不到的。\n","wordCount":"354","inLanguage":"en","datePublished":"0001-01-01T00:00:00Z","dateModified":"0001-01-01T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://ethen-cao.github.io/ethenslab/explore-ai/npu-technology/"},"publisher":{"@type":"Organization","name":"Ethen 的实验室","logo":{"@type":"ImageObject","url":"https://ethen-cao.github.io/ethenslab/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://ethen-cao.github.io/ethenslab/ accesskey=h title="Ethen 的实验室 (Alt + H)">Ethen 的实验室</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://ethen-cao.github.io/ethenslab/android-dev/ title=Android系统开发><span>Android系统开发</span></a></li><li><a href=https://ethen-cao.github.io/ethenslab/android-automotive-os-dev/ title="Android Automotive"><span>Android Automotive</span></a></li><li><a href=https://ethen-cao.github.io/ethenslab/qnx/ title=QNX开发><span>QNX开发</span></a></li><li><a href=https://ethen-cao.github.io/ethenslab/gunyah/ title=Gunyah><span>Gunyah</span></a></li><li><a href=https://ethen-cao.github.io/ethenslab/ivi-solution/ title=智能座舱方案><span>智能座舱方案</span></a></li><li><a href=https://ethen-cao.github.io/ethenslab/explore-ai title="Explore AI"><span>Explore AI</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://ethen-cao.github.io/ethenslab/>Home</a>&nbsp;»&nbsp;<a href=https://ethen-cao.github.io/ethenslab/explore-ai/>Explore AI</a></div><h1 class="post-title entry-hint-parent"></h1><div class=post-meta>2 min&nbsp;·&nbsp;354 words</div></header><div class=post-content><h2 id=hexagon-dsp-的生态>Hexagon DSP 的生态<a hidden class=anchor aria-hidden=true href=#hexagon-dsp-的生态>#</a></h2><p>在 Qualcomm Hexagon DSP 的生态中，可以把资源的使用方式明确划分为<strong>两条主要赛道</strong>。它们针对的场景不同，开发难度不同，工具链也完全不同。</p><h3 id=1-第一条赛道ai-推理-ai-inference>1. 第一条赛道：AI 推理 (AI Inference)<a hidden class=anchor aria-hidden=true href=#1-第一条赛道ai-推理-ai-inference>#</a></h3><p><strong>关键词</strong>：TFLite, ONNX, SNPE, QNN, NNAPI
<strong>核心逻辑</strong>：<strong>“模型即代码” (Model is the code)</strong></p><p>这是目前最主流的用法，主要用于深度学习。</p><ul><li><strong>主要工作</strong>：<ul><li>训练模型（在 PC 上用 PyTorch/TensorFlow）。</li><li>量化模型（把 float32 转成 int8，为了 DSP 效率）。</li><li><strong>配置</strong>：你不需要写 DSP 代码，只需要在 App 里配置“代理”（Delegate）或“后端”（Backend）。</li></ul></li><li><strong>IDL 哪里去了？</strong><ul><li>高通（或 Google）已经提前写好了通用的 <code>.idl</code> 和 <code>skel.so</code>。</li><li>比如 <code>libQnnDsp.so</code> 或 <code>libhexagon_nn_skel.so</code>。这些库就像一个“万能翻译官”，它能读懂你的神经网络层（Conv2d, Softmax 等），并指挥 DSP 去执行。</li></ul></li><li><strong>优点</strong>：开发快，不用懂 DSP 汇编，只要模型能跑通就行。</li><li><strong>缺点</strong>：只能做神经网络相关的任务。如果你想做个特殊的“图像去雾算法”或者“音频变声”，这套框架帮不了你。</li></ul><h3 id=2-第二条赛道通用计算-general-compute--heterogeneous-computing>2. 第二条赛道：通用计算 (General Compute / Heterogeneous Computing)<a hidden class=anchor aria-hidden=true href=#2-第二条赛道通用计算-general-compute--heterogeneous-computing>#</a></h3><p><strong>关键词</strong>：Hexagon SDK, FastRPC, IDL, QAIC, C/C++, HVX/HMX
<strong>核心逻辑</strong>：<strong>“手写算子” (Custom Implementation)</strong></p><p>这是传统的嵌入式开发用法。</p><ul><li><strong>主要工作</strong>：<ul><li><strong>定义接口</strong>：必须写 <code>.idl</code> 文件，告诉 CPU 和 DSP 怎么传参数。</li><li><strong>生成胶水代码</strong>：使用 <code>QAIC</code> 编译 IDL，生成 Stub 和 Skel。</li><li><strong>实现算法</strong>：在 DSP 侧写 C/C++ 代码（Skel 实现）。如果是为了高性能，你甚至需要用 <strong>Hexagon Intrinsics</strong> 手写向量化指令（利用 HVX 硬件加速）。</li></ul></li><li><strong>IDL 的作用</strong>：<ul><li>因为你的函数是自定义的（例如 <code>my_special_image_filter()</code>），高通没法预知，所以必须由你通过 IDL 定义，并由 QAIC 生成专用的桥梁。</li></ul></li><li><strong>优点</strong>：<ul><li><strong>极高的自由度</strong>：可以做任何计算任务（图像处理、CV 算法、音频编解码、加密解密、传感器数据融合）。</li><li><strong>极致性能</strong>：你可以手写汇编级优化，榨干 DSP 的每一个时钟周期。</li></ul></li><li><strong>缺点</strong>：门槛极高，需要懂内存管理、多线程同步、向量化编程，还要处理复杂的签名和打包流程。</li></ul><hr><h3 id=对比总结表>对比总结表<a hidden class=anchor aria-hidden=true href=#对比总结表>#</a></h3><table><thead><tr><th style=text-align:left>特性</th><th style=text-align:left><strong>途径 1: AI 框架 (TFLite/ONNX)</strong></th><th style=text-align:left><strong>途径 2: 普通 DSP 开发 (FastRPC)</strong></th></tr></thead><tbody><tr><td style=text-align:left><strong>输入物</strong></td><td style=text-align:left>神经网络模型文件 (<code>.tflite</code>, <code>.onnx</code>, <code>.dlc</code>)</td><td style=text-align:left>C/C++ 源代码 + <code>.idl</code> 接口定义</td></tr><tr><td style=text-align:left><strong>中间工具</strong></td><td style=text-align:left>模型转换器 (Converter / Quantizer)</td><td style=text-align:left><strong>QAIC 编译器</strong></td></tr><tr><td style=text-align:left><strong>运行库</strong></td><td style=text-align:left>通用推理引擎 (<code>libQnnDsp.so</code>, <code>libSnpeDsp.so</code>)</td><td style=text-align:left>你编译生成的专用库 (<code>lib_skel.so</code>)</td></tr><tr><td style=text-align:left><strong>是否需要 IDL</strong></td><td style=text-align:left><strong>不需要</strong> (框架内部封装好了)</td><td style=text-align:left><strong>必须需要</strong></td></tr><tr><td style=text-align:left><strong>主要难点</strong></td><td style=text-align:left>模型量化精度损失、算子支持度</td><td style=text-align:left>内存管理、并行编程、HVX 向量化优化</td></tr><tr><td style=text-align:left><strong>典型场景</strong></td><td style=text-align:left>物体检测、人脸识别、语音识别</td><td style=text-align:left>图像预处理(缩放/旋转)、ISP 算法、音频降噪</td></tr></tbody></table><h3 id=它们有交集吗>它们有交集吗？<a hidden class=anchor aria-hidden=true href=#它们有交集吗>#</a></h3><p><strong>有，而且很重要。</strong></p><p>这就是所谓的 <strong>&ldquo;Custom Operator&rdquo; (自定义算子)</strong>。
假设你在跑一个 TFLite 模型，里面有一个很新的数学运算层（比如某种特殊的 Attention 机制），TFLite 的 DSP 代理不支持它。
这时候，你需要：</p><ol><li>走 <strong>途径 2</strong>：写 <code>.idl</code>，用 C++ 实现这个特殊的算子，编译成一个 DSP 库。</li><li>走 <strong>途径 1</strong>：告诉 TFLite，“遇到这个特殊的层，请调用我刚才写的那个库”。</li></ol><p>所以，<strong>途径 2 其实是途径 1 的底层基石</strong>。</p><h4 id=神经网络相关的任务简介>神经网络相关的任务简介<a hidden class=anchor aria-hidden=true href=#神经网络相关的任务简介>#</a></h4><p>当我们说“基于 TFLite/ONNX 等框架<strong>只能做神经网络相关的任务</strong>”时，意思是这套工具链的本质是**“解释器”（Interpreter）**。</p><p>它不懂你的 C++ 业务逻辑，它只懂**“张量运算”（Matrix Math）**。它的唯一工作就是加载一个你训练好的模型文件，把输入数据喂进去，算出输出结果。</p><p>具体来说，这些任务通常指的是<strong>可以用深度学习模型（Deep Learning Models）解决的问题</strong>。</p><p>以下是这类任务的具体分类和典型例子：</p><h5 id=1-计算机视觉-computer-vision---cv>1. 计算机视觉 (Computer Vision - CV)<a hidden class=anchor aria-hidden=true href=#1-计算机视觉-computer-vision---cv>#</a></h5><p>这是 DSP 上最常见的神经网络任务。输入是图片/视频帧，输出是识别结果。</p><ul><li><strong>物体检测 (Object Detection)</strong>: 识别画面里哪里有人、车、红绿灯。（典型模型：YOLO, SSD, EfficientDet）。</li><li><strong>图像分类 (Image Classification)</strong>: 判断这张图是“猫”还是“狗”。（典型模型：MobileNet, ResNet）。</li><li><strong>语义分割 (Semantic Segmentation)</strong>: 把背景虚化（比如视频会议换背景），或者自动驾驶中识别哪里是路面。（典型模型：DeepLab, UNet）。</li><li><strong>人脸关键点 (Face Landmark)</strong>: 识别眼睛、鼻子嘴巴的位置，用于美颜、贴纸特效。</li><li><strong>超分辨率 (Super Resolution)</strong>: 把 720p 的模糊视频通过 AI 猜想变成 1080p 清晰视频。</li></ul><h5 id=2-音频与语音处理-audio--speech>2. 音频与语音处理 (Audio & Speech)<a hidden class=anchor aria-hidden=true href=#2-音频与语音处理-audio--speech>#</a></h5><p>输入是麦克风的音频流，输出是文字或增强后的音频。</p><ul><li><strong>关键词唤醒 (Keyword Spotting)</strong>: 手机待机时监听“Hey Siri”或“小爱同学”。这是一个极小的神经网络，常驻 DSP。</li><li><strong>语音降噪 (AI Noise Suppression)</strong>: 区分人声和背景噪音（如风扇声），只保留人声。（传统降噪是用滤波算法，现在流行用 RNN/LSTM 神经网络做）。</li><li><strong>声纹识别 (Speaker Verification)</strong>: 确认说话的人是不是机主。</li></ul><h5 id=3-自然语言处理-natural-language---nlp>3. 自然语言处理 (Natural Language - NLP)<a hidden class=anchor aria-hidden=true href=#3-自然语言处理-natural-language---nlp>#</a></h5><p>虽然大模型（LLM）通常跑在 NPU 上，但 DSP 也可以处理轻量级的 NLP 任务。</p><ul><li><strong>意图识别</strong>: 比如输入“定明天的闹钟”，模型判断这是一个“设置闹钟”的指令。</li><li><strong>智能键盘预测</strong>: 预测你下一个要打的字。</li></ul><hr><h5 id=关键区别它不能做什么>关键区别：它“不能”做什么？<a hidden class=anchor aria-hidden=true href=#关键区别它不能做什么>#</a></h5><p>为了更清楚边界在哪里，我们来看看哪些任务<strong>不属于</strong>“神经网络相关任务”，因此<strong>不能</strong>用 TFLite/ONNX 途径，而必须用 <strong>FastRPC + C++ (IDL)</strong> 的方式去开发：</p><ol><li><p><strong>传统的 ISP 图像处理</strong>:</p><ul><li>比如：<strong>Bayer 格式转 RGB</strong>、<strong>白平衡算法 (AWB)</strong>、<strong>镜头畸变校正</strong>。</li><li>这些主要靠几何计算和查表，不是靠神经网络的“权重”算出来的。</li><li><em>虽然现在也有 AI-ISP，但传统流程依然是 C++ 算法的主场。</em></li></ul></li><li><p><strong>特征点匹配 (传统 CV)</strong>:</p><ul><li>比如：<strong>ORB, SIFT, RANSAC</strong> 算法。</li><li>这些算法包含大量的 <code>if-else</code> 逻辑判断、循环和排序。神经网络框架（TFLite）处理大量的逻辑分支效率极低，它擅长的是乘法和加法。</li></ul></li><li><p><strong>编解码 (Codec)</strong>:</p><ul><li>比如：解析 H.264 视频流，或者解码 MP3/AAC 音频。</li><li>这是严格标准的数学流程，不能用神经网络去“猜”。</li></ul></li><li><p><strong>传感器融合 (Sensor Fusion)</strong>:</p><ul><li>比如：把加速度计、陀螺仪和 GPS 的数据结合起来计算车辆位置（<strong>卡尔曼滤波</strong>）。</li><li>这是一套纯数学公式，完全不需要神经网络。</li></ul></li></ol><h5 id=总结>总结<a hidden class=anchor aria-hidden=true href=#总结>#</a></h5><ul><li>如果你有一个 <strong><code>.tflite</code></strong> 或 <strong><code>.onnx</code></strong> 文件，里面装满了卷积层（Conv）、激活层（Relu），那就是<strong>途径 1</strong>。</li><li>如果你有一堆 <strong>C++ 代码</strong>，里面充满了 <code>for</code> 循环、<code>if</code> 判断、数学公式（FFT、矩阵求逆），那就是<strong>途径 2</strong>。</li></ul><p><img src=/ethenslab/images/licensed-image.jpeg alt="Image of neural network architecture layers"></p><p><img src=/ethenslab/images/licensed-image.jpeg alt="Image of neural network architecture layers"></p><p><strong>TFLite/SNPE 就像是一个“播放器”</strong>，它只能播放“神经网络”这一种格式的“影片”。如果你想在这个播放器里运行一个 Excel 表格（复杂的逻辑控制），它是做不到的。</p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://ethen-cao.github.io/ethenslab/>Ethen 的实验室</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script src=https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js></script><script>mermaid.initialize({startOnLoad:!0,theme:"default"})</script><script src=https://cdn.jsdelivr.net/npm/plantuml-encoder@1.4.0/dist/plantuml-encoder.min.js></script><script>(function(){const e=document.querySelectorAll("pre > code.language-plantuml, pre > code.language-planuml");e.forEach(e=>{const s=e.innerText,o=plantumlEncoder.encode(s),i="https://www.plantuml.com/plantuml/svg/"+o,t=document.createElement("img");t.src=i,t.alt="PlantUML Diagram",t.style.maxWidth="100%";const n=e.parentNode;n.parentNode.replaceChild(t,n)})})()</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>