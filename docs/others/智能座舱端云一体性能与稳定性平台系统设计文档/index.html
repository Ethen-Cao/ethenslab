<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Ethen 的实验室</title><meta name=keywords content><meta name=description content="智能座舱端云一体性能与稳定性平台 (Polaris 1.0) 系统设计文档
版本信息

  
      
          序号
          版本
          修订内容
          状态
          修订人
          日期
      
  
  
      
          1
          0.1
          First draft
          
          操权力
          2025/12/9
      
  

文档目的
本文档旨在全面定义 智能座舱端云一体性能与稳定性平台 (代号 Polaris 1.0) 的系统架构、功能需求及实施路径。本文档将服务于以下核心场景：

管理层决策：清晰阐述项目背景、痛点、ROI（投入产出比）及资源需求，作为立项审批与资源调度的依据。
跨部门协同：作为座舱平台部与车云平台部沟通数据协议、接口规范及边界划分的“蓝本”，确保端云技术方案的一致性。
工程落地指导：作为项目启动后的核心输入，指导研发团队进行端侧 Agent 开发、埋点设计及测试验收。

背景与问题定义
背景
当前智能座舱的数据建设存在数据维度失衡与底层感知缺失的问题，具体表现在以下三个方面：


应用质量量化手段缺失：目前虽已具备应用层的业务埋点能力（如 PV/UV、页面点击流），能支撑产品运营分析；但对于应用技术质量（如 Crash率、ANR率、错误日志）及 核心性能指标（如启动耗时、页面响应延迟）尚缺乏系统性的监控与度量手段，导致软件交付质量缺乏客观数据支撑。


平台侧缺乏云端可观测性：作为座舱底座的平台研发部门，目前缺乏专属的云端观测平台。对于线上车辆的系统级健康度（如 SystemServer 重启、关键服务存活、资源水位），研发团队缺乏实时获取线上运行时状态的能力，往往只能在故障发生后进行被动回溯。


系统稳定性保障体系亟待构建：随着智能座舱软件规模与复杂度的提升，单纯依赖线下测试已难以覆盖所有边缘场景。为了保障用户体验，亟需构建一套严谨的、标准化的端云一体性能与稳定性监控平台，实现对线上真实运行质量的精准监测与闭环管理。


当前痛点

  
      
          痛点
          描述
          业务影响
      
  
  
      
          跨端故障排查成本较高
          当前缺乏跨端（Android-Linux-MCU）的自动化关联数据，面对复杂的跨域交互问题，排查过程往往需要人工拼接多端日志。
          研发效率受限：故障定位往往需要多方协同与多次排查，拉长了问题的解决周期。
      
      
          性能量化数据覆盖不足
          现有的性能评估主要依赖线下测试或有限样本，缺乏全量用户场景下的启动速度、流畅度等自动化量化数据。
          版本评价受限：难以精确捕捉版本迭代中的细微性能波动，线上实际体验的评估数据不够丰满。
      
      
          偶发异常现场回溯困难
          对于线上偶发的非必现问题，目前主要依赖事后尝试复现，缺乏异常发生瞬间的自动“快照”捕获机制。
          闭环周期较长：部分偶发性稳定性问题（如随机黑屏、卡顿）因缺乏现场数据支持，难以快速彻底根除。
      
      
          资源效能优化缺乏支撑
          缺乏进程级的 CPU、内存、IO 历史趋势画像，在进行精细化资源管控时缺乏足够的数据颗粒度。
          成本优化受限：硬件资源规划倾向于保守策略以保障稳定性，BOM 成本的进一步精细化挖掘存在困难。
      
  

目标与范围
项目目标
本项目旨在基于 “端侧深度探针 + 云端聚合分析 + 全链路追踪” 的技术理念，构建 Polaris 1.0 端云一体化平台，实现以下三个核心目标："><meta name=author content><link rel=canonical href=https://ethen-cao.github.io/ethenslab/others/%E6%99%BA%E8%83%BD%E5%BA%A7%E8%88%B1%E7%AB%AF%E4%BA%91%E4%B8%80%E4%BD%93%E6%80%A7%E8%83%BD%E4%B8%8E%E7%A8%B3%E5%AE%9A%E6%80%A7%E5%B9%B3%E5%8F%B0%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3/><link crossorigin=anonymous href=/ethenslab/assets/css/stylesheet.a1917769c3c78460b110da6d7905321bb53af4a56f22ba4cc0de824cf4d097ab.css integrity="sha256-oZF3acPHhGCxENpteQUyG7U69KVvIrpMwN6CTPTQl6s=" rel="preload stylesheet" as=style><link rel=icon href=https://ethen-cao.github.io/ethenslab/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://ethen-cao.github.io/ethenslab/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://ethen-cao.github.io/ethenslab/favicon-32x32.png><link rel=apple-touch-icon href=https://ethen-cao.github.io/ethenslab/apple-touch-icon.png><link rel=mask-icon href=https://ethen-cao.github.io/ethenslab/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://ethen-cao.github.io/ethenslab/others/%E6%99%BA%E8%83%BD%E5%BA%A7%E8%88%B1%E7%AB%AF%E4%BA%91%E4%B8%80%E4%BD%93%E6%80%A7%E8%83%BD%E4%B8%8E%E7%A8%B3%E5%AE%9A%E6%80%A7%E5%B9%B3%E5%8F%B0%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://ethen-cao.github.io/ethenslab/others/%E6%99%BA%E8%83%BD%E5%BA%A7%E8%88%B1%E7%AB%AF%E4%BA%91%E4%B8%80%E4%BD%93%E6%80%A7%E8%83%BD%E4%B8%8E%E7%A8%B3%E5%AE%9A%E6%80%A7%E5%B9%B3%E5%8F%B0%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3/"><meta property="og:site_name" content="Ethen 的实验室"><meta property="og:title" content="Ethen 的实验室"><meta property="og:description" content="智能座舱端云一体性能与稳定性平台 (Polaris 1.0) 系统设计文档 版本信息 序号 版本 修订内容 状态 修订人 日期 1 0.1 First draft 操权力 2025/12/9 文档目的 本文档旨在全面定义 智能座舱端云一体性能与稳定性平台 (代号 Polaris 1.0) 的系统架构、功能需求及实施路径。本文档将服务于以下核心场景：
管理层决策：清晰阐述项目背景、痛点、ROI（投入产出比）及资源需求，作为立项审批与资源调度的依据。 跨部门协同：作为座舱平台部与车云平台部沟通数据协议、接口规范及边界划分的“蓝本”，确保端云技术方案的一致性。 工程落地指导：作为项目启动后的核心输入，指导研发团队进行端侧 Agent 开发、埋点设计及测试验收。 背景与问题定义 背景 当前智能座舱的数据建设存在数据维度失衡与底层感知缺失的问题，具体表现在以下三个方面：
应用质量量化手段缺失：目前虽已具备应用层的业务埋点能力（如 PV/UV、页面点击流），能支撑产品运营分析；但对于应用技术质量（如 Crash率、ANR率、错误日志）及 核心性能指标（如启动耗时、页面响应延迟）尚缺乏系统性的监控与度量手段，导致软件交付质量缺乏客观数据支撑。
平台侧缺乏云端可观测性：作为座舱底座的平台研发部门，目前缺乏专属的云端观测平台。对于线上车辆的系统级健康度（如 SystemServer 重启、关键服务存活、资源水位），研发团队缺乏实时获取线上运行时状态的能力，往往只能在故障发生后进行被动回溯。
系统稳定性保障体系亟待构建：随着智能座舱软件规模与复杂度的提升，单纯依赖线下测试已难以覆盖所有边缘场景。为了保障用户体验，亟需构建一套严谨的、标准化的端云一体性能与稳定性监控平台，实现对线上真实运行质量的精准监测与闭环管理。
当前痛点 痛点 描述 业务影响 跨端故障排查成本较高 当前缺乏跨端（Android-Linux-MCU）的自动化关联数据，面对复杂的跨域交互问题，排查过程往往需要人工拼接多端日志。 研发效率受限：故障定位往往需要多方协同与多次排查，拉长了问题的解决周期。 性能量化数据覆盖不足 现有的性能评估主要依赖线下测试或有限样本，缺乏全量用户场景下的启动速度、流畅度等自动化量化数据。 版本评价受限：难以精确捕捉版本迭代中的细微性能波动，线上实际体验的评估数据不够丰满。 偶发异常现场回溯困难 对于线上偶发的非必现问题，目前主要依赖事后尝试复现，缺乏异常发生瞬间的自动“快照”捕获机制。 闭环周期较长：部分偶发性稳定性问题（如随机黑屏、卡顿）因缺乏现场数据支持，难以快速彻底根除。 资源效能优化缺乏支撑 缺乏进程级的 CPU、内存、IO 历史趋势画像，在进行精细化资源管控时缺乏足够的数据颗粒度。 成本优化受限：硬件资源规划倾向于保守策略以保障稳定性，BOM 成本的进一步精细化挖掘存在困难。 目标与范围 项目目标 本项目旨在基于 “端侧深度探针 + 云端聚合分析 + 全链路追踪” 的技术理念，构建 Polaris 1.0 端云一体化平台，实现以下三个核心目标："><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="others"><meta name=twitter:card content="summary"><meta name=twitter:title content><meta name=twitter:description content="智能座舱端云一体性能与稳定性平台 (Polaris 1.0) 系统设计文档
版本信息

  
      
          序号
          版本
          修订内容
          状态
          修订人
          日期
      
  
  
      
          1
          0.1
          First draft
          
          操权力
          2025/12/9
      
  

文档目的
本文档旨在全面定义 智能座舱端云一体性能与稳定性平台 (代号 Polaris 1.0) 的系统架构、功能需求及实施路径。本文档将服务于以下核心场景：

管理层决策：清晰阐述项目背景、痛点、ROI（投入产出比）及资源需求，作为立项审批与资源调度的依据。
跨部门协同：作为座舱平台部与车云平台部沟通数据协议、接口规范及边界划分的“蓝本”，确保端云技术方案的一致性。
工程落地指导：作为项目启动后的核心输入，指导研发团队进行端侧 Agent 开发、埋点设计及测试验收。

背景与问题定义
背景
当前智能座舱的数据建设存在数据维度失衡与底层感知缺失的问题，具体表现在以下三个方面：


应用质量量化手段缺失：目前虽已具备应用层的业务埋点能力（如 PV/UV、页面点击流），能支撑产品运营分析；但对于应用技术质量（如 Crash率、ANR率、错误日志）及 核心性能指标（如启动耗时、页面响应延迟）尚缺乏系统性的监控与度量手段，导致软件交付质量缺乏客观数据支撑。


平台侧缺乏云端可观测性：作为座舱底座的平台研发部门，目前缺乏专属的云端观测平台。对于线上车辆的系统级健康度（如 SystemServer 重启、关键服务存活、资源水位），研发团队缺乏实时获取线上运行时状态的能力，往往只能在故障发生后进行被动回溯。


系统稳定性保障体系亟待构建：随着智能座舱软件规模与复杂度的提升，单纯依赖线下测试已难以覆盖所有边缘场景。为了保障用户体验，亟需构建一套严谨的、标准化的端云一体性能与稳定性监控平台，实现对线上真实运行质量的精准监测与闭环管理。


当前痛点

  
      
          痛点
          描述
          业务影响
      
  
  
      
          跨端故障排查成本较高
          当前缺乏跨端（Android-Linux-MCU）的自动化关联数据，面对复杂的跨域交互问题，排查过程往往需要人工拼接多端日志。
          研发效率受限：故障定位往往需要多方协同与多次排查，拉长了问题的解决周期。
      
      
          性能量化数据覆盖不足
          现有的性能评估主要依赖线下测试或有限样本，缺乏全量用户场景下的启动速度、流畅度等自动化量化数据。
          版本评价受限：难以精确捕捉版本迭代中的细微性能波动，线上实际体验的评估数据不够丰满。
      
      
          偶发异常现场回溯困难
          对于线上偶发的非必现问题，目前主要依赖事后尝试复现，缺乏异常发生瞬间的自动“快照”捕获机制。
          闭环周期较长：部分偶发性稳定性问题（如随机黑屏、卡顿）因缺乏现场数据支持，难以快速彻底根除。
      
      
          资源效能优化缺乏支撑
          缺乏进程级的 CPU、内存、IO 历史趋势画像，在进行精细化资源管控时缺乏足够的数据颗粒度。
          成本优化受限：硬件资源规划倾向于保守策略以保障稳定性，BOM 成本的进一步精细化挖掘存在困难。
      
  

目标与范围
项目目标
本项目旨在基于 “端侧深度探针 + 云端聚合分析 + 全链路追踪” 的技术理念，构建 Polaris 1.0 端云一体化平台，实现以下三个核心目标："><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"杂记","item":"https://ethen-cao.github.io/ethenslab/others/"},{"@type":"ListItem","position":2,"name":"","item":"https://ethen-cao.github.io/ethenslab/others/%E6%99%BA%E8%83%BD%E5%BA%A7%E8%88%B1%E7%AB%AF%E4%BA%91%E4%B8%80%E4%BD%93%E6%80%A7%E8%83%BD%E4%B8%8E%E7%A8%B3%E5%AE%9A%E6%80%A7%E5%B9%B3%E5%8F%B0%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"","name":"","description":"智能座舱端云一体性能与稳定性平台 (Polaris 1.0) 系统设计文档 版本信息 序号 版本 修订内容 状态 修订人 日期 1 0.1 First draft 操权力 2025/12/9 文档目的 本文档旨在全面定义 智能座舱端云一体性能与稳定性平台 (代号 Polaris 1.0) 的系统架构、功能需求及实施路径。本文档将服务于以下核心场景：\n管理层决策：清晰阐述项目背景、痛点、ROI（投入产出比）及资源需求，作为立项审批与资源调度的依据。 跨部门协同：作为座舱平台部与车云平台部沟通数据协议、接口规范及边界划分的“蓝本”，确保端云技术方案的一致性。 工程落地指导：作为项目启动后的核心输入，指导研发团队进行端侧 Agent 开发、埋点设计及测试验收。 背景与问题定义 背景 当前智能座舱的数据建设存在数据维度失衡与底层感知缺失的问题，具体表现在以下三个方面：\n应用质量量化手段缺失：目前虽已具备应用层的业务埋点能力（如 PV/UV、页面点击流），能支撑产品运营分析；但对于应用技术质量（如 Crash率、ANR率、错误日志）及 核心性能指标（如启动耗时、页面响应延迟）尚缺乏系统性的监控与度量手段，导致软件交付质量缺乏客观数据支撑。\n平台侧缺乏云端可观测性：作为座舱底座的平台研发部门，目前缺乏专属的云端观测平台。对于线上车辆的系统级健康度（如 SystemServer 重启、关键服务存活、资源水位），研发团队缺乏实时获取线上运行时状态的能力，往往只能在故障发生后进行被动回溯。\n系统稳定性保障体系亟待构建：随着智能座舱软件规模与复杂度的提升，单纯依赖线下测试已难以覆盖所有边缘场景。为了保障用户体验，亟需构建一套严谨的、标准化的端云一体性能与稳定性监控平台，实现对线上真实运行质量的精准监测与闭环管理。\n当前痛点 痛点 描述 业务影响 跨端故障排查成本较高 当前缺乏跨端（Android-Linux-MCU）的自动化关联数据，面对复杂的跨域交互问题，排查过程往往需要人工拼接多端日志。 研发效率受限：故障定位往往需要多方协同与多次排查，拉长了问题的解决周期。 性能量化数据覆盖不足 现有的性能评估主要依赖线下测试或有限样本，缺乏全量用户场景下的启动速度、流畅度等自动化量化数据。 版本评价受限：难以精确捕捉版本迭代中的细微性能波动，线上实际体验的评估数据不够丰满。 偶发异常现场回溯困难 对于线上偶发的非必现问题，目前主要依赖事后尝试复现，缺乏异常发生瞬间的自动“快照”捕获机制。 闭环周期较长：部分偶发性稳定性问题（如随机黑屏、卡顿）因缺乏现场数据支持，难以快速彻底根除。 资源效能优化缺乏支撑 缺乏进程级的 CPU、内存、IO 历史趋势画像，在进行精细化资源管控时缺乏足够的数据颗粒度。 成本优化受限：硬件资源规划倾向于保守策略以保障稳定性，BOM 成本的进一步精细化挖掘存在困难。 目标与范围 项目目标 本项目旨在基于 “端侧深度探针 + 云端聚合分析 + 全链路追踪” 的技术理念，构建 Polaris 1.0 端云一体化平台，实现以下三个核心目标：\n","keywords":[],"articleBody":"智能座舱端云一体性能与稳定性平台 (Polaris 1.0) 系统设计文档 版本信息 序号 版本 修订内容 状态 修订人 日期 1 0.1 First draft 操权力 2025/12/9 文档目的 本文档旨在全面定义 智能座舱端云一体性能与稳定性平台 (代号 Polaris 1.0) 的系统架构、功能需求及实施路径。本文档将服务于以下核心场景：\n管理层决策：清晰阐述项目背景、痛点、ROI（投入产出比）及资源需求，作为立项审批与资源调度的依据。 跨部门协同：作为座舱平台部与车云平台部沟通数据协议、接口规范及边界划分的“蓝本”，确保端云技术方案的一致性。 工程落地指导：作为项目启动后的核心输入，指导研发团队进行端侧 Agent 开发、埋点设计及测试验收。 背景与问题定义 背景 当前智能座舱的数据建设存在数据维度失衡与底层感知缺失的问题，具体表现在以下三个方面：\n应用质量量化手段缺失：目前虽已具备应用层的业务埋点能力（如 PV/UV、页面点击流），能支撑产品运营分析；但对于应用技术质量（如 Crash率、ANR率、错误日志）及 核心性能指标（如启动耗时、页面响应延迟）尚缺乏系统性的监控与度量手段，导致软件交付质量缺乏客观数据支撑。\n平台侧缺乏云端可观测性：作为座舱底座的平台研发部门，目前缺乏专属的云端观测平台。对于线上车辆的系统级健康度（如 SystemServer 重启、关键服务存活、资源水位），研发团队缺乏实时获取线上运行时状态的能力，往往只能在故障发生后进行被动回溯。\n系统稳定性保障体系亟待构建：随着智能座舱软件规模与复杂度的提升，单纯依赖线下测试已难以覆盖所有边缘场景。为了保障用户体验，亟需构建一套严谨的、标准化的端云一体性能与稳定性监控平台，实现对线上真实运行质量的精准监测与闭环管理。\n当前痛点 痛点 描述 业务影响 跨端故障排查成本较高 当前缺乏跨端（Android-Linux-MCU）的自动化关联数据，面对复杂的跨域交互问题，排查过程往往需要人工拼接多端日志。 研发效率受限：故障定位往往需要多方协同与多次排查，拉长了问题的解决周期。 性能量化数据覆盖不足 现有的性能评估主要依赖线下测试或有限样本，缺乏全量用户场景下的启动速度、流畅度等自动化量化数据。 版本评价受限：难以精确捕捉版本迭代中的细微性能波动，线上实际体验的评估数据不够丰满。 偶发异常现场回溯困难 对于线上偶发的非必现问题，目前主要依赖事后尝试复现，缺乏异常发生瞬间的自动“快照”捕获机制。 闭环周期较长：部分偶发性稳定性问题（如随机黑屏、卡顿）因缺乏现场数据支持，难以快速彻底根除。 资源效能优化缺乏支撑 缺乏进程级的 CPU、内存、IO 历史趋势画像，在进行精细化资源管控时缺乏足够的数据颗粒度。 成本优化受限：硬件资源规划倾向于保守策略以保障稳定性，BOM 成本的进一步精细化挖掘存在困难。 目标与范围 项目目标 本项目旨在基于 “端侧深度探针 + 云端聚合分析 + 全链路追踪” 的技术理念，构建 Polaris 1.0 端云一体化平台，实现以下三个核心目标：\n全链路可观测：打破 Android、Linux Host、MCU 的数据孤岛，建立统一的 全局事件标准 (Global Event ID)，将分散在不同系统的故障与状态数据聚合至同一平台，实现跨端调用的追踪，为后续的可视化链路分析奠定数据基础。\n故障现场自动聚合与关联：突破现有“日志碎片化”及“事后拉取不全”的局限。建立 “事件驱动”的现场快照机制，在异常发生瞬间，自动聚合与该事件强相关的全维度上下文信息（如 Trace、系统 Log、进程状态等）并生成 完整的故障证据包。这不仅实现了 Event 与 Log 的精准索引，更确保了现场信息的完整性，彻底解决因关键日志缺失导致无法定位的难题。\n数据驱动治理：建立系统级的性能与稳定性基线（Baseline），通过量化数据驱动版本质量验收与硬件资源优化，将质量管理从“定性”转向“定量”。\n核心 KPI 指标 维度 指标名称 目标值 (示例) 说明 质量 严重故障主动发现率 \u003e 90% 在用户报修前，通过平台主动捕获并预警系统级崩溃与卡顿。 效率 日志精准命中率 100% 每一个上报的严重异常事件，都能直接下载到对应的、正确的 Log 文件，无需人工筛选。 复现 致命问题现场捕获率 \u003e 80% 针对 Crash/Watchdog 等致命问题，确保有对应的 Trace/Log 可供分析。 成本 资源优化场景产出 TOP 5/季度 每季度识别并输出 5 个高资源消耗（CPU/内存）场景。 项目范围 范围内 端侧全栈感知体系：\nAndroid 深度探针：构建系统级监控服务 PolarisAgentService，实现对应用生命周期、核心服务状态、底层资源（LMK/IO/Binder）的全维度深度监听。 Linux/MCU 异构覆盖：建设 Linux Host 侧的系统健康守护进程，负责关键服务（Service）存活检测与系统指标采集；适配 MCU 遥测协议，实现异构芯片间的故障透传。 边缘智能处理：在端侧实现数据的预处理与清洗，包含事件聚合、流控防爆、日志现场的智能截取与压缩，减轻车云带宽压力。 标准化基础设施：建立《全局事件注册表》及自动化工具链，统一多端的数据定义与协议标准。 云端分析能力需求:\n元数据管理能力：要求云端支持同步《全局事件注册表》，实现对上报事件的自动化解析、分类与标签化管理。 自动化关联引擎：要求云端具备**“事件-日志”自动匹配能力**，将结构化的 Event 数据与非结构化的 Log 文件（基于索引）在存储层自动关联，形成完整的故障证据包。 趋势与模式识别：要求云端支持基于时间窗口的聚合计算，能够识别异常爆发（Spike）趋势及性能指标（CPU/内存）的长期演进趋势。 可视化与运营平台\n数字化质量驾驶舱：建设多维度的质量仪表盘（Dashboard），支持按版本、车型、时间段下钻分析千车故障率、性能基线达标率。 智能排查工作台：提供“一站式”问题分析界面，支持通过 EventID/TraceID 检索故障，直接浏览关联的日志、堆栈及设备状态，支持远程诊断指令的下发与结果展示。 范围外 可视化的全链路拓扑分析：1.0 阶段聚焦于跨端链路数据的 标准化采集与逻辑串联，优先夯实数据底座能力；全链路图形化的调用链拓扑展示规划在后续版本迭代中实现。 业务代码修复：Polaris 平台负责精准“定位”并“指派”问题，不负责 具体业务 APP 内部的代码逻辑修复。 交互体验设计：本项目专注于性能数据的量化，不包含 HMI 界面（UI/UE）的主观交互设计与优化。 业务流程与核心场景 角色定义 角色 职责描述 关注点 研发工程师 接收告警，分析堆栈与日志，修复 Bug；针对疑难客诉问题，远程下发特定诊断指令 故障堆栈的完整性，日志关联的准确性，是否需要补充更多运行时信息。 质量工程师 配置告警阈值，监控线上大盘水位，识别版本质量风险 故障率趋势是否劣化，性能指标是否符合预期，流量消耗是否异常。 产品经理 查看应用活跃度与性能体验趋势 核心功能的响应速度趋势，用户使用过程中的卡顿频率。 核心作业流程图 1. 故障主动发现闭环流程\n描述从异常发生到研发接入的处理路径\n捕获 (Capture): Polaris Agent 监听到异常（如 ANR），记录运行时状态，抓取 Trace/Logcat，并生成唯一 EventID。 处理 (Process): 端侧进行流量控制检查，通过 logf 索引将 Event 与 Log 文件进行逻辑组合。 上报 (Report): Event 数据实时上报，大文件 Log 在 WiFi/空闲时段异步上传（支持云端按需拉取）。 通知 (Notify): 云端检测到异常数据超过阈值（例如某版本 Crash 率上升），向 责任模块负责人 发送通知。 分析 (Analyze): 研发工程师查看通知，进入平台查看关联的上下文数据，确认问题根因并修复。 2. 疑难问题排查流程\n描述针对复杂客诉或非必现问题的处理路径\n检索: 研发工程师在平台输入车辆 VIN 码或 EventID 检索相关记录。 查看: 系统展示该事件的发生时间、设备信息、以及已自动关联的 Log 文件下载链接。 诊断: 针对区域技术支持无法处理的复杂客诉，若现有日志不足以定位，研发工程师 通过控制台下发 Shell 诊断指令，端侧执行后回传结果，以获取更深度的运行时信息。 典型用户故事 场景一：风险预警 背景: 某车型灰度推送 v1.5 OTA 版本。 事件: 上线 24 小时内，Polaris 平台监测到 GVM_SYS_STORAGE_LOW（磁盘空间不足）事件在特定批次车辆上的上报量呈异常上升趋势。 行动:\n平台自动触发 风险预警，即时通知研发负责人。 研发工程师通过平台获取存储分布数据，精准定位到某应用私有目录占用空间急剧膨胀。 分析: 结合自动关联采样的 Log，确认该应用在特定异常分支下陷入数据库高频重复写入死循环。 结果: 研发团队在磁盘被完全耗尽导致系统挂死（System Hang）前，紧急输出修复补丁并推送 OTA，成功拦截了批量重大事故。 场景二：稳定性治理 背景: 某应用发布 v2.0 灰度版本。 事件: 灰度发布期间，平台监测到应用出现偶发性 GVM_APP_ANR（无响应）告警，且线下测试难以复现。 行动:\n研发工程师点击告警详情，查看聚合后的故障样本。 系统已通过 logf 字段自动关联了故障时刻的 traces.txt 以及系统侧 perflog (性能日志)。 分析: 工程师通过 Trace 文件发现应用主线程阻塞在 Binder IPC 调用中；进一步联合分析 perflog，定位到是对端 Service 在高并发场景下因锁竞争导致处理耗时过长，拖累了客户端。 结果: 确认根因为服务端卡顿。研发工程师针对服务端逻辑进行异步化优化，彻底解决了这一隐蔽的跨进程阻塞问题。 场景三：性能监控 背景: 某版本上线后，产品经理关注核心应用在复杂交互场景下的滑动流畅度。 事件: Polaris 仪表盘显示 GVM_APP_JANK (掉帧/卡顿) 指标在特定列表滑动场景下出现劣化趋势。 行动:\n系统展示了掉帧率与主线程负载的关联曲线。 发现: 在卡顿发生的时间段内，主线程 MessageQueue 待处理消息数量显著激增。 分析: 研发工程师通过分析采集到的 Looper 统计数据，发现是一次性加载过多列表项导致并在主线程频繁 Post UI 刷新消息，引发主线程消息队列积压，从而阻塞了渲染信号（Vsync）的处理。 结果: 研发工程师引入消息合并与节流机制（Throttling），消除了主线程拥堵，恢复了滑动流畅性。 场景四：远程指令下发 背景: 用户反馈方控按键（下一曲）失效，或错误地控制了不显示在屏幕上的后台音乐应用，常规 Logcat 无法体现系统内部的分发逻辑。 行动:\n研发工程师怀疑是 MediaSession 焦点抢占或状态同步异常。 工程师通过 Polaris 控制台，向目标车辆下发 dumpsys media_session 指令。 分析: 回传的诊断结果显示，Media button session 仍被后台应用 com.reachauto.clouddesk 占用（尽管其状态为 active=false），导致按键事件未正确分发给前台亮屏的 com.tencent.wecarflow。 结果: 确认根因是后台应用未正确释放焦点，研发工程师将 Bug 准确指派给相关应用团队，无需现场抓包。 需求拆解 本章节将 Polaris 1.0 平台的核心需求拆解为四大关键能力域。这些能力定义了系统的边界与核心价值，是后续详细功能设计的基础。 本章节采用能力域（Capability Domain）拆解方法，以系统应具备的核心能力为中心，而非具体功能或实现方式。每一能力域仅定义目标、适用范围与责任边界，不涉及接口设计、数据结构或技术选型细节。具体功能点将在后续《功能性需求》中展开，质量与约束要求将在《非功能性需求》中统一定义。\n稳定性全栈感知能力 目标：构建覆盖 Android 应用层、系统框架层以及 Linux Host/MCU 异构计算单元的异常捕获体系，实现全栈、全维度的故障感知与现场数据留存。\n能力名称 能力描述与目标 适用范围 责任边界 应用层稳定性监控\n(App Layer Stability) 描述：具备对 Android 应用层 (APK) 致命异常的实时监测能力。涵盖 Java Crash、App Native Crash (JNI)、ANR 及 App OOM；在异常触发时同步执行现场冻结与堆栈抓取。\n目标：确保应用级崩溃捕获率 \u003e 98%，异常现场数据完整性 100%。 Android Framework\nThird-party Apps\nSystem Apps (Launcher等) 负责：捕获应用堆栈、页面栈及进程状态；\n不负责：分析应用内部具体的业务逻辑错误。 系统框架稳定性监控\n(System Framework Stability) 描述：具备对 Android 核心服务及关键守护进程的存活状态监测能力；识别系统级资源耗尽风险（如 Binder 耗尽、句柄泄漏、LMK）。\n目标：准确识别 SystemServer 死锁 (Watchdog)、核心服务崩溃、系统异常重启及严重资源拥堵事件。 SystemServer\nBinder Driver\nNative Daemons (SurfaceFlinger等) 负责：识别导致系统不稳定的服务异常和资源瓶颈；\n不负责：介入 Linux Kernel 内部调度机制的调试。 异构运行环境监控\n(Heterogeneous Env Monitoring) 描述：具备对 Linux Host (PVM) 及 MCU 运行状态的独立监测能力。通过 Native Daemon 标准化采集 Linux 侧服务状态、系统重启事件以及 MCU 侧的心跳与硬件故障码。\n目标：实现对底层虚拟化环境与硬件外设健康状况的统一视图监控。 Linux Host (PVM)\nMCU\nHypervisor 负责：异构数据的标准化接入、协议对齐及状态监测；\n不负责：异构系统内部具体业务逻辑的监控实现。 性能与资源度量能力 目标：建立可量化的性能基线，从“主观体验”转向“客观数据”，实现对计算资源（CPU/Mem/IO）的精细化审计。\n能力名称 能力描述与目标 适用范围 责任边界 交互体验量化 描述：具备对用户核心交互路径（冷/热启动、页面滑动、点击响应）的耗时与流畅度监测能力。\n目标：量化 App 启动速度与掉帧率（Jank），支持版本间性能对比。 Top 核心应用, Launcher, SystemUI 负责采集关键节点的耗时数据；不负责 UI 渲染流程的优化。 资源水位画像 描述：具备对进程级资源消耗（CPU使用率、内存占用、IO吞吐量）的周期性采样与超限识别能力。\n目标：识别“资源刺客”与异常泄漏，绘制 24h 资源趋势图。 所有运行状态下的进程 负责资源数据的统计与归因；不负责系统资源调度策略。 异常爆发检测 描述：具备对特定异常事件（如连续 Crash、持续高负载）的频率统计与突变识别能力。\n目标：防止单点故障引发的“告警风暴”，并在端侧进行初步降噪。 全局事件流 负责端侧的流控与阈值判断。 现场还原与协同能力 目标：解决“有报警无日志”的痛点，构建端云协同的自动化取证与远程诊断通道。\n能力名称 能力描述与目标 适用范围 责任边界 标准化事件协议体系 描述：基于《全局事件注册表》构建统一的事件定义、序列化与解析能力。\n目标：确保端侧上报数据与云端解析引擎的语义一致性，支持协议动态扩展。 端侧 Agent, 车云 SDK, 云端解析服务 负责协议的定义与维护工具链；不限制业务 Payload 的具体内容。 智能现场快照 描述：具备“事件驱动”的自动化日志聚合能力，在异常发生瞬间关联并打包 Trace、Logcat 及系统状态信息。\n目标：实现 Event 与 Log 文件的 1:1 精准索引。 本地日志系统, 文件系统 负责日志的定位、截取与压缩；不负责日志内容的语义分析。 远程诊断执行 描述：具备安全可控的云端指令接收与本地执行能力，支持下发 Shell 脚本或调试命令。\n目标：在不打扰用户的前提下获取更深度的运行时信息。 Shell 环境, Debug 接口 负责指令通道的建立与执行结果回传；严禁执行未授权的高危写操作，不支持批量执行、默认灰度单车、需显式授权、强审计。 数据智能与运营能力 目标：将海量原始数据转化为可行动的洞察（Actionable Insights），支撑研发与质量团队的决策。\n能力名称 能力描述与目标 适用范围 责任边界 端云数据自动关联 描述：具备在海量存储中，根据索引自动将结构化事件与非结构化日志文件进行绑定的能力。\n目标：消除人工查找日志的成本。 云端存储层 负责数据的逻辑关联与存储生命周期管理。 实时风险预警 描述：具备基于时间窗口的流式计算能力，识别线上故障的爆发趋势并触发告警。\n目标：实现故障感知。 计算引擎 负责告警策略的计算与推送；不负责告警后的工单流转。 多维质量可视化 描述：具备多维度（版本/车型/时间/地区）的数据聚合与图表展示能力。\n目标：提供从“宏观大盘”到“微观个案”的钻取分析视图。 数据仓库, 可视化前端 负责数据的可视化呈现。 系统总体方案 总体设计概述 Polaris 1.0 基于 Hypervisor 虚拟化架构 设计，旨在构建跨越 GVM (Guest VM - Android)、PVM (Primary VM - Linux) 及 MCU 的端云一体化全栈监控系统。 系统采用 分层架构 与 模块化服务设计。在控制面上，通过 注册表驱动（Registry-Driven） 机制实现业务埋点定义与底层采集逻辑的解耦；在数据面上，通过 双守护进程（Dual Daemon） 机制打通异构芯片与系统的通信壁垒。系统将计算能力前置至端侧，通过 PolarisAgentService 实现数据的实时清洗、流控与现场关联，仅将高价值的结构化数据与诊断日志同步至云端。\n系统总体架构图 架构分层详解 业务应用与接口层 本层负责定义数据采集的标准接口，通过自动代码生成技术屏蔽底层通信细节：\nPolaris SDK: 面向上层业务应用（如 Launcher, Maps）。该组件由《全局事件注册表》编译生成，提供强类型的事件对象封装与校验逻辑，负责将业务数据序列化并传递给 Framework 层。 System Internal SDK: 面向 SystemServer 内部服务（如 AMS, WMS）。与 Polaris SDK 同源生成，专门用于系统关键服务内部的插桩（Instrumentation），以捕获服务级异常与状态变更。 Host SDK: 面向 PVM 侧的 Linux 应用程序（如 Cluster HMI）、系统核心服务，提供 C++ 标准上报接口，负责将 PVM 侧业务数据发送至 Host Daemon。 框架传输与核心服务层 本层位于 Android GVM，是数据汇聚、策略执行与处理的核心区域：\nPolaris SDK (Framework API): 部署于 AppFramework API 层。作为系统级的传输接口实现，它承接来自上层业务的调用请求，并维护与*PolarisAgentService的 IPC 通信链路，确保数据的可靠投递。\nPolarisAgentService: 常驻系统服务，内部包含五个核心功能模块：\nEventCollector: 统一接入模块。作为 Binder 服务端接收 Polaris SDK 请求；同时作为 LocalSocket 客户端，在服务启动时主动连接 Native Daemon 建立长连接通道，并通过后台线程实时拉取 Native 侧上报的事件流。 ConfigManager: 配置管理模块。负责加载本地注册表文件的配置，解析采样率、阈值及采集开关策略。 FlowController: 流量控制模块。对输入事件进行频率限制，防止异常爆发导致系统资源耗尽。 ContextEngine: 现场聚合模块。在事件通过流控后，负责生成唯一 EventID，挂载系统时间戳，并根据事件类型关联 Logcat、Trace 文件及进程快照，生成索引信息。 DiagnoseHandler: 诊断执行模块。负责校验并执行来自云端的诊断指令（Shell Command），并管理执行结果的回传。 原生与异构跨域层 本层负责 Android Runtime 之外的底层环境监控及跨虚拟机通信：\nPolaris Native Daemon (GVM):\n本地采集: 负责监控 Native 进程崩溃（Tombstone）、系统资源、及 HAL 层状态。\n跨域网关: 作为 GVM 侧的通信端点，维护与 PVM/MCU 的连接，接收跨域透传的数据。\nPolaris Host Daemon (PVM):\n宿主监控: 负责监控 PVM 侧的 systemd 服务状态、关键驱动状态及虚拟机管理服务（qcrosvm/VMM）。\n传输通道与云平台 VlmAgent: 统一传输网关。作为端侧唯一的数据出口，负责接收来自 PolarisAgentService 的结构化事件,以及日志文件（按需拉取），执行断点续传、数据压缩与网络流量调度。 Cloud Platform: 负责数据的计算、存储与可视化。 核心设计原则 进程级隔离与服务化：PolarisAgentService 设计为独立系统进程，而非 SystemServer 的内部线程。这种设计带来了两大优势： 稳定性：监控服务的异常（如 OOM）不会导致系统核心服务（SystemServer）崩溃，反之亦然。 高性能：独立的进程空间避免了与 AMS/WMS 争抢主线程资源，确保了监控逻辑的独立调度。 系统核心即客户端：确立 SystemServer 在监控体系中的 Client 身份。AMS、WMS 等核心服务通过 System Internal SDK，以跨进程调用（IPC）的方式向 Polaris 上报数据。这种“旁路监控”模式确保了对系统原有逻辑的最小侵入。 异构接入抽象化：针对 MCU 等异构单元，系统采用 “HAL 驱动适配 + Daemon 统一采集” 的接入原则。不强依赖特定的物理连接方式（如直连或透传），而是通过 Native 层的适配层（Adapter/HAL）屏蔽硬件连接差异，确保架构在不同车型硬件拓扑下的通用性与兼容性。 功能性需求 稳定性全栈感知能力 应用层稳定性监控 FR-STAB-001 应用 Java 崩溃 (Java Crash) 捕获 属性 内容 优先级 P0 前置条件 1.系统层已部署全局监控探针。\n2. 监控功能的配置开关处于开启状态。 输入 触发源：\n应用运行环境（Android Runtime）抛出的未捕获异常信号（Uncaught Exception）。\n数据：\n1. 异常堆栈信息（StackTrace）。\n2. 异常类型与描述消息（Exception Message）。 处理逻辑 1. 异常拦截：\n在应用进程因异常即将终止前，拦截异常信号，挂起当前线程以确保有足够的 CPU 时间片执行数据采集。\n2. 上下文捕获：\n提取崩溃时刻的运行时环境信息，包括但不限于：\n- 进程名称、线程名称及 ID。\n- 应用的前后台状态。\n- 当前 Activity 页面栈信息（用于还原用户路径）。\n3. 流控策略：\n执行本地频次控制策略。检查该进程在设定时间窗口（如 10 分钟）内的崩溃次数，若超限则降级处理（仅记录统计计数，不抓取详细堆栈），防止日志写入引发 IO 阻塞。\n4. 透传退出：\n数据采集完成后，必须将异常信号交还给系统默认处理程序，确保应用能够按照 Android 系统规范正常退出，防止应用界面假死或进程僵滞。 输出 1. 结构化事件：生成包含完整上下文信息的 GVM_APP_CRASH 事件对象。2. 本地日志：在本地持久化存储区保留一份异常日志备份（作为兜底）。 3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》 FR-STAB-002 应用无响应 (ANR) 捕获 属性 内容 优先级 P0 前置条件 1. 系统层已部署全局监控探针。\n2. 监控功能的配置开关处于开启状态。 输入 触发源：系统框架层（Framework）识别到的应用无响应信号（AppNotResponding）。\n数据：\n1. 目标应用进程标识（PID/ProcessName）。\n2. 系统生成的堆栈跟踪文件（Trace File，通常位于 /data/anr/ 目录）。 处理逻辑 1. 信号识别：\n实时接收系统 ActivityManagerService 发出的 ANR 通知。\n2. 目标过滤：\n根据配置白名单判断是否采集该进程，过滤非关注应用的 ANR 事件。3. 堆栈截取：\n读取系统生成的 Trace 文件，根据目标 PID 精准截取该进程及其子线程的堆栈片段（需剔除文件中的其他无关进程数据，以减少数据体积）。\n4. 快照关联：\n获取 ANR 发生时刻的系统负载信息（Load Avg / CPU Usage / IO Wait）并与堆栈信息打包。\n5. 流控策略：\n执行本地频次控制策略。检查该进程在设定时间窗口（如 10 分钟）内的 ANR 次数，若超限则仅记录计数，不再执行堆栈截取操作。 输出 1. 结构化事件：生成包含 Trace 附件索引（Reference）的 GVM_APP_ANR 事件对象。\n2. 本地日志：在本地持久化存储区生成关联的证据包（包含截取的 Trace 片段与系统负载快照）。\n3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》 FR-STAB-003 应用 Native 库崩溃 (App JNI Crash) 捕获 属性 内容 优先级 P0 前置条件 1. 系统层已部署全局监控探针（Native Daemon）。\n2. 监控功能的配置开关处于开启状态。 输入 触发源：\n应用进程（APP）加载的 JNI 动态库触发致命信号（SIGSEGV/SIGABRT）。\n数据：\n1. 系统生成的 Tombstone 崩溃文件（通常位于 /data/tombstones/）。\n2. 进程退出信号（Signal Code）。 处理逻辑 1. 监听与解析：\n实时监听系统 Tombstone 文件的生成事件，读取文件头部信息。\n2. 身份识别：\n检查崩溃进程的 UID 或进程名称。若属于非系统核心进程（即普通 App），则执行应用级采集逻辑；若为系统服务则忽略（交由系统框架监控处理）。\n3. 指纹去重：\n基于“应用名称 + 崩溃堆栈关键帧”生成唯一指纹，在端侧聚合重复的崩溃事件，防止日志风暴。\n4. 事件生成：\n将非结构化的 Tombstone 数据转换为标准化的事件对象。 输出 1. 结构化事件：生成 GVM_APP_NATIVE_CRASH 事件对象。\n2. 本地日志：建立事件 ID 与原始 Tombstone 文件的索引关联。\n3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》 FR-STAB-004 应用 OOM (App OOM) 事件监控 属性 内容 优先级 P0 前置条件 1. 系统层已部署全局监控探针。\n2. 监控功能的配置开关处于开启状态。\n3. 具备获取应用进程退出详细原因的能力（如 ApplicationExitInfo 或类似机制）。 输入 触发源：\n应用进程意外终止信号。\n数据：\n1. 进程退出原因描述（Exit Reason，需区分系统回收/异常崩溃）。\n2. 进程终止前的内存使用统计数据（如 PSS/RSS/VSS）。 处理逻辑 1. 原因甄别：\n在进程退出后，识别退出原因。准确区分是系统低内存查杀 (LMK)（通常表现为 REASON_LOW_MEMORY）还是Java 堆内存耗尽（通常表现为 OutOfMemoryError 导致的 Crash）引发的异常。\n2. 内存快照回溯：\n尝试关联该进程在终止前最近一次采集的内存统计数据（如 PSS/RSS），以辅助判断是否存在内存泄漏。\n3. 风暴抑制：\n针对前台应用因 OOM 导致的反复重启进行检测。若同一应用在短时间内（如 5 分钟）连续触发 OOM，则实施指数退避策略，减少上报频次。\n4. 事件生成：\n组装 OOM 事件负载，标记明确的 OOM 类型（System LMK / Java OOM）。 输出 1. 结构化事件：生成包含内存快照信息的 GVM_APP_OOM 事件对象。\n2. 本地日志：记录关联的系统内存水位信息（MemInfo）。\n3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》 系统框架稳定性监控 FR-STAB-005 SystemServer Watchdog (死锁) 监控 属性 内容 优先级 P0 前置条件 1. 监控探针已植入系统看门狗（Watchdog）模块或具备监听能力。\n2. 监控功能的配置开关处于开启状态。 输入 触发源：\n系统关键锁或核心线程（如 UI Thread, IoThread）等待超时信号（通常阈值为 60秒）。\n数据：\n1. 阻塞线程的完整堆栈信息（Stack Traces）。\n2. 持锁状态与锁竞争信息（Lock Contention）。 处理逻辑 1. 重启前拦截：\n在系统触发看门狗复位（Soft Reboot / Restart）流程前，优先执行监控逻辑，确保有短暂的时间窗口进行数据转存。\n2. 现场固化：\n立即将当前的系统全量线程堆栈（Traces.txt）复制或转存至持久化存储区，防止系统重启过程清理现场文件，导致关键证据丢失。\n3. 异常标记：\n在磁盘特定位置写入“非正常重启”标志位（Flag），以便系统下次启动时进行归因统计，区分正常关机与异常重启。\n4. 事件上报：\n尝试通过 Native 通道（因为 Java 层可能已挂死）发送死锁事件。 输出 1. 结构化事件：生成包含死锁堆栈索引的 GVM_SYS_WATCHDOG 事件对象。\n2. 本地日志：在持久化目录保留死锁现场的 Trace 文件。\n3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》 FR-STAB-006 Android 系统异常重启 (System Restart) 监控 属性 内容 优先级 P0 前置条件 1. 系统完成启动初始化流程（Boot Completed）。\n2. 具备读取系统启动属性（Boot Reason）及持久化存储的权限。 输入 触发源：\n系统启动完成广播 (Boot Completed) 或同等时机的初始化信号。\n数据：\n1. 系统启动原因属性（如 sys.boot.reason 或 ro.boot.bootreason）。\n2. 持久化存储中的历史状态标记（包含上一次启动时间戳、Watchdog/Crash 遗留的异常标志位）。 处理逻辑 1. 原因推断：\n对比本次启动原因与上一次运行状态进行逻辑仲裁：\n- 已知异常：若存在 Watchdog 或 Core Crash 遗留的标记，判定为对应的系统级故障重启。\n- 内核恐慌：若启动属性标识为 Kernel Panic 或 WDT（硬件看门狗），判定为内核级重启。\n- 正常重启：若标识为用户主动关机、OTA 升级或常规电源管理操作，判定为正常重启。\n- 掉电/未知：若无任何异常标记且非正常重启，判定为异常掉电或未知原因重启。\n2. 时长计算：\n基于上一次记录的启动时间戳，计算上一次系统正常运行的时长（Uptime），用于评估系统平均无故障时间（MTBF）。\n3. 状态重置：\n分析完成后，清除历史异常标记，更新本次启动时间戳，为下一次监控周期做准备。 输出 1. 结构化事件：生成包含重启原因分类（Category）及运行时长（Duration）的 GVM_SYS_RESTART 事件对象。\n2. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》 FR-STAB-007 核心服务崩溃 (Core Service Crash) 监控 属性 内容 优先级 P0 前置条件 1. 监控进程具备监听系统服务管理器（ServiceManager）或 init 进程状态的能力。\n2. 核心进程白名单配置已加载。 输入 触发源：\n1. Native 守护进程崩溃产生的 Tombstone 文件。\n2. ServiceManager 发出的 DeathRecipient 通知。\n3. init 进程发出的 SIGCHLD 信号。\n数据：\n1. 崩溃进程名称（Process Name）及 PID。\n2. 进程退出状态码或终止信号。 处理逻辑 1. 核心识别：\n匹配崩溃进程名称是否在核心白名单中（如 surfaceflinger, audioserver, netd, lmkd）。若不在白名单，则视为普通 Native Crash 处理（参考 FR-STAB-003）。\n2. 多源仲裁：\n优先使用 Tombstone 信息（包含详细堆栈），若未生成 Tombstone（如被系统强杀或 Watchdog 处决），则使用 ServiceManager 通知作为补充来源。\n3. 等级判定：\n根据服务重要性标记故障等级（例如 SurfaceFlinger 崩溃标记为“致命”，会导致屏幕黑屏或系统软重启）。\n4. 事件生成：\n组装核心服务崩溃事件，记录服务名称、崩溃时间及退出原因。 输出 1. 结构化事件：生成包含服务名及影响等级的 GVM_CORE_CRASH 事件对象。\n2. 本地日志：关联该时间点附近的系统日志（Logcat）与崩溃堆栈。\n3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》 FR-STAB-008 系统低内存 (LMK) 事件监控 属性 内容 优先级 P0 前置条件 1. 系统启用 Low Memory Killer 机制（如 Userspace LMKD）。\n2. 监控组件具备接收系统内存管理模块通知的权限。 输入 触发源：\n系统内存管理守护进程（lmkd）执行的进程查杀动作。\n数据：\n1. 目标进程信息（PID、UID、Process Name）。\n2. 查杀时的决策依据（OOM Score Adj）。\n3. 触发查杀时的系统内存压力状态（Memory Pressure State / PSI）。 处理逻辑 1. 动作捕获：\n实时感知 LMK 的查杀行为。推荐方案：采用源码插桩（Instrumentation）方式，在 lmkd 执行 kill 操作的原子逻辑处植入通知钩子，以获取零延迟、高精度的上下文信息；（备选方案：监听 EventLog 中的 lmk_kill 标签）。\n2. 水位快照：\n同步记录系统当前的内存水位详情（MemTotal, MemFree, SwapUsed, Cached），用于后续分析是物理内存耗尽还是虚拟内存（Swap）耗尽。\n3. 聚合去噪：\n执行时间窗口聚合策略。由于内存压力常导致短时间内连续查杀多个进程，需将同一压力波峰内（如 1 秒）的一组查杀事件聚合，避免产生告警风暴。\n4. 严重性判定：\n识别被杀进程的类型。若被杀进程为前台可见应用或关键服务，标记为“高影响”事件。 输出 1. 结构化事件：生成包含被杀进程列表及内存水位的 GVM_SYS_LMK 事件对象。\n2. 本地日志：保留查杀时刻的 meminfo 快照。\n3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》 FR-STAB-009 Binder 通信异常监控 属性 内容 优先级 P1 前置条件 1. 监控探针具备访问内核 Binder 驱动节点或 Hook libbinder 的能力。\n2. 监控配置已定义 Binder 线程池水位的告警阈值。 输入 触发源：\n1. Binder 驱动层的事务失败信号（如 BR_FAILED_REPLY, BR_DEAD_REPLY）。\n2. 进程 Binder 线程池的资源耗尽状态。\n数据：\n1. 通信双方身份（Caller PID/UID, Callee PID/UID）。\n2. 接口描述符（Interface Descriptor）或事务代码（Transaction Code）。\n3. 失败原因（如 TransactionTooLarge, DeadObject, Timeout）。 处理逻辑 1. 异常捕获：\n监测 IPC 通信链路健康度。推荐方案：在 Native libbinder 层进行插桩，拦截 IPCThreadState 中的错误返回码，从而在第一现场捕获异常。\n2. 资源枯竭识别 (Starvation)：\n周期性或事件驱动地检查关键进程的 Binder 线程池状态。若活跃线程数达到上限（默认 16）且仍有请求积压，判定为 Binder 线程耗尽。\n3. 大负载识别：\n识别 TransactionTooLargeException，记录传输过大数据的接口名称，辅助排查跨进程传输大图或大列表导致的性能问题。\n4. 链路还原：\n在异常发生时，自动解析并记录“谁调用谁”（Client -\u003e Server），明确责任方。 输出 1. 结构化事件：生成包含通信双方及错误类型的 GVM_SYS_BINDER_ERROR 事件对象。\n2. 本地日志：记录 /sys/kernel/debug/binder/transaction_log (若可用) 或相关 Logcat 片段。\n3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》 FR-STAB-010 文件句柄 (FD) 泄漏监控 属性 内容 优先级 P1 前置条件 1. 监控探针具备读取 /proc/[pid]/fd 目录或执行 lsof 类指令的权限。\n2. 针对不同类型的进程（System/App）配置了相应的 FD 数量告警阈值。 输入 触发源：\n1. 周期性采样：定时检查系统内进程的资源占用情况。\n2. 被动触发：捕获到系统日志中抛出的 EMFILE (“Too many open files”) 错误信号。\nData：\n1. 目标进程当前打开的文件句柄总数。\n2. 具体的句柄指向路径（Symlinks in /proc/pid/fd/）。 处理逻辑 1. 水位监测：\n对关键进程进行周期性（如每 5 分钟）的 FD 数量扫描。对比系统设定的软限制（Soft Limit）与硬限制（Hard Limit）。\n2. 超限识别：\n当某进程 FD 数量超过预警阈值（例如 \u003e 800 或占比 \u003e 80%）时，判定为存在泄漏风险。\n3. 现场快照：\n在检测到超限瞬间，遍历该进程的 /proc/[pid]/fd/ 目录，生成句柄分布快照。智能分类：统计不同类型句柄的占比（如 Socket, Anon_inode, Regular File），快速定位是网络连接泄漏还是文件未关闭。\n4. 趋势分析：\n结合历史数据，识别 FD 数量是否呈“持续上升且不回落”的阶梯状趋势，以排除正常的业务并发高峰。\n输出 1. 结构化事件：生成包含 FD 总数及分类统计的 GVM_SYS_FD_LEAK 事件对象。\n2. 本地日志：保留 top N 的句柄路径列表（Evidence List）。\n3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》 异构运行环境监控 (Heterogeneous Env Monitoring) FR-STAB-012 Linux Host (PVM) 重启与状态监控 属性 内容 优先级 P0 前置条件 1. PVM (Linux Host) 侧已部署 Host Daemon 并具备读取系统启动日志（如 /sys/fs/pstore 或 systemd journal）的权限。\n2. PVM 与 GVM 之间的跨域通信通道在启动后能够建立连接。 输入 触发源：\n1. PVM 启动完成：Host Daemon 随系统启动初始化。\n2. 连接建立：PVM 与 GVM 建立首次握手成功。\n数据：\n1. PVM 本次启动原因（Boot Reason）。\n2. 历史持久化日志（上一周期的 Kernel Panic Log 或 Watchdog 记录）。\n3. 实时心跳报文。 处理逻辑 1. 启动回溯（Post-Boot Analysis）：\nHost Daemon 在 PVM 启动初期，检查持久化存储中的上一次关机状态。识别是正常关机、掉电还是异常重启（如 Kernel Panic 导致的 WDT Reset）。\n2. 事件缓存：\n若判定为异常重启，Host Daemon 生成重启事件对象并暂存于本地内存或磁盘队列中，等待跨域通道就绪。\n3. 延迟同步（Delayed Sync）：\n当监测到 GVM (Android) 侧的 PolarisNativeDaemon 上线并建立连接后，立即将缓存的“上一次重启事件”发送给 GVM。\n4. 运行时状态监测：\n在连接建立后的运行期间，Host Daemon 周期性向 GVM 发送心跳包与健康度状态（如 Systemd Failed Units），供 GVM 侧记录实时趋势。 输出 1. 结构化事件：生成 PVM_SYS_RESTART（携带重启原因的历史事件）或 PVM_STATUS_REPORT（运行时状态）。\n2. 本地日志：在 PVM 侧保留原始的重启原因分析日志。\n3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》 FR-STAB-013 MCU 故障码与心跳监控 属性 内容 优先级 P1 前置条件 1. 硬件抽象层（HAL）或驱动层已完成 MCU 通信协议适配。\n2. 监控守护进程（Native Daemon）具备读取 MCU 状态接口的权限。 输入 触发源：\n1. MCU 周期性上报的状态报文（Status Message）。\n2. 硬件中断或底层驱动回调。\n数据：\n1. 存活心跳计数器（Rolling Counter）。\n2. 硬件诊断故障码（DTC - Diagnostic Trouble Code）。\n3. 外设关键状态字（如电源模式、复位原因）。 处理逻辑 1. 存活判定：\n通过监测心跳计数器的连续性和变化率来判断 MCU 状态。若计数器在设定时间窗口（TBD）内停止跳变或非法跳变，判定为 MCU 挂死或通信中断。\n2. 协议映射：\n建立 MCU 原始故障码与平台统一错误定义的映射表。将厂商特定的十六进制 DTC（如 0x1234）转换为可读的平台标准错误码（如 ERR_MCU_PMIC_FAIL）。\n3. 信号去抖：\n对偶发的故障信号进行软件滤波（De-bounce）。只有在连续 N 帧报文中确认同一故障码，或故障持续时长超过阈值时，才确认为有效故障，防止因总线干扰导致的误报。\n4. 复位检测：\n监测 MCU 的复位原因寄存器。若发现异常复位标识（如 WDT Reset），记录异常复位事件。 输出 1. 结构化事件：生成 MCU_HEARTBEAT_LOST（失联）或 MCU_HARDWARE_FAULT（硬件故障）事件对象。\n2. 本地日志：记录原始报文数据（Raw Data）以便后续校验。\n3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》 FR-STAB-014 异构关键进程 (PVM Critical Process) 稳定性监控 属性 内容 优先级 P0 前置条件 1. 目标关键进程（如 Audio Server, Display Composer, GSL HAL 等）已在 Host 侧启动。\n2. Polaris Host Daemon 具备对目标进程状态的查询或监听权限。 输入 触发源：\n1. 操作系统（Linux Host）发出的进程终止信号（如 SIGCHLD）。\n2. 服务管理框架（如 Systemd）抛出的服务状态变更通知（Service Unit Status Change）。\n3. 目标进程输出到标准错误流（Stderr）的致命错误日志。\n数据：\n1. 进程标识（PID, Process Name, Unit Name）。\n2. 退出状态码（Exit Code）或终止信号（Signal）。 处理逻辑 1. 通用监听：\n采用非侵入式手段实时感知关键进程的生命周期。针对受 Systemd 托管的服务，订阅其 D-Bus 状态变更信号；针对独立进程，采用 PID 存活轮询或父进程信号监听机制。\n2. 状态判定：\n- 异常退出：识别进程非预期的终止（Exit Code != 0）。\n- 僵死/挂起：若具备条件，监测进程是否长时间处于 D 状态（Uninterruptible Sleep）或对心跳接口无响应。\n3. 抖动抑制 (Flapping Detection)：\n针对具有“自动重启”机制的关键服务，在设定时间窗口内（如 10秒）若检测到多次反复重启，应将其聚合为单次“服务抖动”事件上报，防止告警风暴。\n4. 现场记录：\n在进程崩溃瞬间，尝试捕获其最后输出的标准错误日志（Stderr）或 Journalctl 片段，作为归因线索。 输出 1. 结构化事件：生成包含进程名、退出码及故障频次的 PVM_PROCESS_CRASH 事件对象。\n2. 本地日志：Host 侧保留相关的系统日志片段。\n3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》 FR-STAB-015 温度监控 属性 内容 优先级 P1 前置条件 1. 系统底层具备热管理子系统（Thermal HAL / Thermal Daemon）。\n2. 监控探针具备读取 /sys/class/thermal 节点或订阅 IThermalService 回调的权限。 输入 触发源：\n1. 被动接收：Thermal HAL 上报的热状态变更回调（如 onStatusChanged）。\n2. 主动采样：周期性读取关键热区（Thermal Zone）的温度传感器数值。\n数据：\n1. 热区名称（Zone Name, 如 cpu, gpu, battery, soc）。\n2. 当前温度值（Temperature in m°C）。\n3. 热状态等级（Thermal Status: NONE, LIGHT, MODERATE, SEVERE, CRITICAL, SHUTDOWN）。 处理逻辑 1. 状态监听：\n实时订阅系统热管理服务的状态变更通知。一旦热状态跨越阈值（例如从 NONE 变为 SEVERE），立即触发记录逻辑。\n2. 降频关联：\n当检测到温度过高触发温控策略（Throttling）时，尝试关联当前的 CPU/GPU 频率限制状态，以解释可能伴随发生的卡顿或掉帧现象（辅助性能分析）。\n3. 危急保护记录：\n当收到 SHUTDOWN 级别的热信号时，视为“过热关机前兆”，必须以最高优先级将当前温度快照写入持久化存储，作为系统异常重启（FR-STAB-006）的直接归因证据。\n4. 趋势采样：\n在非危急状态下，按低频（如每 5 分钟）采样 SoC 核心温度，用于绘制温度变化趋势图。 输出 1. 结构化事件：生成 GVM_SYS_THERMAL_EVENT（包含热区名称、温度值及温控等级）。\n2. 本地日志：保留过热时刻的 thermalservice 状态或相关节点快照。\n3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》 非功能需求 端云交互协议设计 安全与隐私 风险 \u0026 限制 \u0026 依赖 实施计划 阶段划分 资源需求计划 附录 ","wordCount":"1854","inLanguage":"en","datePublished":"0001-01-01T00:00:00Z","dateModified":"0001-01-01T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://ethen-cao.github.io/ethenslab/others/%E6%99%BA%E8%83%BD%E5%BA%A7%E8%88%B1%E7%AB%AF%E4%BA%91%E4%B8%80%E4%BD%93%E6%80%A7%E8%83%BD%E4%B8%8E%E7%A8%B3%E5%AE%9A%E6%80%A7%E5%B9%B3%E5%8F%B0%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3/"},"publisher":{"@type":"Organization","name":"Ethen 的实验室","logo":{"@type":"ImageObject","url":"https://ethen-cao.github.io/ethenslab/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://ethen-cao.github.io/ethenslab/ accesskey=h title="Ethen 的实验室 (Alt + H)">Ethen 的实验室</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://ethen-cao.github.io/ethenslab/android-dev/ title=Android系统开发><span>Android系统开发</span></a></li><li><a href=https://ethen-cao.github.io/ethenslab/android-automotive-os-dev/ title="Android Automotive"><span>Android Automotive</span></a></li><li><a href=https://ethen-cao.github.io/ethenslab/qnx/ title=QNX开发><span>QNX开发</span></a></li><li><a href=https://ethen-cao.github.io/ethenslab/gunyah/ title=Gunyah><span>Gunyah</span></a></li><li><a href=https://ethen-cao.github.io/ethenslab/ivi-solution/ title=智能座舱方案><span>智能座舱方案</span></a></li><li><a href=https://ethen-cao.github.io/ethenslab/explore-ai title="Explore AI"><span>Explore AI</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://ethen-cao.github.io/ethenslab/>Home</a>&nbsp;»&nbsp;<a href=https://ethen-cao.github.io/ethenslab/others/>杂记</a></div><h1 class="post-title entry-hint-parent"></h1><div class=post-meta>9 min&nbsp;·&nbsp;1854 words</div></header><div class=post-content><h1 id=智能座舱端云一体性能与稳定性平台-polaris-10-系统设计文档>智能座舱端云一体性能与稳定性平台 (Polaris 1.0) 系统设计文档<a hidden class=anchor aria-hidden=true href=#智能座舱端云一体性能与稳定性平台-polaris-10-系统设计文档>#</a></h1><h2 id=版本信息>版本信息<a hidden class=anchor aria-hidden=true href=#版本信息>#</a></h2><table><thead><tr><th>序号</th><th>版本</th><th>修订内容</th><th>状态</th><th>修订人</th><th>日期</th></tr></thead><tbody><tr><td>1</td><td>0.1</td><td>First draft</td><td></td><td>操权力</td><td>2025/12/9</td></tr></tbody></table><h2 id=文档目的>文档目的<a hidden class=anchor aria-hidden=true href=#文档目的>#</a></h2><p>本文档旨在全面定义 智能座舱端云一体性能与稳定性平台 (代号 Polaris 1.0) 的系统架构、功能需求及实施路径。本文档将服务于以下核心场景：</p><ul><li>管理层决策：清晰阐述项目背景、痛点、ROI（投入产出比）及资源需求，作为立项审批与资源调度的依据。</li><li>跨部门协同：作为座舱平台部与车云平台部沟通数据协议、接口规范及边界划分的“蓝本”，确保端云技术方案的一致性。</li><li>工程落地指导：作为项目启动后的核心输入，指导研发团队进行端侧 Agent 开发、埋点设计及测试验收。</li></ul><h2 id=背景与问题定义>背景与问题定义<a hidden class=anchor aria-hidden=true href=#背景与问题定义>#</a></h2><h3 id=背景>背景<a hidden class=anchor aria-hidden=true href=#背景>#</a></h3><p>当前智能座舱的数据建设存在数据维度失衡与底层感知缺失的问题，具体表现在以下三个方面：</p><ul><li><p>应用质量量化手段缺失：目前虽已具备应用层的业务埋点能力（如 PV/UV、页面点击流），能支撑产品运营分析；但对于应用技术质量（如 Crash率、ANR率、错误日志）及 核心性能指标（如启动耗时、页面响应延迟）尚缺乏系统性的监控与度量手段，导致软件交付质量缺乏客观数据支撑。</p></li><li><p>平台侧缺乏云端可观测性：作为座舱底座的平台研发部门，目前缺乏专属的云端观测平台。对于线上车辆的系统级健康度（如 SystemServer 重启、关键服务存活、资源水位），研发团队缺乏实时获取线上运行时状态的能力，往往只能在故障发生后进行被动回溯。</p></li><li><p>系统稳定性保障体系亟待构建：随着智能座舱软件规模与复杂度的提升，单纯依赖线下测试已难以覆盖所有边缘场景。为了保障用户体验，亟需构建一套严谨的、标准化的端云一体性能与稳定性监控平台，实现对线上真实运行质量的精准监测与闭环管理。</p></li></ul><h3 id=当前痛点>当前痛点<a hidden class=anchor aria-hidden=true href=#当前痛点>#</a></h3><table><thead><tr><th>痛点</th><th>描述</th><th>业务影响</th></tr></thead><tbody><tr><td><strong>跨端故障排查成本较高</strong></td><td>当前缺乏跨端（Android-Linux-MCU）的自动化关联数据，面对复杂的跨域交互问题，排查过程往往需要人工拼接多端日志。</td><td><strong>研发效率受限</strong>：故障定位往往需要多方协同与多次排查，拉长了问题的解决周期。</td></tr><tr><td><strong>性能量化数据覆盖不足</strong></td><td>现有的性能评估主要依赖线下测试或有限样本，缺乏全量用户场景下的启动速度、流畅度等自动化量化数据。</td><td><strong>版本评价受限</strong>：难以精确捕捉版本迭代中的细微性能波动，线上实际体验的评估数据不够丰满。</td></tr><tr><td><strong>偶发异常现场回溯困难</strong></td><td>对于线上偶发的非必现问题，目前主要依赖事后尝试复现，缺乏异常发生瞬间的自动“快照”捕获机制。</td><td><strong>闭环周期较长</strong>：部分偶发性稳定性问题（如随机黑屏、卡顿）因缺乏现场数据支持，难以快速彻底根除。</td></tr><tr><td><strong>资源效能优化缺乏支撑</strong></td><td>缺乏进程级的 CPU、内存、IO 历史趋势画像，在进行精细化资源管控时缺乏足够的数据颗粒度。</td><td><strong>成本优化受限</strong>：硬件资源规划倾向于保守策略以保障稳定性，BOM 成本的进一步精细化挖掘存在困难。</td></tr></tbody></table><h2 id=目标与范围>目标与范围<a hidden class=anchor aria-hidden=true href=#目标与范围>#</a></h2><h3 id=项目目标>项目目标<a hidden class=anchor aria-hidden=true href=#项目目标>#</a></h3><p>本项目旨在基于 “端侧深度探针 + 云端聚合分析 + 全链路追踪” 的技术理念，构建 Polaris 1.0 端云一体化平台，实现以下三个核心目标：</p><ol><li><p>全链路可观测：打破 Android、Linux Host、MCU 的数据孤岛，建立统一的 全局事件标准 (Global Event ID)，将分散在不同系统的故障与状态数据聚合至同一平台，实现跨端调用的追踪，为后续的可视化链路分析奠定数据基础。</p></li><li><p>故障现场自动聚合与关联：突破现有“日志碎片化”及“事后拉取不全”的局限。建立 “事件驱动”的现场快照机制，在异常发生瞬间，自动聚合与该事件强相关的全维度上下文信息（如 Trace、系统 Log、进程状态等）并生成 完整的故障证据包。这不仅实现了 Event 与 Log 的精准索引，更确保了现场信息的完整性，彻底解决因关键日志缺失导致无法定位的难题。</p></li><li><p>数据驱动治理：建立系统级的性能与稳定性基线（Baseline），通过量化数据驱动版本质量验收与硬件资源优化，将质量管理从“定性”转向“定量”。</p></li></ol><h3 id=核心-kpi-指标>核心 KPI 指标<a hidden class=anchor aria-hidden=true href=#核心-kpi-指标>#</a></h3><table><thead><tr><th>维度</th><th>指标名称</th><th>目标值 (示例)</th><th>说明</th></tr></thead><tbody><tr><td><strong>质量</strong></td><td><strong>严重故障主动发现率</strong></td><td><strong>> 90%</strong></td><td>在用户报修前，通过平台主动捕获并预警系统级崩溃与卡顿。</td></tr><tr><td><strong>效率</strong></td><td><strong>日志精准命中率</strong></td><td><strong>100%</strong></td><td>每一个上报的严重异常事件，都能直接下载到对应的、正确的 Log 文件，无需人工筛选。</td></tr><tr><td><strong>复现</strong></td><td><strong>致命问题现场捕获率</strong></td><td><strong>> 80%</strong></td><td>针对 Crash/Watchdog 等致命问题，确保有对应的 Trace/Log 可供分析。</td></tr><tr><td><strong>成本</strong></td><td><strong>资源优化场景产出</strong></td><td><strong>TOP 5/季度</strong></td><td>每季度识别并输出 5 个高资源消耗（CPU/内存）场景。</td></tr></tbody></table><h3 id=项目范围>项目范围<a hidden class=anchor aria-hidden=true href=#项目范围>#</a></h3><h4 id=范围内>范围内<a hidden class=anchor aria-hidden=true href=#范围内>#</a></h4><ol><li><p><strong>端侧全栈感知体系</strong>：</p><ul><li><strong>Android 深度探针</strong>：构建系统级监控服务 <code>PolarisAgentService</code>，实现对应用生命周期、核心服务状态、底层资源（LMK/IO/Binder）的<strong>全维度深度监听</strong>。</li><li><strong>Linux/MCU 异构覆盖</strong>：建设 Linux Host 侧的<strong>系统健康守护进程</strong>，负责关键服务（Service）存活检测与系统指标采集；适配 MCU 遥测协议，实现异构芯片间的故障透传。</li><li><strong>边缘智能处理</strong>：在端侧实现数据的<strong>预处理与清洗</strong>，包含事件聚合、流控防爆、日志现场的智能截取与压缩，减轻车云带宽压力。</li><li><strong>标准化基础设施</strong>：建立《全局事件注册表》及自动化工具链，统一多端的数据定义与协议标准。</li></ul></li><li><p><strong>云端分析能力需求</strong>:</p><ul><li><strong>元数据管理能力</strong>：要求云端支持同步《全局事件注册表》，实现对上报事件的自动化解析、分类与标签化管理。</li><li><strong>自动化关联引擎</strong>：要求云端具备**“事件-日志”自动匹配能力**，将结构化的 Event 数据与非结构化的 Log 文件（基于索引）在存储层自动关联，形成完整的故障证据包。</li><li><strong>趋势与模式识别</strong>：要求云端支持基于时间窗口的聚合计算，能够识别异常爆发（Spike）趋势及性能指标（CPU/内存）的长期演进趋势。</li></ul></li><li><p><strong>可视化与运营平台</strong></p><ul><li><strong>数字化质量驾驶舱</strong>：建设多维度的质量仪表盘（Dashboard），支持按版本、车型、时间段下钻分析千车故障率、性能基线达标率。</li><li><strong>智能排查工作台</strong>：提供“一站式”问题分析界面，支持通过 EventID/TraceID 检索故障，直接浏览关联的日志、堆栈及设备状态，支持远程诊断指令的下发与结果展示。</li></ul></li></ol><h4 id=范围外>范围外<a hidden class=anchor aria-hidden=true href=#范围外>#</a></h4><ol><li><strong>可视化的全链路拓扑分析</strong>：1.0 阶段聚焦于跨端链路数据的 标准化采集与逻辑串联，优先夯实数据底座能力；全链路图形化的调用链拓扑展示规划在后续版本迭代中实现。</li><li><strong>业务代码修复</strong>：Polaris 平台负责精准“定位”并“指派”问题，<strong>不负责</strong> 具体业务 APP 内部的代码逻辑修复。</li><li><strong>交互体验设计</strong>：本项目专注于性能数据的量化，<strong>不包含</strong> HMI 界面（UI/UE）的主观交互设计与优化。</li></ol><h2 id=业务流程与核心场景>业务流程与核心场景<a hidden class=anchor aria-hidden=true href=#业务流程与核心场景>#</a></h2><h3 id=角色定义>角色定义<a hidden class=anchor aria-hidden=true href=#角色定义>#</a></h3><table><thead><tr><th>角色</th><th>职责描述</th><th>关注点</th></tr></thead><tbody><tr><td><strong>研发工程师</strong></td><td>接收告警，分析堆栈与日志，修复 Bug；针对疑难客诉问题，远程下发特定诊断指令</td><td>故障堆栈的完整性，日志关联的准确性，是否需要补充更多运行时信息。</td></tr><tr><td><strong>质量工程师</strong></td><td>配置告警阈值，监控线上大盘水位，识别版本质量风险</td><td>故障率趋势是否劣化，性能指标是否符合预期，流量消耗是否异常。</td></tr><tr><td><strong>产品经理</strong></td><td>查看应用活跃度与性能体验趋势</td><td>核心功能的响应速度趋势，用户使用过程中的卡顿频率。</td></tr></tbody></table><h3 id=核心作业流程图>核心作业流程图<a hidden class=anchor aria-hidden=true href=#核心作业流程图>#</a></h3><p><strong>1. 故障主动发现闭环流程</strong></p><blockquote><p><em>描述从异常发生到研发接入的处理路径</em></p></blockquote><ul><li><strong>捕获 (Capture)</strong>: Polaris Agent 监听到异常（如 ANR），记录运行时状态，抓取 Trace/Logcat，并生成唯一 EventID。</li><li><strong>处理 (Process)</strong>: 端侧进行流量控制检查，通过 <code>logf</code> 索引将 Event 与 Log 文件进行逻辑组合。</li><li><strong>上报 (Report)</strong>: Event 数据实时上报，大文件 Log 在 WiFi/空闲时段异步上传（支持云端按需拉取）。</li><li><strong>通知 (Notify)</strong>: 云端检测到异常数据超过阈值（例如某版本 Crash 率上升），向 <strong>责任模块负责人</strong> 发送通知。</li><li><strong>分析 (Analyze)</strong>: 研发工程师查看通知，进入平台查看关联的上下文数据，确认问题根因并修复。</li></ul><p><strong>2. 疑难问题排查流程</strong></p><blockquote><p><em>描述针对复杂客诉或非必现问题的处理路径</em></p></blockquote><ul><li><strong>检索</strong>: 研发工程师在平台输入车辆 VIN 码或 EventID 检索相关记录。</li><li><strong>查看</strong>: 系统展示该事件的发生时间、设备信息、以及<strong>已自动关联</strong>的 Log 文件下载链接。</li><li><strong>诊断</strong>: 针对区域技术支持无法处理的复杂客诉，若现有日志不足以定位，<strong>研发工程师</strong> 通过控制台下发 <code>Shell</code> 诊断指令，端侧执行后回传结果，以获取更深度的运行时信息。</li></ul><h3 id=典型用户故事>典型用户故事<a hidden class=anchor aria-hidden=true href=#典型用户故事>#</a></h3><h4 id=场景一风险预警>场景一：风险预警<a hidden class=anchor aria-hidden=true href=#场景一风险预警>#</a></h4><blockquote><p><strong>背景</strong>: 某车型灰度推送 v1.5 OTA 版本。
<strong>事件</strong>: 上线 24 小时内，Polaris 平台监测到 <code>GVM_SYS_STORAGE_LOW</code>（磁盘空间不足）事件在特定批次车辆上的上报量呈<strong>异常上升趋势</strong>。
<strong>行动</strong>:</p><ol><li>平台自动触发 <strong>风险预警</strong>，即时通知研发负责人。</li><li>研发工程师通过平台获取存储分布数据，精准定位到某应用私有目录占用空间急剧膨胀。</li><li><strong>分析</strong>: 结合自动关联采样的 Log，确认该应用在特定异常分支下陷入<strong>数据库高频重复写入</strong>死循环。
<strong>结果</strong>: 研发团队在磁盘被完全耗尽导致系统挂死（System Hang）前，紧急输出修复补丁并推送 OTA，成功拦截了批量重大事故。</li></ol></blockquote><h4 id=场景二稳定性治理>场景二：稳定性治理<a hidden class=anchor aria-hidden=true href=#场景二稳定性治理>#</a></h4><blockquote><p><strong>背景</strong>: 某应用发布 v2.0 灰度版本。
<strong>事件</strong>: 灰度发布期间，平台监测到应用出现<strong>偶发性</strong> <code>GVM_APP_ANR</code>（无响应）告警，且线下测试难以复现。
<strong>行动</strong>:</p><ol><li>研发工程师点击告警详情，查看聚合后的故障样本。</li><li>系统已通过 <code>logf</code> 字段自动关联了故障时刻的 <code>traces.txt</code> 以及系统侧 <code>perflog</code> (性能日志)。</li><li><strong>分析</strong>: 工程师通过 Trace 文件发现应用主线程阻塞在 Binder IPC 调用中；进一步联合分析 <code>perflog</code>，定位到是对端 Service 在高并发场景下因锁竞争导致处理耗时过长，拖累了客户端。
<strong>结果</strong>: 确认根因为<strong>服务端卡顿</strong>。研发工程师针对服务端逻辑进行异步化优化，彻底解决了这一隐蔽的跨进程阻塞问题。</li></ol></blockquote><h4 id=场景三性能监控>场景三：性能监控<a hidden class=anchor aria-hidden=true href=#场景三性能监控>#</a></h4><blockquote><p><strong>背景</strong>: 某版本上线后，产品经理关注核心应用在复杂交互场景下的滑动流畅度。
<strong>事件</strong>: Polaris 仪表盘显示 <code>GVM_APP_JANK</code> (掉帧/卡顿) 指标在特定列表滑动场景下出现劣化趋势。
<strong>行动</strong>:</p><ol><li>系统展示了掉帧率与主线程负载的关联曲线。</li><li><strong>发现</strong>: 在卡顿发生的时间段内，主线程 MessageQueue 待处理消息数量显著激增。</li><li><strong>分析</strong>: 研发工程师通过分析采集到的 <code>Looper</code> 统计数据，发现是一次性加载过多列表项导致并在主线程频繁 Post UI 刷新消息，引发<strong>主线程消息队列积压</strong>，从而阻塞了渲染信号（Vsync）的处理。
<strong>结果</strong>: 研发工程师引入消息合并与节流机制（Throttling），消除了主线程拥堵，恢复了滑动流畅性。</li></ol></blockquote><h4 id=场景四远程指令下发>场景四：远程指令下发<a hidden class=anchor aria-hidden=true href=#场景四远程指令下发>#</a></h4><blockquote><p><strong>背景</strong>: 用户反馈方控按键（下一曲）失效，或错误地控制了不显示在屏幕上的后台音乐应用，常规 Logcat 无法体现系统内部的分发逻辑。
<strong>行动</strong>:</p><ol><li>研发工程师怀疑是 MediaSession 焦点抢占或状态同步异常。</li><li>工程师通过 Polaris 控制台，向目标车辆下发 dumpsys media_session 指令。</li><li>分析: 回传的诊断结果显示，Media button session 仍被后台应用 com.reachauto.clouddesk 占用（尽管其状态为 active=false），导致按键事件未正确分发给前台亮屏的 com.tencent.wecarflow。
结果: 确认根因是后台应用未正确释放焦点，研发工程师将 Bug 准确指派给相关应用团队，无需现场抓包。</li></ol></blockquote><h2 id=需求拆解>需求拆解<a hidden class=anchor aria-hidden=true href=#需求拆解>#</a></h2><p>本章节将 Polaris 1.0 平台的核心需求拆解为四大关键能力域。这些能力定义了系统的边界与核心价值，是后续详细功能设计的基础。
本章节采用能力域（Capability Domain）拆解方法，以系统应具备的核心能力为中心，而非具体功能或实现方式。每一能力域仅定义目标、适用范围与责任边界，不涉及接口设计、数据结构或技术选型细节。具体功能点将在后续《功能性需求》中展开，质量与约束要求将在《非功能性需求》中统一定义。</p><h3 id=稳定性全栈感知能力>稳定性全栈感知能力<a hidden class=anchor aria-hidden=true href=#稳定性全栈感知能力>#</a></h3><p><strong>目标</strong>：构建覆盖 Android 应用层、系统框架层以及 Linux Host/MCU 异构计算单元的异常捕获体系，实现全栈、全维度的故障感知与现场数据留存。</p><table><thead><tr><th>能力名称</th><th>能力描述与目标</th><th>适用范围</th><th>责任边界</th></tr></thead><tbody><tr><td><strong>应用层稳定性监控</strong><br>(App Layer Stability)</td><td><strong>描述</strong>：具备对 Android <strong>应用层 (APK)</strong> 致命异常的实时监测能力。涵盖 Java Crash、App Native Crash (JNI)、ANR 及 App OOM；在异常触发时同步执行现场冻结与堆栈抓取。<br><strong>目标</strong>：确保应用级崩溃捕获率 > 98%，异常现场数据完整性 100%。</td><td>Android Framework<br>Third-party Apps<br>System Apps (Launcher等)</td><td><strong>负责</strong>：捕获应用堆栈、页面栈及进程状态；<br><strong>不负责</strong>：分析应用内部具体的业务逻辑错误。</td></tr><tr><td><strong>系统框架稳定性监控</strong><br>(System Framework Stability)</td><td><strong>描述</strong>：具备对 <strong>Android 核心服务</strong>及<strong>关键守护进程</strong>的存活状态监测能力；识别系统级资源耗尽风险（如 Binder 耗尽、句柄泄漏、LMK）。<br><strong>目标</strong>：准确识别 SystemServer 死锁 (Watchdog)、核心服务崩溃、系统异常重启及严重资源拥堵事件。</td><td>SystemServer<br>Binder Driver<br>Native Daemons (SurfaceFlinger等)</td><td><strong>负责</strong>：识别导致系统不稳定的服务异常和资源瓶颈；<br><strong>不负责</strong>：介入 Linux Kernel 内部调度机制的调试。</td></tr><tr><td><strong>异构运行环境监控</strong><br>(Heterogeneous Env Monitoring)</td><td><strong>描述</strong>：具备对 <strong>Linux Host (PVM)</strong> 及 <strong>MCU</strong> 运行状态的独立监测能力。通过 Native Daemon 标准化采集 Linux 侧服务状态、系统重启事件以及 MCU 侧的心跳与硬件故障码。<br><strong>目标</strong>：实现对底层虚拟化环境与硬件外设健康状况的统一视图监控。</td><td>Linux Host (PVM)<br>MCU<br>Hypervisor</td><td><strong>负责</strong>：异构数据的标准化接入、协议对齐及状态监测；<br><strong>不负责</strong>：异构系统内部具体业务逻辑的监控实现。</td></tr></tbody></table><h3 id=性能与资源度量能力>性能与资源度量能力<a hidden class=anchor aria-hidden=true href=#性能与资源度量能力>#</a></h3><p><strong>目标</strong>：建立可量化的性能基线，从“主观体验”转向“客观数据”，实现对计算资源（CPU/Mem/IO）的精细化审计。</p><table><thead><tr><th>能力名称</th><th>能力描述与目标</th><th>适用范围</th><th>责任边界</th></tr></thead><tbody><tr><td><strong>交互体验量化</strong></td><td><strong>描述</strong>：具备对用户核心交互路径（冷/热启动、页面滑动、点击响应）的耗时与流畅度监测能力。<br><strong>目标</strong>：量化 App 启动速度与掉帧率（Jank），支持版本间性能对比。</td><td>Top 核心应用, Launcher, SystemUI</td><td>负责采集关键节点的耗时数据；不负责 UI 渲染流程的优化。</td></tr><tr><td><strong>资源水位画像</strong></td><td><strong>描述</strong>：具备对进程级资源消耗（CPU使用率、内存占用、IO吞吐量）的周期性采样与超限识别能力。<br><strong>目标</strong>：识别“资源刺客”与异常泄漏，绘制 24h 资源趋势图。</td><td>所有运行状态下的进程</td><td>负责资源数据的统计与归因；不负责系统资源调度策略。</td></tr><tr><td><strong>异常爆发检测</strong></td><td><strong>描述</strong>：具备对特定异常事件（如连续 Crash、持续高负载）的频率统计与突变识别能力。<br><strong>目标</strong>：防止单点故障引发的“告警风暴”，并在端侧进行初步降噪。</td><td>全局事件流</td><td>负责端侧的流控与阈值判断。</td></tr></tbody></table><h3 id=现场还原与协同能力>现场还原与协同能力<a hidden class=anchor aria-hidden=true href=#现场还原与协同能力>#</a></h3><p><strong>目标</strong>：解决“有报警无日志”的痛点，构建端云协同的自动化取证与远程诊断通道。</p><table><thead><tr><th>能力名称</th><th>能力描述与目标</th><th>适用范围</th><th>责任边界</th></tr></thead><tbody><tr><td><strong>标准化事件协议体系</strong></td><td><strong>描述</strong>：基于《全局事件注册表》构建统一的事件定义、序列化与解析能力。<br><strong>目标</strong>：确保端侧上报数据与云端解析引擎的语义一致性，支持协议动态扩展。</td><td>端侧 Agent, 车云 SDK, 云端解析服务</td><td>负责协议的定义与维护工具链；不限制业务 Payload 的具体内容。</td></tr><tr><td><strong>智能现场快照</strong></td><td><strong>描述</strong>：具备“事件驱动”的自动化日志聚合能力，在异常发生瞬间关联并打包 Trace、Logcat 及系统状态信息。<br><strong>目标</strong>：实现 Event 与 Log 文件的 1:1 精准索引。</td><td>本地日志系统, 文件系统</td><td>负责日志的定位、截取与压缩；不负责日志内容的语义分析。</td></tr><tr><td><strong>远程诊断执行</strong></td><td><strong>描述</strong>：具备安全可控的云端指令接收与本地执行能力，支持下发 Shell 脚本或调试命令。<br><strong>目标</strong>：在不打扰用户的前提下获取更深度的运行时信息。</td><td>Shell 环境, Debug 接口</td><td>负责指令通道的建立与执行结果回传；严禁执行未授权的高危写操作，不支持批量执行、默认灰度单车、需显式授权、强审计。</td></tr></tbody></table><h3 id=数据智能与运营能力>数据智能与运营能力<a hidden class=anchor aria-hidden=true href=#数据智能与运营能力>#</a></h3><p><strong>目标</strong>：将海量原始数据转化为可行动的洞察（Actionable Insights），支撑研发与质量团队的决策。</p><table><thead><tr><th>能力名称</th><th>能力描述与目标</th><th>适用范围</th><th>责任边界</th></tr></thead><tbody><tr><td><strong>端云数据自动关联</strong></td><td><strong>描述</strong>：具备在海量存储中，根据索引自动将结构化事件与非结构化日志文件进行绑定的能力。<br><strong>目标</strong>：消除人工查找日志的成本。</td><td>云端存储层</td><td>负责数据的逻辑关联与存储生命周期管理。</td></tr><tr><td><strong>实时风险预警</strong></td><td><strong>描述</strong>：具备基于时间窗口的流式计算能力，识别线上故障的爆发趋势并触发告警。<br><strong>目标</strong>：实现故障感知。</td><td>计算引擎</td><td>负责告警策略的计算与推送；不负责告警后的工单流转。</td></tr><tr><td><strong>多维质量可视化</strong></td><td><strong>描述</strong>：具备多维度（版本/车型/时间/地区）的数据聚合与图表展示能力。<br><strong>目标</strong>：提供从“宏观大盘”到“微观个案”的钻取分析视图。</td><td>数据仓库, 可视化前端</td><td>负责数据的可视化呈现。</td></tr></tbody></table><h2 id=系统总体方案>系统总体方案<a hidden class=anchor aria-hidden=true href=#系统总体方案>#</a></h2><h3 id=总体设计概述>总体设计概述<a hidden class=anchor aria-hidden=true href=#总体设计概述>#</a></h3><p>Polaris 1.0 基于 <strong>Hypervisor 虚拟化架构</strong> 设计，旨在构建跨越 <strong>GVM (Guest VM - Android)</strong>、<strong>PVM (Primary VM - Linux)</strong> 及 <strong>MCU</strong> 的端云一体化全栈监控系统。
系统采用 <strong>分层架构</strong> 与 <strong>模块化服务设计</strong>。在控制面上，通过 <strong>注册表驱动（Registry-Driven）</strong> 机制实现业务埋点定义与底层采集逻辑的解耦；在数据面上，通过 <strong>双守护进程（Dual Daemon）</strong> 机制打通异构芯片与系统的通信壁垒。系统将计算能力前置至端侧，通过 <code>PolarisAgentService</code> 实现数据的实时清洗、流控与现场关联，仅将高价值的结构化数据与诊断日志同步至云端。</p><h3 id=系统总体架构图>系统总体架构图<a hidden class=anchor aria-hidden=true href=#系统总体架构图>#</a></h3><p><img src=/ethenslab/images/Polaris1.0.drawio.png alt></p><h3 id=架构分层详解>架构分层详解<a hidden class=anchor aria-hidden=true href=#架构分层详解>#</a></h3><h4 id=业务应用与接口层>业务应用与接口层<a hidden class=anchor aria-hidden=true href=#业务应用与接口层>#</a></h4><p>本层负责定义数据采集的标准接口，通过自动代码生成技术屏蔽底层通信细节：</p><ul><li><strong>Polaris SDK</strong>: 面向上层业务应用（如 Launcher, Maps）。该组件由《全局事件注册表》编译生成，提供强类型的事件对象封装与校验逻辑，负责将业务数据序列化并传递给 Framework 层。</li><li><strong>System Internal SDK</strong>: 面向 SystemServer 内部服务（如 AMS, WMS）。与 Polaris SDK 同源生成，专门用于系统关键服务内部的插桩（Instrumentation），以捕获服务级异常与状态变更。</li><li><strong>Host SDK</strong>: 面向 PVM 侧的 Linux 应用程序（如 Cluster HMI）、系统核心服务，提供 C++ 标准上报接口，负责将 PVM 侧业务数据发送至 Host Daemon。</li></ul><h4 id=框架传输与核心服务层>框架传输与核心服务层<a hidden class=anchor aria-hidden=true href=#框架传输与核心服务层>#</a></h4><p>本层位于 Android GVM，是数据汇聚、策略执行与处理的核心区域：</p><ul><li><p><strong>Polaris SDK (Framework API)</strong>: 部署于 <code>AppFramework API</code> 层。作为系统级的传输接口实现，它承接来自上层业务的调用请求，并维护与*PolarisAgentService的 IPC 通信链路，确保数据的可靠投递。</p></li><li><p><strong>PolarisAgentService</strong>: 常驻系统服务，内部包含五个核心功能模块：</p><ul><li><strong>EventCollector</strong>: <strong>统一接入模块</strong>。作为 Binder 服务端接收 Polaris SDK 请求；同时作为 LocalSocket 客户端，在服务启动时主动连接 Native Daemon 建立长连接通道，并通过后台线程实时拉取 Native 侧上报的事件流。</li><li><strong>ConfigManager</strong>: <strong>配置管理模块</strong>。负责加载本地注册表文件的配置，解析采样率、阈值及采集开关策略。</li><li><strong>FlowController</strong>: <strong>流量控制模块</strong>。对输入事件进行频率限制，防止异常爆发导致系统资源耗尽。</li><li><strong>ContextEngine</strong>: <strong>现场聚合模块</strong>。在事件通过流控后，负责生成唯一 EventID，挂载系统时间戳，并根据事件类型关联 Logcat、Trace 文件及进程快照，生成索引信息。</li><li><strong>DiagnoseHandler</strong>: <strong>诊断执行模块</strong>。负责校验并执行来自云端的诊断指令（Shell Command），并管理执行结果的回传。</li></ul></li></ul><h4 id=原生与异构跨域层>原生与异构跨域层<a hidden class=anchor aria-hidden=true href=#原生与异构跨域层>#</a></h4><p>本层负责 Android Runtime 之外的底层环境监控及跨虚拟机通信：</p><ul><li><p><strong>Polaris Native Daemon (GVM)</strong>:</p></li><li><p><strong>本地采集</strong>: 负责监控 Native 进程崩溃（Tombstone）、系统资源、及 HAL 层状态。</p></li><li><p><strong>跨域网关</strong>: 作为 GVM 侧的通信端点，维护与 PVM/MCU 的连接，接收跨域透传的数据。</p></li><li><p><strong>Polaris Host Daemon (PVM)</strong>:</p></li><li><p><strong>宿主监控</strong>: 负责监控 PVM 侧的 <code>systemd</code> 服务状态、关键驱动状态及虚拟机管理服务（qcrosvm/VMM）。</p></li></ul><h4 id=传输通道与云平台>传输通道与云平台<a hidden class=anchor aria-hidden=true href=#传输通道与云平台>#</a></h4><ul><li><strong>VlmAgent</strong>: <strong>统一传输网关</strong>。作为端侧唯一的数据出口，负责接收来自 <code>PolarisAgentService</code> 的结构化事件,以及日志文件（按需拉取），执行断点续传、数据压缩与网络流量调度。</li><li><strong>Cloud Platform</strong>: 负责数据的计算、存储与可视化。</li></ul><h3 id=核心设计原则>核心设计原则<a hidden class=anchor aria-hidden=true href=#核心设计原则>#</a></h3><ol><li>进程级隔离与服务化：PolarisAgentService 设计为独立系统进程，而非 SystemServer 的内部线程。这种设计带来了两大优势：<ul><li>稳定性：监控服务的异常（如 OOM）不会导致系统核心服务（SystemServer）崩溃，反之亦然。</li><li>高性能：独立的进程空间避免了与 AMS/WMS 争抢主线程资源，确保了监控逻辑的独立调度。</li></ul></li><li>系统核心即客户端：确立 SystemServer 在监控体系中的 Client 身份。AMS、WMS 等核心服务通过 System Internal SDK，以跨进程调用（IPC）的方式向 Polaris 上报数据。这种“旁路监控”模式确保了对系统原有逻辑的最小侵入。</li><li>异构接入抽象化：针对 MCU 等异构单元，系统采用 &ldquo;HAL 驱动适配 + Daemon 统一采集&rdquo; 的接入原则。不强依赖特定的物理连接方式（如直连或透传），而是通过 Native 层的适配层（Adapter/HAL）屏蔽硬件连接差异，确保架构在不同车型硬件拓扑下的通用性与兼容性。</li></ol><h2 id=功能性需求>功能性需求<a hidden class=anchor aria-hidden=true href=#功能性需求>#</a></h2><h3 id=稳定性全栈感知能力-1>稳定性全栈感知能力<a hidden class=anchor aria-hidden=true href=#稳定性全栈感知能力-1>#</a></h3><h4 id=应用层稳定性监控>应用层稳定性监控<a hidden class=anchor aria-hidden=true href=#应用层稳定性监控>#</a></h4><h5 id=fr-stab-001-应用-java-崩溃-java-crash-捕获><strong>FR-STAB-001 应用 Java 崩溃 (Java Crash) 捕获</strong><a hidden class=anchor aria-hidden=true href=#fr-stab-001-应用-java-崩溃-java-crash-捕获>#</a></h5><table><thead><tr><th>属性</th><th>内容</th></tr></thead><tbody><tr><td><strong>优先级</strong></td><td>P0</td></tr><tr><td><strong>前置条件</strong></td><td>1.系统层已部署全局监控探针。<br>2. 监控功能的配置开关处于开启状态。</td></tr><tr><td><strong>输入</strong></td><td><strong>触发源</strong>：<br>应用运行环境（Android Runtime）抛出的<strong>未捕获异常信号</strong>（Uncaught Exception）。<br><strong>数据</strong>：<br>1. 异常堆栈信息（StackTrace）。<br>2. 异常类型与描述消息（Exception Message）。</td></tr><tr><td><strong>处理逻辑</strong></td><td>1. <strong>异常拦截</strong>：<br>在应用进程因异常即将终止前，拦截异常信号，挂起当前线程以确保有足够的 CPU 时间片执行数据采集。<br>2. <strong>上下文捕获</strong>：<br>提取崩溃时刻的运行时环境信息，包括但不限于：<br>- 进程名称、线程名称及 ID。<br>- 应用的前后台状态。<br>- 当前 Activity 页面栈信息（用于还原用户路径）。<br>3. <strong>流控策略</strong>：<br>执行本地频次控制策略。检查该进程在设定时间窗口（如 10 分钟）内的崩溃次数，若超限则降级处理（仅记录统计计数，不抓取详细堆栈），防止日志写入引发 IO 阻塞。<br>4. <strong>透传退出</strong>：<br>数据采集完成后，<strong>必须</strong>将异常信号交还给系统默认处理程序，确保应用能够按照 Android 系统规范正常退出，防止应用界面假死或进程僵滞。</td></tr><tr><td><strong>输出</strong></td><td>1. <strong>结构化事件</strong>：生成包含完整上下文信息的 <code>GVM_APP_CRASH</code> 事件对象。<br>2. <strong>本地日志</strong>：在本地持久化存储区保留一份异常日志备份（作为兜底）。<br>3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》</td></tr></tbody></table><h5 id=fr-stab-002-应用无响应-anr-捕获><strong>FR-STAB-002 应用无响应 (ANR) 捕获</strong><a hidden class=anchor aria-hidden=true href=#fr-stab-002-应用无响应-anr-捕获>#</a></h5><table><thead><tr><th>属性</th><th>内容</th></tr></thead><tbody><tr><td><strong>优先级</strong></td><td>P0</td></tr><tr><td><strong>前置条件</strong></td><td>1. 系统层已部署全局监控探针。<br>2. 监控功能的配置开关处于开启状态。</td></tr><tr><td><strong>输入</strong></td><td><strong>触发源</strong>：系统框架层（Framework）识别到的<strong>应用无响应信号</strong>（AppNotResponding）。<br><strong>数据</strong>：<br>1. 目标应用进程标识（PID/ProcessName）。<br>2. 系统生成的<strong>堆栈跟踪文件</strong>（Trace File，通常位于 <code>/data/anr/</code> 目录）。</td></tr><tr><td><strong>处理逻辑</strong></td><td>1. <strong>信号识别</strong>：<br>实时接收系统 ActivityManagerService 发出的 ANR 通知。<br>2. <strong>目标过滤</strong>：<br>根据配置白名单判断是否采集该进程，过滤非关注应用的 ANR 事件。<br>3. <strong>堆栈截取</strong>：<br>读取系统生成的 Trace 文件，根据目标 PID <strong>精准截取</strong>该进程及其子线程的堆栈片段（需剔除文件中的其他无关进程数据，以减少数据体积）。<br>4. <strong>快照关联</strong>：<br>获取 ANR 发生时刻的系统负载信息（Load Avg / CPU Usage / IO Wait）并与堆栈信息打包。<br>5. <strong>流控策略</strong>：<br>执行本地频次控制策略。检查该进程在设定时间窗口（如 10 分钟）内的 ANR 次数，若超限则仅记录计数，不再执行堆栈截取操作。</td></tr><tr><td><strong>输出</strong></td><td>1. <strong>结构化事件</strong>：生成包含 Trace 附件索引（Reference）的 <code>GVM_APP_ANR</code> 事件对象。<br>2. <strong>本地日志</strong>：在本地持久化存储区生成关联的证据包（包含截取的 Trace 片段与系统负载快照）。<br>3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》</td></tr></tbody></table><h5 id=fr-stab-003-应用-native-库崩溃-app-jni-crash-捕获><strong>FR-STAB-003 应用 Native 库崩溃 (App JNI Crash) 捕获</strong><a hidden class=anchor aria-hidden=true href=#fr-stab-003-应用-native-库崩溃-app-jni-crash-捕获>#</a></h5><table><thead><tr><th style=text-align:left>属性</th><th style=text-align:left>内容</th></tr></thead><tbody><tr><td style=text-align:left><strong>优先级</strong></td><td style=text-align:left>P0</td></tr><tr><td style=text-align:left><strong>前置条件</strong></td><td style=text-align:left>1. 系统层已部署全局监控探针（Native Daemon）。<br>2. 监控功能的配置开关处于开启状态。</td></tr><tr><td style=text-align:left><strong>输入</strong></td><td style=text-align:left><strong>触发源</strong>：<br>应用进程（APP）加载的 JNI 动态库触发致命信号（SIGSEGV/SIGABRT）。<br><strong>数据</strong>：<br>1. 系统生成的 Tombstone 崩溃文件（通常位于 <code>/data/tombstones/</code>）。<br>2. 进程退出信号（Signal Code）。</td></tr><tr><td style=text-align:left><strong>处理逻辑</strong></td><td style=text-align:left>1. <strong>监听与解析</strong>：<br>实时监听系统 Tombstone 文件的生成事件，读取文件头部信息。<br>2. <strong>身份识别</strong>：<br>检查崩溃进程的 UID 或进程名称。若属于<strong>非系统核心进程</strong>（即普通 App），则执行应用级采集逻辑；若为系统服务则忽略（交由系统框架监控处理）。<br>3. <strong>指纹去重</strong>：<br>基于“应用名称 + 崩溃堆栈关键帧”生成唯一指纹，在端侧聚合重复的崩溃事件，防止日志风暴。<br>4. <strong>事件生成</strong>：<br>将非结构化的 Tombstone 数据转换为标准化的事件对象。</td></tr><tr><td style=text-align:left><strong>输出</strong></td><td style=text-align:left>1. <strong>结构化事件</strong>：生成 <code>GVM_APP_NATIVE_CRASH</code> 事件对象。<br>2. <strong>本地日志</strong>：建立事件 ID 与原始 Tombstone 文件的索引关联。<br>3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》</td></tr></tbody></table><h5 id=fr-stab-004-应用-oom-app-oom-事件监控>FR-STAB-004 应用 OOM (App OOM) 事件监控<a hidden class=anchor aria-hidden=true href=#fr-stab-004-应用-oom-app-oom-事件监控>#</a></h5><table><thead><tr><th style=text-align:left>属性</th><th style=text-align:left>内容</th></tr></thead><tbody><tr><td style=text-align:left><strong>优先级</strong></td><td style=text-align:left>P0</td></tr><tr><td style=text-align:left><strong>前置条件</strong></td><td style=text-align:left>1. 系统层已部署全局监控探针。<br>2. 监控功能的配置开关处于开启状态。<br>3. 具备获取应用进程退出详细原因的能力（如 ApplicationExitInfo 或类似机制）。</td></tr><tr><td style=text-align:left><strong>输入</strong></td><td style=text-align:left><strong>触发源</strong>：<br>应用进程<strong>意外终止信号</strong>。<br><strong>数据</strong>：<br>1. 进程退出原因描述（Exit Reason，需区分系统回收/异常崩溃）。<br>2. 进程终止前的内存使用统计数据（如 PSS/RSS/VSS）。</td></tr><tr><td style=text-align:left><strong>处理逻辑</strong></td><td style=text-align:left>1. <strong>原因甄别</strong>：<br>在进程退出后，识别退出原因。准确区分是<strong>系统低内存查杀 (LMK)</strong>（通常表现为 <code>REASON_LOW_MEMORY</code>）还是<strong>Java 堆内存耗尽</strong>（通常表现为 <code>OutOfMemoryError</code> 导致的 Crash）引发的异常。<br>2. <strong>内存快照回溯</strong>：<br>尝试关联该进程在终止前最近一次采集的内存统计数据（如 PSS/RSS），以辅助判断是否存在内存泄漏。<br>3. <strong>风暴抑制</strong>：<br>针对前台应用因 OOM 导致的反复重启进行检测。若同一应用在短时间内（如 5 分钟）连续触发 OOM，则实施指数退避策略，减少上报频次。<br>4. <strong>事件生成</strong>：<br>组装 OOM 事件负载，标记明确的 OOM 类型（System LMK / Java OOM）。</td></tr><tr><td style=text-align:left><strong>输出</strong></td><td style=text-align:left>1. <strong>结构化事件</strong>：生成包含内存快照信息的 <code>GVM_APP_OOM</code> 事件对象。<br>2. <strong>本地日志</strong>：记录关联的系统内存水位信息（MemInfo）。<br>3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》</td></tr></tbody></table><h4 id=系统框架稳定性监控>系统框架稳定性监控<a hidden class=anchor aria-hidden=true href=#系统框架稳定性监控>#</a></h4><h5 id=fr-stab-005-systemserver-watchdog-死锁-监控><strong>FR-STAB-005 SystemServer Watchdog (死锁) 监控</strong><a hidden class=anchor aria-hidden=true href=#fr-stab-005-systemserver-watchdog-死锁-监控>#</a></h5><table><thead><tr><th style=text-align:left>属性</th><th style=text-align:left>内容</th></tr></thead><tbody><tr><td style=text-align:left><strong>优先级</strong></td><td style=text-align:left>P0</td></tr><tr><td style=text-align:left><strong>前置条件</strong></td><td style=text-align:left>1. 监控探针已植入系统看门狗（Watchdog）模块或具备监听能力。<br>2. 监控功能的配置开关处于开启状态。</td></tr><tr><td style=text-align:left><strong>输入</strong></td><td style=text-align:left><strong>触发源</strong>：<br>系统关键锁或核心线程（如 UI Thread, IoThread）<strong>等待超时信号</strong>（通常阈值为 60秒）。<br><strong>数据</strong>：<br>1. 阻塞线程的完整堆栈信息（Stack Traces）。<br>2. 持锁状态与锁竞争信息（Lock Contention）。</td></tr><tr><td style=text-align:left><strong>处理逻辑</strong></td><td style=text-align:left>1. <strong>重启前拦截</strong>：<br>在系统触发看门狗复位（Soft Reboot / Restart）流程前，优先执行监控逻辑，确保有短暂的时间窗口进行数据转存。<br>2. <strong>现场固化</strong>：<br>立即将当前的系统全量线程堆栈（Traces.txt）复制或转存至持久化存储区，<strong>防止系统重启过程清理现场文件</strong>，导致关键证据丢失。<br>3. <strong>异常标记</strong>：<br>在磁盘特定位置写入“非正常重启”标志位（Flag），以便系统下次启动时进行归因统计，区分正常关机与异常重启。<br>4. <strong>事件上报</strong>：<br>尝试通过 Native 通道（因为 Java 层可能已挂死）发送死锁事件。</td></tr><tr><td style=text-align:left><strong>输出</strong></td><td style=text-align:left>1. <strong>结构化事件</strong>：生成包含死锁堆栈索引的 <code>GVM_SYS_WATCHDOG</code> 事件对象。<br>2. <strong>本地日志</strong>：在持久化目录保留死锁现场的 Trace 文件。<br>3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》</td></tr></tbody></table><h5 id=fr-stab-006-android-系统异常重启-system-restart-监控><strong>FR-STAB-006 Android 系统异常重启 (System Restart) 监控</strong><a hidden class=anchor aria-hidden=true href=#fr-stab-006-android-系统异常重启-system-restart-监控>#</a></h5><table><thead><tr><th style=text-align:left>属性</th><th style=text-align:left>内容</th></tr></thead><tbody><tr><td style=text-align:left><strong>优先级</strong></td><td style=text-align:left>P0</td></tr><tr><td style=text-align:left><strong>前置条件</strong></td><td style=text-align:left>1. 系统完成启动初始化流程（Boot Completed）。<br>2. 具备读取系统启动属性（Boot Reason）及持久化存储的权限。</td></tr><tr><td style=text-align:left><strong>输入</strong></td><td style=text-align:left><strong>触发源</strong>：<br>系统<strong>启动完成广播</strong> (Boot Completed) 或同等时机的初始化信号。<br><strong>数据</strong>：<br>1. 系统启动原因属性（如 <code>sys.boot.reason</code> 或 <code>ro.boot.bootreason</code>）。<br>2. 持久化存储中的<strong>历史状态标记</strong>（包含上一次启动时间戳、Watchdog/Crash 遗留的异常标志位）。</td></tr><tr><td style=text-align:left><strong>处理逻辑</strong></td><td style=text-align:left>1. <strong>原因推断</strong>：<br>对比本次启动原因与上一次运行状态进行逻辑仲裁：<br>- <strong>已知异常</strong>：若存在 Watchdog 或 Core Crash 遗留的标记，判定为对应的系统级故障重启。<br>- <strong>内核恐慌</strong>：若启动属性标识为 Kernel Panic 或 WDT（硬件看门狗），判定为内核级重启。<br>- <strong>正常重启</strong>：若标识为用户主动关机、OTA 升级或常规电源管理操作，判定为正常重启。<br>- <strong>掉电/未知</strong>：若无任何异常标记且非正常重启，判定为异常掉电或未知原因重启。<br>2. <strong>时长计算</strong>：<br>基于上一次记录的启动时间戳，计算上一次系统正常运行的时长（Uptime），用于评估系统平均无故障时间（MTBF）。<br>3. <strong>状态重置</strong>：<br>分析完成后，清除历史异常标记，更新本次启动时间戳，为下一次监控周期做准备。</td></tr><tr><td style=text-align:left><strong>输出</strong></td><td style=text-align:left>1. <strong>结构化事件</strong>：生成包含重启原因分类（Category）及运行时长（Duration）的 <code>GVM_SYS_RESTART</code> 事件对象。<br>2. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》</td></tr></tbody></table><h5 id=fr-stab-007-核心服务崩溃-core-service-crash-监控><strong>FR-STAB-007 核心服务崩溃 (Core Service Crash) 监控</strong><a hidden class=anchor aria-hidden=true href=#fr-stab-007-核心服务崩溃-core-service-crash-监控>#</a></h5><table><thead><tr><th style=text-align:left>属性</th><th style=text-align:left>内容</th></tr></thead><tbody><tr><td style=text-align:left><strong>优先级</strong></td><td style=text-align:left>P0</td></tr><tr><td style=text-align:left><strong>前置条件</strong></td><td style=text-align:left>1. 监控进程具备监听系统服务管理器（ServiceManager）或 init 进程状态的能力。<br>2. 核心进程白名单配置已加载。</td></tr><tr><td style=text-align:left><strong>输入</strong></td><td style=text-align:left><strong>触发源</strong>：<br>1. Native 守护进程崩溃产生的 Tombstone 文件。<br>2. ServiceManager 发出的 <code>DeathRecipient</code> 通知。<br>3. init 进程发出的 <code>SIGCHLD</code> 信号。<br><strong>数据</strong>：<br>1. 崩溃进程名称（Process Name）及 PID。<br>2. 进程退出状态码或终止信号。</td></tr><tr><td style=text-align:left><strong>处理逻辑</strong></td><td style=text-align:left>1. <strong>核心识别</strong>：<br>匹配崩溃进程名称是否在<strong>核心白名单</strong>中（如 <code>surfaceflinger</code>, <code>audioserver</code>, <code>netd</code>, <code>lmkd</code>）。若不在白名单，则视为普通 Native Crash 处理（参考 FR-STAB-003）。<br>2. <strong>多源仲裁</strong>：<br>优先使用 Tombstone 信息（包含详细堆栈），若未生成 Tombstone（如被系统强杀或 Watchdog 处决），则使用 ServiceManager 通知作为补充来源。<br>3. <strong>等级判定</strong>：<br>根据服务重要性标记故障等级（例如 SurfaceFlinger 崩溃标记为“致命”，会导致屏幕黑屏或系统软重启）。<br>4. <strong>事件生成</strong>：<br>组装核心服务崩溃事件，记录服务名称、崩溃时间及退出原因。</td></tr><tr><td style=text-align:left><strong>输出</strong></td><td style=text-align:left>1. <strong>结构化事件</strong>：生成包含服务名及影响等级的 <code>GVM_CORE_CRASH</code> 事件对象。<br>2. <strong>本地日志</strong>：关联该时间点附近的系统日志（Logcat）与崩溃堆栈。<br>3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》</td></tr></tbody></table><h5 id=fr-stab-008-系统低内存-lmk-事件监控><strong>FR-STAB-008 系统低内存 (LMK) 事件监控</strong><a hidden class=anchor aria-hidden=true href=#fr-stab-008-系统低内存-lmk-事件监控>#</a></h5><table><thead><tr><th style=text-align:left>属性</th><th style=text-align:left>内容</th></tr></thead><tbody><tr><td style=text-align:left><strong>优先级</strong></td><td style=text-align:left>P0</td></tr><tr><td style=text-align:left><strong>前置条件</strong></td><td style=text-align:left>1. 系统启用 Low Memory Killer 机制（如 Userspace LMKD）。<br>2. 监控组件具备接收系统内存管理模块通知的权限。</td></tr><tr><td style=text-align:left><strong>输入</strong></td><td style=text-align:left><strong>触发源</strong>：<br>系统内存管理守护进程（lmkd）执行的<strong>进程查杀动作</strong>。<br><strong>数据</strong>：<br>1. 目标进程信息（PID、UID、Process Name）。<br>2. 查杀时的决策依据（OOM Score Adj）。<br>3. 触发查杀时的系统内存压力状态（Memory Pressure State / PSI）。</td></tr><tr><td style=text-align:left><strong>处理逻辑</strong></td><td style=text-align:left>1. <strong>动作捕获</strong>：<br>实时感知 LMK 的查杀行为。<strong>推荐方案</strong>：采用源码插桩（Instrumentation）方式，在 <code>lmkd</code> 执行 kill 操作的原子逻辑处植入通知钩子，以获取零延迟、高精度的上下文信息；（备选方案：监听 EventLog 中的 <code>lmk_kill</code> 标签）。<br>2. <strong>水位快照</strong>：<br>同步记录系统当前的内存水位详情（MemTotal, MemFree, SwapUsed, Cached），用于后续分析是物理内存耗尽还是虚拟内存（Swap）耗尽。<br>3. <strong>聚合去噪</strong>：<br>执行时间窗口聚合策略。由于内存压力常导致短时间内连续查杀多个进程，需将同一压力波峰内（如 1 秒）的一组查杀事件聚合，避免产生告警风暴。<br>4. <strong>严重性判定</strong>：<br>识别被杀进程的类型。若被杀进程为前台可见应用或关键服务，标记为“高影响”事件。</td></tr><tr><td style=text-align:left><strong>输出</strong></td><td style=text-align:left>1. <strong>结构化事件</strong>：生成包含被杀进程列表及内存水位的 <code>GVM_SYS_LMK</code> 事件对象。<br>2. <strong>本地日志</strong>：保留查杀时刻的 <code>meminfo</code> 快照。<br>3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》</td></tr></tbody></table><h5 id=fr-stab-009-binder-通信异常监控><strong>FR-STAB-009 Binder 通信异常监控</strong><a hidden class=anchor aria-hidden=true href=#fr-stab-009-binder-通信异常监控>#</a></h5><table><thead><tr><th style=text-align:left>属性</th><th style=text-align:left>内容</th></tr></thead><tbody><tr><td style=text-align:left><strong>优先级</strong></td><td style=text-align:left>P1</td></tr><tr><td style=text-align:left><strong>前置条件</strong></td><td style=text-align:left>1. 监控探针具备访问内核 Binder 驱动节点或 Hook <code>libbinder</code> 的能力。<br>2. 监控配置已定义 Binder 线程池水位的告警阈值。</td></tr><tr><td style=text-align:left><strong>输入</strong></td><td style=text-align:left><strong>触发源</strong>：<br>1. Binder 驱动层的<strong>事务失败信号</strong>（如 <code>BR_FAILED_REPLY</code>, <code>BR_DEAD_REPLY</code>）。<br>2. 进程 Binder 线程池的<strong>资源耗尽状态</strong>。<br><strong>数据</strong>：<br>1. 通信双方身份（Caller PID/UID, Callee PID/UID）。<br>2. 接口描述符（Interface Descriptor）或事务代码（Transaction Code）。<br>3. 失败原因（如 <code>TransactionTooLarge</code>, <code>DeadObject</code>, <code>Timeout</code>）。</td></tr><tr><td style=text-align:left><strong>处理逻辑</strong></td><td style=text-align:left>1. <strong>异常捕获</strong>：<br>监测 IPC 通信链路健康度。<strong>推荐方案</strong>：在 Native <code>libbinder</code> 层进行插桩，拦截 <code>IPCThreadState</code> 中的错误返回码，从而在第一现场捕获异常。<br>2. <strong>资源枯竭识别 (Starvation)</strong>：<br>周期性或事件驱动地检查关键进程的 Binder 线程池状态。若活跃线程数达到上限（默认 16）且仍有请求积压，判定为 <strong>Binder 线程耗尽</strong>。<br>3. <strong>大负载识别</strong>：<br>识别 <code>TransactionTooLargeException</code>，记录传输过大数据的接口名称，辅助排查跨进程传输大图或大列表导致的性能问题。<br>4. <strong>链路还原</strong>：<br>在异常发生时，自动解析并记录“谁调用谁”（Client -> Server），明确责任方。</td></tr><tr><td style=text-align:left><strong>输出</strong></td><td style=text-align:left>1. <strong>结构化事件</strong>：生成包含通信双方及错误类型的 <code>GVM_SYS_BINDER_ERROR</code> 事件对象。<br>2. <strong>本地日志</strong>：记录 <code>/sys/kernel/debug/binder/transaction_log</code> (若可用) 或相关 Logcat 片段。<br>3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》</td></tr></tbody></table><h5 id=fr-stab-010-文件句柄-fd-泄漏监控><strong>FR-STAB-010 文件句柄 (FD) 泄漏监控</strong><a hidden class=anchor aria-hidden=true href=#fr-stab-010-文件句柄-fd-泄漏监控>#</a></h5><table><thead><tr><th style=text-align:left>属性</th><th style=text-align:left>内容</th></tr></thead><tbody><tr><td style=text-align:left><strong>优先级</strong></td><td style=text-align:left>P1</td></tr><tr><td style=text-align:left><strong>前置条件</strong></td><td style=text-align:left>1. 监控探针具备读取 <code>/proc/[pid]/fd</code> 目录或执行 <code>lsof</code> 类指令的权限。<br>2. 针对不同类型的进程（System/App）配置了相应的 FD 数量告警阈值。</td></tr><tr><td style=text-align:left><strong>输入</strong></td><td style=text-align:left><strong>触发源</strong>：<br>1. <strong>周期性采样</strong>：定时检查系统内进程的资源占用情况。<br>2. <strong>被动触发</strong>：捕获到系统日志中抛出的 <code>EMFILE</code> (&ldquo;Too many open files&rdquo;) 错误信号。<br><strong>Data</strong>：<br>1. 目标进程当前打开的文件句柄总数。<br>2. 具体的句柄指向路径（Symlinks in <code>/proc/pid/fd/</code>）。</td></tr><tr><td style=text-align:left><strong>处理逻辑</strong></td><td style=text-align:left>1. <strong>水位监测</strong>：<br>对关键进程进行周期性（如每 5 分钟）的 FD 数量扫描。对比系统设定的软限制（Soft Limit）与硬限制（Hard Limit）。<br>2. <strong>超限识别</strong>：<br>当某进程 FD 数量超过预警阈值（例如 > 800 或占比 > 80%）时，判定为存在泄漏风险。<br>3. <strong>现场快照</strong>：<br>在检测到超限瞬间，遍历该进程的 <code>/proc/[pid]/fd/</code> 目录，生成句柄分布快照。<strong>智能分类</strong>：统计不同类型句柄的占比（如 Socket, Anon_inode, Regular File），快速定位是网络连接泄漏还是文件未关闭。<br>4. <strong>趋势分析</strong>：<br>结合历史数据，识别 FD 数量是否呈“持续上升且不回落”的阶梯状趋势，以排除正常的业务并发高峰。<br></td></tr><tr><td style=text-align:left><strong>输出</strong></td><td style=text-align:left>1. <strong>结构化事件</strong>：生成包含 FD 总数及分类统计的 <code>GVM_SYS_FD_LEAK</code> 事件对象。<br>2. <strong>本地日志</strong>：保留 top N 的句柄路径列表（Evidence List）。<br>3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》</td></tr></tbody></table><h4 id=异构运行环境监控-heterogeneous-env-monitoring>异构运行环境监控 (Heterogeneous Env Monitoring)<a hidden class=anchor aria-hidden=true href=#异构运行环境监控-heterogeneous-env-monitoring>#</a></h4><h5 id=fr-stab-012-linux-host-pvm-重启与状态监控><strong>FR-STAB-012 Linux Host (PVM) 重启与状态监控</strong><a hidden class=anchor aria-hidden=true href=#fr-stab-012-linux-host-pvm-重启与状态监控>#</a></h5><table><thead><tr><th style=text-align:left>属性</th><th style=text-align:left>内容</th></tr></thead><tbody><tr><td style=text-align:left><strong>优先级</strong></td><td style=text-align:left>P0</td></tr><tr><td style=text-align:left><strong>前置条件</strong></td><td style=text-align:left>1. PVM (Linux Host) 侧已部署 Host Daemon 并具备读取系统启动日志（如 <code>/sys/fs/pstore</code> 或 systemd journal）的权限。<br>2. PVM 与 GVM 之间的跨域通信通道在启动后能够建立连接。</td></tr><tr><td style=text-align:left><strong>输入</strong></td><td style=text-align:left><strong>触发源</strong>：<br>1. <strong>PVM 启动完成</strong>：Host Daemon 随系统启动初始化。<br>2. <strong>连接建立</strong>：PVM 与 GVM 建立首次握手成功。<br><strong>数据</strong>：<br>1. PVM 本次启动原因（Boot Reason）。<br>2. 历史持久化日志（上一周期的 Kernel Panic Log 或 Watchdog 记录）。<br>3. 实时心跳报文。</td></tr><tr><td style=text-align:left><strong>处理逻辑</strong></td><td style=text-align:left>1. <strong>启动回溯（Post-Boot Analysis）</strong>：<br>Host Daemon 在 PVM 启动初期，检查持久化存储中的上一次关机状态。识别是<strong>正常关机</strong>、<strong>掉电</strong>还是<strong>异常重启</strong>（如 Kernel Panic 导致的 WDT Reset）。<br>2. <strong>事件缓存</strong>：<br>若判定为异常重启，Host Daemon 生成重启事件对象并暂存于本地内存或磁盘队列中，等待跨域通道就绪。<br>3. <strong>延迟同步（Delayed Sync）</strong>：<br>当监测到 GVM (Android) 侧的 <code>PolarisNativeDaemon</code> 上线并建立连接后，立即将缓存的“上一次重启事件”发送给 GVM。<br>4. <strong>运行时状态监测</strong>：<br>在连接建立后的运行期间，Host Daemon 周期性向 GVM 发送心跳包与健康度状态（如 Systemd Failed Units），供 GVM 侧记录实时趋势。</td></tr><tr><td style=text-align:left><strong>输出</strong></td><td style=text-align:left>1. <strong>结构化事件</strong>：生成 <code>PVM_SYS_RESTART</code>（携带重启原因的历史事件）或 <code>PVM_STATUS_REPORT</code>（运行时状态）。<br>2. <strong>本地日志</strong>：在 PVM 侧保留原始的重启原因分析日志。<br>3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》</td></tr></tbody></table><h5 id=fr-stab-013-mcu-故障码与心跳监控><strong>FR-STAB-013 MCU 故障码与心跳监控</strong><a hidden class=anchor aria-hidden=true href=#fr-stab-013-mcu-故障码与心跳监控>#</a></h5><table><thead><tr><th style=text-align:left>属性</th><th style=text-align:left>内容</th></tr></thead><tbody><tr><td style=text-align:left><strong>优先级</strong></td><td style=text-align:left>P1</td></tr><tr><td style=text-align:left><strong>前置条件</strong></td><td style=text-align:left>1. 硬件抽象层（HAL）或驱动层已完成 MCU 通信协议适配。<br>2. 监控守护进程（Native Daemon）具备读取 MCU 状态接口的权限。</td></tr><tr><td style=text-align:left><strong>输入</strong></td><td style=text-align:left><strong>触发源</strong>：<br>1. MCU 周期性上报的<strong>状态报文</strong>（Status Message）。<br>2. 硬件中断或底层驱动回调。<br><strong>数据</strong>：<br>1. 存活心跳计数器（Rolling Counter）。<br>2. 硬件诊断故障码（DTC - Diagnostic Trouble Code）。<br>3. 外设关键状态字（如电源模式、复位原因）。</td></tr><tr><td style=text-align:left><strong>处理逻辑</strong></td><td style=text-align:left>1. <strong>存活判定</strong>：<br>通过监测心跳计数器的连续性和变化率来判断 MCU 状态。若计数器在设定时间窗口（<strong>TBD</strong>）内停止跳变或非法跳变，判定为 <strong>MCU 挂死或通信中断</strong>。<br>2. <strong>协议映射</strong>：<br>建立 MCU 原始故障码与平台统一错误定义的映射表。将厂商特定的十六进制 DTC（如 <code>0x1234</code>）转换为可读的平台标准错误码（如 <code>ERR_MCU_PMIC_FAIL</code>）。<br>3. <strong>信号去抖</strong>：<br>对偶发的故障信号进行软件滤波（De-bounce）。只有在连续 N 帧报文中确认同一故障码，或故障持续时长超过阈值时，才确认为有效故障，防止因总线干扰导致的误报。<br>4. <strong>复位检测</strong>：<br>监测 MCU 的复位原因寄存器。若发现异常复位标识（如 WDT Reset），记录异常复位事件。</td></tr><tr><td style=text-align:left><strong>输出</strong></td><td style=text-align:left>1. <strong>结构化事件</strong>：生成 <code>MCU_HEARTBEAT_LOST</code>（失联）或 <code>MCU_HARDWARE_FAULT</code>（硬件故障）事件对象。<br>2. <strong>本地日志</strong>：记录原始报文数据（Raw Data）以便后续校验。<br>3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》</td></tr></tbody></table><h5 id=fr-stab-014-异构关键进程-pvm-critical-process-稳定性监控><strong>FR-STAB-014 异构关键进程 (PVM Critical Process) 稳定性监控</strong><a hidden class=anchor aria-hidden=true href=#fr-stab-014-异构关键进程-pvm-critical-process-稳定性监控>#</a></h5><table><thead><tr><th style=text-align:left>属性</th><th style=text-align:left>内容</th></tr></thead><tbody><tr><td style=text-align:left><strong>优先级</strong></td><td style=text-align:left>P0</td></tr><tr><td style=text-align:left><strong>前置条件</strong></td><td style=text-align:left>1. 目标关键进程（如 Audio Server, Display Composer, GSL HAL 等）已在 Host 侧启动。<br>2. Polaris Host Daemon 具备对目标进程状态的查询或监听权限。</td></tr><tr><td style=text-align:left><strong>输入</strong></td><td style=text-align:left><strong>触发源</strong>：<br>1. 操作系统（Linux Host）发出的<strong>进程终止信号</strong>（如 SIGCHLD）。<br>2. 服务管理框架（如 Systemd）抛出的<strong>服务状态变更通知</strong>（Service Unit Status Change）。<br>3. 目标进程输出到标准错误流（Stderr）的<strong>致命错误日志</strong>。<br><strong>数据</strong>：<br>1. 进程标识（PID, Process Name, Unit Name）。<br>2. 退出状态码（Exit Code）或终止信号（Signal）。</td></tr><tr><td style=text-align:left><strong>处理逻辑</strong></td><td style=text-align:left>1. <strong>通用监听</strong>：<br>采用非侵入式手段实时感知关键进程的生命周期。针对受 Systemd 托管的服务，订阅其 D-Bus 状态变更信号；针对独立进程，采用 PID 存活轮询或父进程信号监听机制。<br>2. <strong>状态判定</strong>：<br>- <strong>异常退出</strong>：识别进程非预期的终止（Exit Code != 0）。<br>- <strong>僵死/挂起</strong>：若具备条件，监测进程是否长时间处于 D 状态（Uninterruptible Sleep）或对心跳接口无响应。<br>3. <strong>抖动抑制 (Flapping Detection)</strong>：<br>针对具有“自动重启”机制的关键服务，在设定时间窗口内（如 10秒）若检测到多次反复重启，应将其聚合为单次“服务抖动”事件上报，防止告警风暴。<br>4. <strong>现场记录</strong>：<br>在进程崩溃瞬间，尝试捕获其最后输出的标准错误日志（Stderr）或 Journalctl 片段，作为归因线索。</td></tr><tr><td style=text-align:left><strong>输出</strong></td><td style=text-align:left>1. <strong>结构化事件</strong>：生成包含进程名、退出码及故障频次的 <code>PVM_PROCESS_CRASH</code> 事件对象。<br>2. <strong>本地日志</strong>：Host 侧保留相关的系统日志片段。<br>3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》</td></tr></tbody></table><h5 id=fr-stab-015-温度监控><strong>FR-STAB-015 温度监控</strong><a hidden class=anchor aria-hidden=true href=#fr-stab-015-温度监控>#</a></h5><table><thead><tr><th style=text-align:left>属性</th><th style=text-align:left>内容</th></tr></thead><tbody><tr><td style=text-align:left><strong>优先级</strong></td><td style=text-align:left>P1</td></tr><tr><td style=text-align:left><strong>前置条件</strong></td><td style=text-align:left>1. 系统底层具备热管理子系统（Thermal HAL / Thermal Daemon）。<br>2. 监控探针具备读取 <code>/sys/class/thermal</code> 节点或订阅 <code>IThermalService</code> 回调的权限。</td></tr><tr><td style=text-align:left><strong>输入</strong></td><td style=text-align:left><strong>触发源</strong>：<br>1. <strong>被动接收</strong>：Thermal HAL 上报的热状态变更回调（如 <code>onStatusChanged</code>）。<br>2. <strong>主动采样</strong>：周期性读取关键热区（Thermal Zone）的温度传感器数值。<br><strong>数据</strong>：<br>1. 热区名称（Zone Name, 如 <code>cpu</code>, <code>gpu</code>, <code>battery</code>, <code>soc</code>）。<br>2. 当前温度值（Temperature in m°C）。<br>3. 热状态等级（Thermal Status: NONE, LIGHT, MODERATE, SEVERE, CRITICAL, SHUTDOWN）。</td></tr><tr><td style=text-align:left><strong>处理逻辑</strong></td><td style=text-align:left>1. <strong>状态监听</strong>：<br>实时订阅系统热管理服务的状态变更通知。一旦热状态跨越阈值（例如从 <code>NONE</code> 变为 <code>SEVERE</code>），立即触发记录逻辑。<br>2. <strong>降频关联</strong>：<br>当检测到温度过高触发温控策略（Throttling）时，尝试关联当前的 CPU/GPU 频率限制状态，以解释可能伴随发生的卡顿或掉帧现象（辅助性能分析）。<br>3. <strong>危急保护记录</strong>：<br>当收到 <code>SHUTDOWN</code> 级别的热信号时，视为“过热关机前兆”，必须以最高优先级将当前温度快照写入持久化存储，作为系统异常重启（FR-STAB-006）的直接归因证据。<br>4. <strong>趋势采样</strong>：<br>在非危急状态下，按低频（如每 5 分钟）采样 SoC 核心温度，用于绘制温度变化趋势图。</td></tr><tr><td style=text-align:left><strong>输出</strong></td><td style=text-align:left>1. <strong>结构化事件</strong>：生成 <code>GVM_SYS_THERMAL_EVENT</code>（包含热区名称、温度值及温控等级）。<br>2. <strong>本地日志</strong>：保留过热时刻的 <code>thermalservice</code> 状态或相关节点快照。<br>3. 结构化事件以及本地日志存储目录参考《Polaris 1.0 全局事件ID与注册表规范》</td></tr></tbody></table><h2 id=非功能需求>非功能需求<a hidden class=anchor aria-hidden=true href=#非功能需求>#</a></h2><h2 id=端云交互协议设计>端云交互协议设计<a hidden class=anchor aria-hidden=true href=#端云交互协议设计>#</a></h2><h2 id=安全与隐私>安全与隐私<a hidden class=anchor aria-hidden=true href=#安全与隐私>#</a></h2><h2 id=风险--限制--依赖>风险 & 限制 & 依赖<a hidden class=anchor aria-hidden=true href=#风险--限制--依赖>#</a></h2><h2 id=实施计划>实施计划<a hidden class=anchor aria-hidden=true href=#实施计划>#</a></h2><h3 id=阶段划分>阶段划分<a hidden class=anchor aria-hidden=true href=#阶段划分>#</a></h3><h3 id=资源需求计划>资源需求计划<a hidden class=anchor aria-hidden=true href=#资源需求计划>#</a></h3><h2 id=附录>附录<a hidden class=anchor aria-hidden=true href=#附录>#</a></h2></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://ethen-cao.github.io/ethenslab/>Ethen 的实验室</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script src=https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js></script><script>mermaid.initialize({startOnLoad:!0,theme:"default"})</script><script src=https://cdn.jsdelivr.net/npm/plantuml-encoder@1.4.0/dist/plantuml-encoder.min.js></script><script>(function(){const e=document.querySelectorAll("pre > code.language-plantuml, pre > code.language-planuml");e.forEach(e=>{const s=e.innerText,o=plantumlEncoder.encode(s),i="https://www.plantuml.com/plantuml/svg/"+o,t=document.createElement("img");t.src=i,t.alt="PlantUML Diagram",t.style.maxWidth="100%";const n=e.parentNode;n.parentNode.replaceChild(t,n)})})()</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>